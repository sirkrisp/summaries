{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to MkDocs For full documentation visit mkdocs.org . Commands mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs -h - Print help message and exit. Project layout mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files.","title":"Home"},{"location":"#welcome-to-mkdocs","text":"For full documentation visit mkdocs.org .","title":"Welcome to MkDocs"},{"location":"#commands","text":"mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs -h - Print help message and exit.","title":"Commands"},{"location":"#project-layout","text":"mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files.","title":"Project layout"},{"location":"about/","text":"This is me","title":"About"},{"location":"summaries/","text":"Permalinks to summaries","title":"Summaries"},{"location":"Algorithms%20Lab/boost_graph_library/","text":"","title":"Boost Graph Library"},{"location":"Algorithms%20Lab/dynamic_programming/","text":"","title":"Dynamic Programming"},{"location":"Algorithms%20Lab/geometric_computing/","text":"Geometry Computing using CGAL When do we use exact and when do we use the inexact kernel?","title":"Geometric Computing"},{"location":"Algorithms%20Lab/geometric_computing/#geometry-computing-using-cgal","text":"","title":"Geometry Computing using CGAL"},{"location":"Algorithms%20Lab/geometric_computing/#when-do-we-use-exact-and-when-do-we-use-the-inexact-kernel","text":"","title":"When do we use exact and when do we use the inexact kernel?"},{"location":"Algorithms%20Lab/greedy/","text":"When locally optimal choices lead to globally optimal choices. Proof techniques Exchange argument Example: The Knapsack Problem Stay Ahead argument Example: Job Scheduler: Split & List What if we have to use brute-force to solve a problem: Use heuristics Improve worst case complexity Example: Subset Sum For \\(S \\subseteq N\\) , is there a subset \\(S' \\subseteq S\\) with \\(\\sum_{s \\in S'} s = k\\) ? NP-complete","title":"Greedy Algorithms"},{"location":"Algorithms%20Lab/greedy/#proof-techniques","text":"","title":"Proof techniques"},{"location":"Algorithms%20Lab/greedy/#exchange-argument","text":"","title":"Exchange argument"},{"location":"Algorithms%20Lab/greedy/#example-the-knapsack-problem","text":"","title":"Example: The Knapsack Problem"},{"location":"Algorithms%20Lab/greedy/#stay-ahead-argument","text":"","title":"Stay Ahead argument"},{"location":"Algorithms%20Lab/greedy/#example-job-scheduler","text":"","title":"Example: Job Scheduler:"},{"location":"Algorithms%20Lab/greedy/#split-list","text":"What if we have to use brute-force to solve a problem: Use heuristics Improve worst case complexity","title":"Split &amp; List"},{"location":"Algorithms%20Lab/greedy/#example-subset-sum","text":"For \\(S \\subseteq N\\) , is there a subset \\(S' \\subseteq S\\) with \\(\\sum_{s \\in S'} s = k\\) ? NP-complete","title":"Example: Subset Sum"},{"location":"Algorithms%20Lab/numbers_and_computation/","text":"CGAL = The Computational Geometry Algorithms Library Does the input fit? Predicates vs Constructions Predicates are operations whose output set is finite whereas constructions are operations whose output set is infinite .","title":"Numbers: Representation and Computation (CGAL)"},{"location":"Algorithms%20Lab/numbers_and_computation/#cgal-the-computational-geometry-algorithms-library","text":"","title":"CGAL = The Computational Geometry Algorithms Library"},{"location":"Algorithms%20Lab/numbers_and_computation/#does-the-input-fit","text":"","title":"Does the input fit?"},{"location":"Algorithms%20Lab/numbers_and_computation/#predicates-vs-constructions","text":"Predicates are operations whose output set is finite whereas constructions are operations whose output set is infinite .","title":"Predicates vs Constructions"},{"location":"Algorithms%20Lab/prefix_sum_and_precomputation/","text":"Problem Find the number of consecutive tuples \\((x_i, \\ldots, x_j), \\ 0 < i < j < n\\) such that the sum \\(\\sum_{k=i \\ldots j} x_k\\) is even. Greedy Solution Compute the sum for all possible ranges and check whether the sum is even. 1 2 3 4 5 6 7 8 num_pairs_even = 0 for i in range ( n ): for j in range ( i , n ): sum_ij = 0 for k in range ( i , j ): sum_ij += x [ k ] if sum_ij % 2 == 0 : num_pairs_even += 1 \u2192 Complexity: \\(O(n^3)\\) Improved version Precompute partial sums: 1 2 3 4 5 6 7 8 9 num_pairs_even = 0 partial_sums = [ x [ 0 ]] for i in range ( 1 , n ): partial_sums . append ( partial_sums [ i - 1 ] + x [ i ]) for i in range ( n ): for j in range ( i , n ): sum_ij = partial_sums [ j ] - partial_sums [ i ] if sum_ij % 2 == 0 : num_pairs_even += 1 \u2192 Complexity: \\(O(n^2)\\) Optimal solution We can improve the runtime by exploiting the fact that we are only interested in the number of even pairs. In particular, only the sum of two even or two odd partial sums are even. Let \\(n_e\\) = #even and \\(n_o\\) = #odd partial sums. Then, the number of even pairs is equal to: \\[ n_e + \\binom{n_e}{2} + \\binom{n_o}{2} \\] 1 2 3 4 5 6 7 8 9 10 11 from scipy.special import binom partial_sum = 0 n_e = 0 n_o = 0 for i in range ( n ): partial_sum += x [ i ] if partial_sum % 2 == 0 : n_e += 1 else : n_o += 1 num_pairs_even = n_e + binom ( n_e , 2 ) + binom ( n_o , 2 ) \u2192 Complexity: \\(O(n)\\)","title":"Prefix Sum and Precomputation"},{"location":"Algorithms%20Lab/prefix_sum_and_precomputation/#problem","text":"Find the number of consecutive tuples \\((x_i, \\ldots, x_j), \\ 0 < i < j < n\\) such that the sum \\(\\sum_{k=i \\ldots j} x_k\\) is even.","title":"Problem"},{"location":"Algorithms%20Lab/prefix_sum_and_precomputation/#greedy-solution","text":"Compute the sum for all possible ranges and check whether the sum is even. 1 2 3 4 5 6 7 8 num_pairs_even = 0 for i in range ( n ): for j in range ( i , n ): sum_ij = 0 for k in range ( i , j ): sum_ij += x [ k ] if sum_ij % 2 == 0 : num_pairs_even += 1 \u2192 Complexity: \\(O(n^3)\\)","title":"Greedy Solution"},{"location":"Algorithms%20Lab/prefix_sum_and_precomputation/#improved-version","text":"Precompute partial sums: 1 2 3 4 5 6 7 8 9 num_pairs_even = 0 partial_sums = [ x [ 0 ]] for i in range ( 1 , n ): partial_sums . append ( partial_sums [ i - 1 ] + x [ i ]) for i in range ( n ): for j in range ( i , n ): sum_ij = partial_sums [ j ] - partial_sums [ i ] if sum_ij % 2 == 0 : num_pairs_even += 1 \u2192 Complexity: \\(O(n^2)\\)","title":"Improved version"},{"location":"Algorithms%20Lab/prefix_sum_and_precomputation/#optimal-solution","text":"We can improve the runtime by exploiting the fact that we are only interested in the number of even pairs. In particular, only the sum of two even or two odd partial sums are even. Let \\(n_e\\) = #even and \\(n_o\\) = #odd partial sums. Then, the number of even pairs is equal to: \\[ n_e + \\binom{n_e}{2} + \\binom{n_o}{2} \\] 1 2 3 4 5 6 7 8 9 10 11 from scipy.special import binom partial_sum = 0 n_e = 0 n_o = 0 for i in range ( n ): partial_sum += x [ i ] if partial_sum % 2 == 0 : n_e += 1 else : n_o += 1 num_pairs_even = n_e + binom ( n_e , 2 ) + binom ( n_o , 2 ) \u2192 Complexity: \\(O(n)\\)","title":"Optimal solution"},{"location":"Algorithms%20Lab/proximity_structures/","text":"Using CGAL Triangulation Delaunay triangulation Voronoi diagram","title":"Proximity Structures"},{"location":"Algorithms%20Lab/proximity_structures/#triangulation","text":"","title":"Triangulation"},{"location":"Algorithms%20Lab/proximity_structures/#delaunay-triangulation","text":"","title":"Delaunay triangulation"},{"location":"Algorithms%20Lab/proximity_structures/#voronoi-diagram","text":"","title":"Voronoi diagram"},{"location":"Algorithms%20Lab/sliding_window/","text":"","title":"Sliding Window"},{"location":"Algorithms%20Lab/exercises/w01/","text":"Even Pairs For problem description and solution see Prefix Sum and Precomputation for more detail. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 #include <iostream> // We will use C++ input/output via streams #include <boost/math/special_functions/binomial.hpp> void testcase () { int n ; std :: cin >> n ; // Read the number of integers to follow int n_e = 0 ; int n_o = 0 ; int partial_sum = 0 ; for ( int i = 0 ; i < n ; ++ i ){ int xi ; std :: cin >> xi ; partial_sum += xi ; if ( partial_sum % 2 == 0 ) n_e += 1 ; else n_o += 1 ; } int result = n_e + boost :: math :: binomial_coefficient < double > ( n_e , 2 ) + boost :: math :: binomial_coefficient < double > ( n_o , 2 ); std :: cout << result << std :: endl ; // Output the final result } int main () { std :: ios_base :: sync_with_stdio ( false ); // Always! int t ; std :: cin >> t ; // Read the number of test cases for ( int i = 0 ; i < t ; ++ i ) testcase (); // Solve a particular test case } Dominoes Problem Find the maximum number \\(m\\) of toppled dominoes that vary in height. More formal, \\(\\forall j < m \\, \\exists i < j: i + h_i > j\\) . Difficulties The maximum number of toppled dominoes cannot be larger than the total number of dominoes. Techniques None Solution \\(\\forall j < m \\, \\exists i < j: i + h_i > j\\) is equivalent to \\(\\forall j < m: j < \\max_{i < j} \\{i + h_i\\}\\) . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 #include <iostream> // We will use C++ input/output via streams #include <algorithm> void testcase () { int n ; std :: cin >> n ; // Read the number of integers to follow int max_l ; std :: cin >> max_l ; for ( int i = 1 ; i < n ; ++ i ){ int hi ; std :: cin >> hi ; // height of dominoe i if ( i < max_l ) max_l = std :: max ( i + hi , max_l ); } max_l = std :: min ( max_l , n ); std :: cout << max_l << std :: endl ; // Output the final result } int main () { std :: ios_base :: sync_with_stdio ( false ); // Always! int t ; std :: cin >> t ; // Read the number of test cases for ( int i = 0 ; i < t ; ++ i ) testcase (); // Solve a particular test case } Even Matrices Problem Find the number of quadruples \\((i_1,i_2,j_1,j_2)\\) with \\(1 \\leq i_1 \\leq i_2 \\leq n\\) and \\(1 \\leq j_1 \\leq j_2 \\leq n\\) such that the sum $$ \\sum_{i=i_1}^{i_2} \\sum_{j=j_1}^{j_2} x_{i, j} $$ is even with \\(x_{i,j} \\in \\{0,1\\}\\) . Difficulties First think about runtime: \\(n < 200\\) \u2192 \\(O(n^3)\\) is still ok Special cases for binomial coefficient Techniques Similar to the first problem . Use precomputation of partial sums and the formula for even pairs. Solution 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 #include <iostream> // We will use C++ input/output via streams #include <boost/math/special_functions/binomial.hpp> #include <vector> void testcase () { int n ; std :: cin >> n ; // Read the number of integers to follow // pre-compute partial sums in i-direction std :: vector < std :: vector < int >> S ( n , std :: vector < int > ( n , 0 )); for ( int j = 0 ; j < n ; ++ j ){ int xij ; std :: cin >> xij ; S [ 0 ][ j ] = xij ; } for ( int i = 1 ; i < n ; ++ i ){ for ( int j = 0 ; j < n ; ++ j ){ int xij ; std :: cin >> xij ; S [ i ][ j ] = S [ i -1 ][ j ] + xij ; } } // Since n < 200, runtime of n^3 is still ok int result = 0 ; for ( int i1 = 0 ; i1 < n ; ++ i1 ){ for ( int i2 = i1 ; i2 < n ; ++ i2 ){ // Use same algorithm as for even pairs int n_e = 0 ; int n_o = 0 ; int partial_sum = 0 ; for ( int j = 0 ; j < n ; ++ j ){ int tmp = 0 ; if ( i1 > 0 ) tmp = S [ i1 -1 ][ j ]; partial_sum += ( S [ i2 ][ j ] - tmp ) % 2 ; if ( partial_sum % 2 == 0 ) n_e += 1 ; else n_o += 1 ; } result += n_e ; // Special cases if ( n_e >= 2 ) result += boost :: math :: binomial_coefficient < double > ( n_e , 2 ); if ( n_o >= 2 ) result += boost :: math :: binomial_coefficient < double > ( n_o , 2 ); } } std :: cout << result << std :: endl ; // Output the final result } int main () { std :: ios_base :: sync_with_stdio ( false ); // Always! int t ; std :: cin >> t ; // Read the number of test cases for ( int i = 0 ; i < t ; ++ i ) testcase (); // Solve a particular test case }","title":"week 1"},{"location":"Algorithms%20Lab/exercises/w01/#even-pairs","text":"For problem description and solution see Prefix Sum and Precomputation for more detail. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 #include <iostream> // We will use C++ input/output via streams #include <boost/math/special_functions/binomial.hpp> void testcase () { int n ; std :: cin >> n ; // Read the number of integers to follow int n_e = 0 ; int n_o = 0 ; int partial_sum = 0 ; for ( int i = 0 ; i < n ; ++ i ){ int xi ; std :: cin >> xi ; partial_sum += xi ; if ( partial_sum % 2 == 0 ) n_e += 1 ; else n_o += 1 ; } int result = n_e + boost :: math :: binomial_coefficient < double > ( n_e , 2 ) + boost :: math :: binomial_coefficient < double > ( n_o , 2 ); std :: cout << result << std :: endl ; // Output the final result } int main () { std :: ios_base :: sync_with_stdio ( false ); // Always! int t ; std :: cin >> t ; // Read the number of test cases for ( int i = 0 ; i < t ; ++ i ) testcase (); // Solve a particular test case }","title":"Even Pairs"},{"location":"Algorithms%20Lab/exercises/w01/#dominoes","text":"","title":"Dominoes"},{"location":"Algorithms%20Lab/exercises/w01/#problem","text":"Find the maximum number \\(m\\) of toppled dominoes that vary in height. More formal, \\(\\forall j < m \\, \\exists i < j: i + h_i > j\\) .","title":"Problem"},{"location":"Algorithms%20Lab/exercises/w01/#difficulties","text":"The maximum number of toppled dominoes cannot be larger than the total number of dominoes.","title":"Difficulties"},{"location":"Algorithms%20Lab/exercises/w01/#techniques","text":"None","title":"Techniques"},{"location":"Algorithms%20Lab/exercises/w01/#solution","text":"\\(\\forall j < m \\, \\exists i < j: i + h_i > j\\) is equivalent to \\(\\forall j < m: j < \\max_{i < j} \\{i + h_i\\}\\) . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 #include <iostream> // We will use C++ input/output via streams #include <algorithm> void testcase () { int n ; std :: cin >> n ; // Read the number of integers to follow int max_l ; std :: cin >> max_l ; for ( int i = 1 ; i < n ; ++ i ){ int hi ; std :: cin >> hi ; // height of dominoe i if ( i < max_l ) max_l = std :: max ( i + hi , max_l ); } max_l = std :: min ( max_l , n ); std :: cout << max_l << std :: endl ; // Output the final result } int main () { std :: ios_base :: sync_with_stdio ( false ); // Always! int t ; std :: cin >> t ; // Read the number of test cases for ( int i = 0 ; i < t ; ++ i ) testcase (); // Solve a particular test case }","title":"Solution"},{"location":"Algorithms%20Lab/exercises/w01/#even-matrices","text":"","title":"Even Matrices"},{"location":"Algorithms%20Lab/exercises/w01/#problem_1","text":"Find the number of quadruples \\((i_1,i_2,j_1,j_2)\\) with \\(1 \\leq i_1 \\leq i_2 \\leq n\\) and \\(1 \\leq j_1 \\leq j_2 \\leq n\\) such that the sum $$ \\sum_{i=i_1}^{i_2} \\sum_{j=j_1}^{j_2} x_{i, j} $$ is even with \\(x_{i,j} \\in \\{0,1\\}\\) .","title":"Problem"},{"location":"Algorithms%20Lab/exercises/w01/#difficulties_1","text":"First think about runtime: \\(n < 200\\) \u2192 \\(O(n^3)\\) is still ok Special cases for binomial coefficient","title":"Difficulties"},{"location":"Algorithms%20Lab/exercises/w01/#techniques_1","text":"Similar to the first problem . Use precomputation of partial sums and the formula for even pairs.","title":"Techniques"},{"location":"Algorithms%20Lab/exercises/w01/#solution_1","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 #include <iostream> // We will use C++ input/output via streams #include <boost/math/special_functions/binomial.hpp> #include <vector> void testcase () { int n ; std :: cin >> n ; // Read the number of integers to follow // pre-compute partial sums in i-direction std :: vector < std :: vector < int >> S ( n , std :: vector < int > ( n , 0 )); for ( int j = 0 ; j < n ; ++ j ){ int xij ; std :: cin >> xij ; S [ 0 ][ j ] = xij ; } for ( int i = 1 ; i < n ; ++ i ){ for ( int j = 0 ; j < n ; ++ j ){ int xij ; std :: cin >> xij ; S [ i ][ j ] = S [ i -1 ][ j ] + xij ; } } // Since n < 200, runtime of n^3 is still ok int result = 0 ; for ( int i1 = 0 ; i1 < n ; ++ i1 ){ for ( int i2 = i1 ; i2 < n ; ++ i2 ){ // Use same algorithm as for even pairs int n_e = 0 ; int n_o = 0 ; int partial_sum = 0 ; for ( int j = 0 ; j < n ; ++ j ){ int tmp = 0 ; if ( i1 > 0 ) tmp = S [ i1 -1 ][ j ]; partial_sum += ( S [ i2 ][ j ] - tmp ) % 2 ; if ( partial_sum % 2 == 0 ) n_e += 1 ; else n_o += 1 ; } result += n_e ; // Special cases if ( n_e >= 2 ) result += boost :: math :: binomial_coefficient < double > ( n_e , 2 ); if ( n_o >= 2 ) result += boost :: math :: binomial_coefficient < double > ( n_o , 2 ); } } std :: cout << result << std :: endl ; // Output the final result } int main () { std :: ios_base :: sync_with_stdio ( false ); // Always! int t ; std :: cin >> t ; // Read the number of test cases for ( int i = 0 ; i < t ; ++ i ) testcase (); // Solve a particular test case }","title":"Solution"},{"location":"Algorithms%20Lab/exercises/w02/","text":"Burning Coins Problem The goal is to find an optimal policy \\(\\pi^*\\) that maximizes the guaranteed total reward in a deterministic game: \\[ \\pi^* = \\arg \\max_\\pi \\left\\{\\min_{\\pi'} r(\\pi, \\pi') \\right\\}, \\] where \\(r\\) is the total reward by acting according to the deterministic policies \\(\\pi\\) and \\(\\pi'\\) . Difficulties Formulating the mathematical problem. Techniques Dynamic program Solution Let \\(S_{i,j}\\) be the guaranteed total reward in range \\([i,j]\\) and it's the turn of player 1. We can then formulate the dynamic program by exploiting the following recursive relationship: \\[ S_{i,j} = \\max_{(i',j') \\in A_{i,j}} \\left\\{ v(i,j,i',j') + \\min_{(i'',j'') \\in A_{i',j'}} S_{i'',j''} \\right\\} \\] 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 #include <iostream> // We will use C++ input/output via streams #include <vector> typedef std :: vector < std :: vector < int >> VVI ; int step ( int i , int j , std :: vector < int >& v , VVI & S ){ if ( i == j ) return v [ i ]; if ( i > j ) return 0 ; if ( S [ i ][ j ] == -1 ){ S [ i ][ j ] = std :: max ( std :: min ( step ( i + 1 + 1 , j , v , S ), step ( i + 1 , j -1 , v , S ) ) + v [ i ], std :: min ( step ( i , j -1-1 , v , S ), step ( i + 1 , j -1 , v , S ) ) + v [ j ] ); } return S [ i ][ j ]; } void testcase () { int n ; std :: cin >> n ; // Read the number of integers to follow std :: vector < int > values ( n ); for ( int i = 0 ; i < n ; ++ i ){ int v_i ; std :: cin >> v_i ; values [ i ] = v_i ; } // storage VVI S ( n , std :: vector < int > ( n , -1 )); // dynamic program std :: cout << step ( 0 , n -1 , values , S ) << std :: endl ; } int main () { std :: ios_base :: sync_with_stdio ( false ); // Always! int t ; std :: cin >> t ; for ( int i = 0 ; i < t ; ++ i ) testcase (); // Solve a particular test case } The Great Game Problem Difficulties Techniques Solution Beach Bars Problem Difficulties Special cases (e.g. location can be negative) Techniques Sliding window, data structures - use set for storing optimal locations Solution 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 #include <iostream> // We will use C++ input/output via streams #include <vector> #include <limits> #include <cmath> #include <algorithm> #include <set> void testcase () { int n ; std :: cin >> n ; // Read the number of integers to follow std :: vector < int > coords ( n ); for ( int i = 0 ; i < n ; ++ i ){ std :: cin >> coords [ i ]; } std :: sort ( coords . begin (), coords . end ()); // sliding window int max_parasols = 0 ; int min_longest_distance = std :: numeric_limits < int >:: max (); int i = 0 , j = 0 ; std :: set < int > optimal_locations ; while ( j < n ){ if ( coords [ j ] - coords [ i ] <= 2 * 100 ){ int num_parasols = j - i + 1 ; int location = ( int ) std :: floor ((( double ) coords [ j ] + ( double ) coords [ i ]) / 2.0 ); int max_distance = std :: max ( coords [ j ] - location , location - coords [ i ]); bool update = false , only_insert = false ; if ( num_parasols > max_parasols ) update = true ; else if ( num_parasols == max_parasols ){ if ( max_distance < min_longest_distance ) update = true ; else if ( max_distance == min_longest_distance ) only_insert = true ; } if ( update ){ max_parasols = num_parasols ; min_longest_distance = max_distance ; optimal_locations . clear (); } if ( update or only_insert ){ optimal_locations . insert ( location ); if (( coords [ j ] - coords [ i ]) % 2 != 0 ){ optimal_locations . insert ( location + 1 ); } } j ++ ; } else { if ( i < j ){ i ++ ; } else { j ++ ; } } } std :: cout << max_parasols << \" \" << min_longest_distance << std :: endl ; for ( int ele : optimal_locations ) std :: cout << ele << \" \" ; std :: cout << std :: endl ; } int main () { std :: ios_base :: sync_with_stdio ( false ); // Always! int t ; std :: cin >> t ; for ( int i = 0 ; i < t ; ++ i ) testcase (); // Solve a particular test case } Search Snippets Problem single, contiguous, shortest possible (measured in the number of words contained) snippet that contains all the search terms. Difficulties using priority queue (changing compare operator) Techniques Sliding window, data structure - Priority queue for storing the current word locations in range Solution 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 #include <iostream> // We will use C++ input/output via streams #include <vector> #include <limits> #include <queue> typedef std :: vector < std :: vector < int >> VVI ; void testcase () { int n ; std :: cin >> n ; // Read the number of integers to follow std :: vector < int > m ( n ); int m_max = 0 ; for ( int i = 0 ; i < n ; ++ i ){ std :: cin >> m [ i ]; m_max = m [ i ] > m_max ? m [ i ] : m_max ; } VVI p ( n , std :: vector < int > ( m_max , -1 )); for ( int i = 0 ; i < n ; ++ i ){ for ( int j = 0 ; j < m [ i ]; ++ j ) std :: cin >> p [ i ][ j ]; } // sliding window with priority queue std :: priority_queue < std :: pair < int , int > , std :: vector < std :: pair < int , int >> , std :: greater < std :: pair < int , int >>> q ; int range_start = 0 , range_end = 0 ; for ( int i = 0 ; i < n ; ++ i ){ q . push ( std :: make_pair ( p [ i ][ 0 ], i )); if ( p [ i ][ 0 ] > range_end ) range_end = p [ i ][ 0 ]; } std :: vector < int > locs ( n , 0 ); // store iterations variables int min_range = std :: numeric_limits < int >:: max (); while ( true ){ // get the word at the head of the range auto pair = q . top (); q . pop (); range_start = pair . first ; int idx = pair . second ; int range = range_end - range_start + 1 ; if ( range < min_range ) min_range = range ; // break if this was the last entry of idx locs [ idx ] ++ ; if ( locs [ idx ] == m [ idx ]) break ; // update range_end if ( p [ idx ][ locs [ idx ]] > range_end ) range_end = p [ idx ][ locs [ idx ]]; // insert new position for idx q . push ( std :: make_pair ( p [ idx ][ locs [ idx ]], idx )); } std :: cout << min_range << std :: endl ; } int main () { std :: ios_base :: sync_with_stdio ( false ); // Always! int t ; std :: cin >> t ; for ( int i = 0 ; i < t ; ++ i ) testcase (); // Solve a particular test case }","title":"week 2"},{"location":"Algorithms%20Lab/exercises/w02/#burning-coins","text":"","title":"Burning Coins"},{"location":"Algorithms%20Lab/exercises/w02/#problem","text":"The goal is to find an optimal policy \\(\\pi^*\\) that maximizes the guaranteed total reward in a deterministic game: \\[ \\pi^* = \\arg \\max_\\pi \\left\\{\\min_{\\pi'} r(\\pi, \\pi') \\right\\}, \\] where \\(r\\) is the total reward by acting according to the deterministic policies \\(\\pi\\) and \\(\\pi'\\) .","title":"Problem"},{"location":"Algorithms%20Lab/exercises/w02/#difficulties","text":"Formulating the mathematical problem.","title":"Difficulties"},{"location":"Algorithms%20Lab/exercises/w02/#techniques","text":"Dynamic program","title":"Techniques"},{"location":"Algorithms%20Lab/exercises/w02/#solution","text":"Let \\(S_{i,j}\\) be the guaranteed total reward in range \\([i,j]\\) and it's the turn of player 1. We can then formulate the dynamic program by exploiting the following recursive relationship: \\[ S_{i,j} = \\max_{(i',j') \\in A_{i,j}} \\left\\{ v(i,j,i',j') + \\min_{(i'',j'') \\in A_{i',j'}} S_{i'',j''} \\right\\} \\] 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 #include <iostream> // We will use C++ input/output via streams #include <vector> typedef std :: vector < std :: vector < int >> VVI ; int step ( int i , int j , std :: vector < int >& v , VVI & S ){ if ( i == j ) return v [ i ]; if ( i > j ) return 0 ; if ( S [ i ][ j ] == -1 ){ S [ i ][ j ] = std :: max ( std :: min ( step ( i + 1 + 1 , j , v , S ), step ( i + 1 , j -1 , v , S ) ) + v [ i ], std :: min ( step ( i , j -1-1 , v , S ), step ( i + 1 , j -1 , v , S ) ) + v [ j ] ); } return S [ i ][ j ]; } void testcase () { int n ; std :: cin >> n ; // Read the number of integers to follow std :: vector < int > values ( n ); for ( int i = 0 ; i < n ; ++ i ){ int v_i ; std :: cin >> v_i ; values [ i ] = v_i ; } // storage VVI S ( n , std :: vector < int > ( n , -1 )); // dynamic program std :: cout << step ( 0 , n -1 , values , S ) << std :: endl ; } int main () { std :: ios_base :: sync_with_stdio ( false ); // Always! int t ; std :: cin >> t ; for ( int i = 0 ; i < t ; ++ i ) testcase (); // Solve a particular test case }","title":"Solution"},{"location":"Algorithms%20Lab/exercises/w02/#the-great-game","text":"","title":"The Great Game"},{"location":"Algorithms%20Lab/exercises/w02/#problem_1","text":"","title":"Problem"},{"location":"Algorithms%20Lab/exercises/w02/#difficulties_1","text":"","title":"Difficulties"},{"location":"Algorithms%20Lab/exercises/w02/#techniques_1","text":"","title":"Techniques"},{"location":"Algorithms%20Lab/exercises/w02/#solution_1","text":"","title":"Solution"},{"location":"Algorithms%20Lab/exercises/w02/#beach-bars","text":"","title":"Beach Bars"},{"location":"Algorithms%20Lab/exercises/w02/#problem_2","text":"","title":"Problem"},{"location":"Algorithms%20Lab/exercises/w02/#difficulties_2","text":"Special cases (e.g. location can be negative)","title":"Difficulties"},{"location":"Algorithms%20Lab/exercises/w02/#techniques_2","text":"Sliding window, data structures - use set for storing optimal locations","title":"Techniques"},{"location":"Algorithms%20Lab/exercises/w02/#solution_2","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 #include <iostream> // We will use C++ input/output via streams #include <vector> #include <limits> #include <cmath> #include <algorithm> #include <set> void testcase () { int n ; std :: cin >> n ; // Read the number of integers to follow std :: vector < int > coords ( n ); for ( int i = 0 ; i < n ; ++ i ){ std :: cin >> coords [ i ]; } std :: sort ( coords . begin (), coords . end ()); // sliding window int max_parasols = 0 ; int min_longest_distance = std :: numeric_limits < int >:: max (); int i = 0 , j = 0 ; std :: set < int > optimal_locations ; while ( j < n ){ if ( coords [ j ] - coords [ i ] <= 2 * 100 ){ int num_parasols = j - i + 1 ; int location = ( int ) std :: floor ((( double ) coords [ j ] + ( double ) coords [ i ]) / 2.0 ); int max_distance = std :: max ( coords [ j ] - location , location - coords [ i ]); bool update = false , only_insert = false ; if ( num_parasols > max_parasols ) update = true ; else if ( num_parasols == max_parasols ){ if ( max_distance < min_longest_distance ) update = true ; else if ( max_distance == min_longest_distance ) only_insert = true ; } if ( update ){ max_parasols = num_parasols ; min_longest_distance = max_distance ; optimal_locations . clear (); } if ( update or only_insert ){ optimal_locations . insert ( location ); if (( coords [ j ] - coords [ i ]) % 2 != 0 ){ optimal_locations . insert ( location + 1 ); } } j ++ ; } else { if ( i < j ){ i ++ ; } else { j ++ ; } } } std :: cout << max_parasols << \" \" << min_longest_distance << std :: endl ; for ( int ele : optimal_locations ) std :: cout << ele << \" \" ; std :: cout << std :: endl ; } int main () { std :: ios_base :: sync_with_stdio ( false ); // Always! int t ; std :: cin >> t ; for ( int i = 0 ; i < t ; ++ i ) testcase (); // Solve a particular test case }","title":"Solution"},{"location":"Algorithms%20Lab/exercises/w02/#search-snippets","text":"","title":"Search Snippets"},{"location":"Algorithms%20Lab/exercises/w02/#problem_3","text":"single, contiguous, shortest possible (measured in the number of words contained) snippet that contains all the search terms.","title":"Problem"},{"location":"Algorithms%20Lab/exercises/w02/#difficulties_3","text":"using priority queue (changing compare operator)","title":"Difficulties"},{"location":"Algorithms%20Lab/exercises/w02/#techniques_3","text":"Sliding window, data structure - Priority queue for storing the current word locations in range","title":"Techniques"},{"location":"Algorithms%20Lab/exercises/w02/#solution_3","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 #include <iostream> // We will use C++ input/output via streams #include <vector> #include <limits> #include <queue> typedef std :: vector < std :: vector < int >> VVI ; void testcase () { int n ; std :: cin >> n ; // Read the number of integers to follow std :: vector < int > m ( n ); int m_max = 0 ; for ( int i = 0 ; i < n ; ++ i ){ std :: cin >> m [ i ]; m_max = m [ i ] > m_max ? m [ i ] : m_max ; } VVI p ( n , std :: vector < int > ( m_max , -1 )); for ( int i = 0 ; i < n ; ++ i ){ for ( int j = 0 ; j < m [ i ]; ++ j ) std :: cin >> p [ i ][ j ]; } // sliding window with priority queue std :: priority_queue < std :: pair < int , int > , std :: vector < std :: pair < int , int >> , std :: greater < std :: pair < int , int >>> q ; int range_start = 0 , range_end = 0 ; for ( int i = 0 ; i < n ; ++ i ){ q . push ( std :: make_pair ( p [ i ][ 0 ], i )); if ( p [ i ][ 0 ] > range_end ) range_end = p [ i ][ 0 ]; } std :: vector < int > locs ( n , 0 ); // store iterations variables int min_range = std :: numeric_limits < int >:: max (); while ( true ){ // get the word at the head of the range auto pair = q . top (); q . pop (); range_start = pair . first ; int idx = pair . second ; int range = range_end - range_start + 1 ; if ( range < min_range ) min_range = range ; // break if this was the last entry of idx locs [ idx ] ++ ; if ( locs [ idx ] == m [ idx ]) break ; // update range_end if ( p [ idx ][ locs [ idx ]] > range_end ) range_end = p [ idx ][ locs [ idx ]]; // insert new position for idx q . push ( std :: make_pair ( p [ idx ][ locs [ idx ]], idx )); } std :: cout << min_range << std :: endl ; } int main () { std :: ios_base :: sync_with_stdio ( false ); // Always! int t ; std :: cin >> t ; for ( int i = 0 ; i < t ; ++ i ) testcase (); // Solve a particular test case }","title":"Solution"},{"location":"Algorithms%20Lab/exercises/w03/","text":"Hit Problem Check whether ray intersect line Difficulties End early to minimize number of intersection tests Techniques CGAL, Exact Constructions, Intersections Solution 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 #include <iostream> // We will use C++ input/output via streams #include <CGAL/Exact_predicates_exact_constructions_kernel.h> typedef CGAL :: Exact_predicates_exact_constructions_kernel K ; typedef K :: Point_2 P ; typedef K :: Segment_2 L ; typedef K :: Ray_2 R ; bool testcase () { int n ; std :: cin >> n ; // Read the number of integers to follow if ( n == 0 ) return false ; long x , y , a , b ; std :: cin >> x >> y >> a >> b ; P p1 ( x , y ); P p2 ( a , b ); R ray ( p1 , p2 ); long r , s , t , u ; bool hit = false ; for ( int i = 0 ; i < n ; ++ i ){ std :: cin >> r >> s >> t >> u ; if ( ! hit ){ p1 = P ( r , s ); p2 = P ( t , u ); L l ( p1 , p2 ); if ( CGAL :: do_intersect ( l , ray )) hit = true ; } } if ( hit ) std :: cout << \"yes\" << std :: endl ; else std :: cout << \"no\" << std :: endl ; return true ; } int main () { std :: ios_base :: sync_with_stdio ( false ); // Always! while ( testcase ()); // Solve a particular test case } First Hit Problem Determine the intersection point at which a ray hits one of \\(n\\) segments first. Difficulties When to use inexact / exact kernel Techniques Clipping, Intersections, CGAL, Exact Kernel Solution From sample solution. Clip the ray to minimize the number of intersection constructions (note that checking for intersection is a predicate operation - finite number of outputs). If we assume that the input data is random, clipping the ray reduces the expected number of constructions to \\(O(\\log n)\\) . To see this, let us define for each iteration \\(i\\) the random variable \\(x_i\\) which is \\(1\\) when segment \\(s_i\\) intersects the clipped ray \\(r_i\\) and \\(0\\) otherwise. \\(x_i\\) is \\(1\\) iff the distance \\(d_i < d_j, \\, j < i\\) . The expected value for this event is \\[E[x_i = 1] = 1 \\cdot p(x_i = 1) = \\frac{i!}{(i+1)!} = \\frac{1}{(i+1)}\\] Therefore, the total expected value for the number of intersection events is: \\[E \\left[\\sum_{i=0}^{n-1}{x_i = 1} \\right] = \\sum_{i=1}^n \\frac{1}{i} = O(\\log n)\\] 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 #include <CGAL/Exact_predicates_exact_constructions_kernel.h> #include <vector> #include <algorithm> #include <type_traits> #include <stdexcept> typedef CGAL :: Exact_predicates_exact_constructions_kernel K ; typedef std :: result_of < K :: Intersect_2 ( K :: Ray_2 , K :: Segment_2 ) >:: type IT ; // round down to next double (as defined in the tutorial) double floor_to_double ( const K :: FT & x ) { double a = std :: floor ( CGAL :: to_double ( x )); while ( a > x ) a -= 1 ; while ( a + 1 <= x ) a += 1 ; return a ; } // clip/set target of s to o void shorten_segment ( K :: Segment_2 & s , const IT & o ) { if ( const K :: Point_2 * p = boost :: get < K :: Point_2 > ( &* o )) s = K :: Segment_2 ( s . source (), * p ); else if ( const K :: Segment_2 * t = boost :: get < K :: Segment_2 > ( &* o )) // select endpoint of *t closer to s.source() if ( CGAL :: collinear_are_ordered_along_line ( s . source (), t -> source (), t -> target ())) s = K :: Segment_2 ( s . source (), t -> source ()); else s = K :: Segment_2 ( s . source (), t -> target ()); else throw std :: runtime_error ( \"Strange segment intersection.\" ); } void find_hit ( std :: size_t n ) { // read input long x1 , y1 , x2 , y2 ; std :: cin >> x1 >> y1 >> x2 >> y2 ; K :: Ray_2 r ( K :: Point_2 ( x1 , y1 ), K :: Point_2 ( x2 , y2 )); std :: vector < K :: Segment_2 > segs ; segs . reserve ( n ); for ( std :: size_t i = 0 ; i < n ; ++ i ) { std :: cin >> x1 >> y1 >> x2 >> y2 ; segs . push_back ( K :: Segment_2 ( K :: Point_2 ( x1 , y1 ), K :: Point_2 ( x2 , y2 ))); } std :: random_shuffle ( segs . begin (), segs . end ()); // clip the ray at each segment hit (cuts down on the number of intersection // points to be constructed: for a uniformly random order of segments, the // expected number of constructions is logarithmic in the number of segments // that intersect the initial ray.) K :: Segment_2 rc ( r . source (), r . point ( 1 )); // find some segment hit by r std :: size_t i = 0 ; for (; i < n ; ++ i ) if ( CGAL :: do_intersect ( segs [ i ], r )) { shorten_segment ( rc , CGAL :: intersection ( segs [ i ], r )); break ; } if ( i == n ) { std :: cout << \"no \\n \" ; return ; } // check remaining segments against rc while ( ++ i < n ) if ( CGAL :: do_intersect ( segs [ i ], rc )) shorten_segment ( rc , CGAL :: intersection ( segs [ i ], r )); // not rc! std :: cout << floor_to_double ( rc . target (). x ()) << \" \" << floor_to_double ( rc . target (). y ()) << \" \\n \" ; } int main () { std :: ios_base :: sync_with_stdio ( false ); std :: cout << std :: setiosflags ( std :: ios :: fixed ) << std :: setprecision ( 0 ); for ( std :: size_t n ; std :: cin >> n && n > 0 ;) find_hit ( n ); } Antenna Problem Find minimum enclosing circle Difficulties Kernel with sqrt too slow (only 90%) Techniques Min_Circle_2, Ceil to double Solution 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 #include <iostream> #include <vector> // CGAL #include <CGAL/Exact_predicates_exact_constructions_kernel_with_sqrt.h> #include <CGAL/Min_circle_2.h> #include <CGAL/Min_circle_2_traits_2.h> typedef CGAL :: Exact_predicates_exact_constructions_kernel_with_sqrt K ; typedef CGAL :: Min_circle_2_traits_2 < K > Traits ; typedef CGAL :: Min_circle_2 < Traits > Min_circle ; template < typename T > double ceil_to_double ( const T & x ) { double a = std :: ceil ( CGAL :: to_double ( x )); while ( a < x ) a += 1 ; while ( a - 1 >= x ) a -= 1 ; return a ; } void antenna ( std :: size_t n ) { std :: vector < K :: Point_2 > points ; points . reserve ( n ); long x , y ; for ( std :: size_t i = 0 ; i < n ; ++ i ){ std :: cin >> x >> y ; points . push_back ( K :: Point_2 ( x , y )); } Min_circle mc ( points . begin (), points . end (), true ); Traits :: Circle c = mc . circle (); std :: cout << ceil_to_double ( CGAL :: sqrt ( c . squared_radius ())) << std :: endl ; } int main () { std :: ios_base :: sync_with_stdio ( false ); std :: cout << std :: setiosflags ( std :: ios :: fixed ) << std :: setprecision ( 0 ); for ( std :: size_t n ; std :: cin >> n && n > 0 ;) antenna ( n ); } Hiking Maps Problem Find consecutive range of maps that cover all hikes. Difficulties Instead of in-triangle tests we can also use right and left turn predicate operations Techniques Sliding window, Finding the correct kernel Solution 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 // // Created by Krispin Wandel on 05.01.21. // #include <iostream> #include <vector> #include <set> // CGAL #include <CGAL/Exact_predicates_inexact_constructions_kernel.h> typedef CGAL :: Exact_predicates_inexact_constructions_kernel K ; // ====== From solution ====== // does triangle t contain point p? inline bool contains ( const std :: vector < K :: Point_2 > & t , const K :: Point_2 & p ) { return ! CGAL :: right_turn ( t [ 0 ], t [ 1 ], p ) && ! CGAL :: right_turn ( t [ 2 ], t [ 3 ], p ) && ! CGAL :: right_turn ( t [ 4 ], t [ 5 ], p ); } // =========================== void testcase () { // m - 1 = number of legs, n = number of maps size_t m , n ; std :: cin >> m >> n ; std :: vector < K :: Point_2 > points ; points . reserve ( m ); for ( size_t i = 0 ; i < m ; i ++ ) { int x , y ; std :: cin >> x >> y ; points . emplace_back ( K :: Point_2 ( x , y )); } std :: vector < std :: vector < int >> S ( n + 1 , std :: vector < int > ( m - 1 , 0 )); for ( size_t i = 1 ; i < n + 1 ; i ++ ) { // construct edges std :: vector < K :: Point_2 > t ; t . reserve ( 6 ); for ( size_t j = 0 ; j < 6 ; j ++ ) { int x , y ; std :: cin >> x >> y ; t . emplace_back ( K :: Point_2 ( x , y )); } // ====== From solution ====== // ensure correct (ccw) order for orientation tests for ( std :: size_t j = 0 ; j < 6 ; j += 2 ) if ( CGAL :: right_turn ( t [ j ], t [ j + 1 ], t [( j + 2 ) % 6 ])) std :: swap ( t [ j ], t [ j + 1 ]); // =========================== // check which points intersect with triangle i std :: vector < bool > inter ( m - 1 , false ); for ( int j = 0 ; j < m ; ++ j ) if ( contains ( t , points [ j ])) inter [ j ] = true ; // precompute partial sums // NOTE each leg is completely contained inside one or multiple triangles for ( size_t j = 0 ; j < m - 1 ; ++ j ) { S [ i ][ j ] += S [ i - 1 ][ j ]; // check whether leg j is contained in triangle i if ( inter [ j ] && inter [ j + 1 ]) S [ i ][ j ] += 1 ; } } // sliding window to find optimal begin b and end e std :: size_t b = 1 , e = 1 ; size_t min_range_size = std :: numeric_limits < int >:: max (); while ( e < n + 1 ) { // check if all legs are contained in maps b to e bool all_legs_are_contained = true ; // TODO could be speed up by only iterating over legs that are covered by new/removed triangle for ( int j = 0 ; j < m - 1 ; ++ j ) { if ( S [ e ][ j ] - S [ b - 1 ][ j ] == 0 ) { all_legs_are_contained = false ; break ; } } // advanced b and e if ( all_legs_are_contained ) { if ( e - b + 1 < min_range_size ) min_range_size = e - b + 1 ; b ++ ; if ( b > e ) e ++ ; } else e ++ ; } std :: cout << min_range_size << std :: endl ; } int main () { std :: ios_base :: sync_with_stdio ( false ); std :: cout << std :: setiosflags ( std :: ios :: fixed ) << std :: setprecision ( 0 ); std :: size_t c ; std :: cin >> c ; for ( int i = 0 ; i < c ; ++ i ) testcase (); }","title":"week 3"},{"location":"Algorithms%20Lab/exercises/w03/#hit","text":"","title":"Hit"},{"location":"Algorithms%20Lab/exercises/w03/#problem","text":"Check whether ray intersect line","title":"Problem"},{"location":"Algorithms%20Lab/exercises/w03/#difficulties","text":"End early to minimize number of intersection tests","title":"Difficulties"},{"location":"Algorithms%20Lab/exercises/w03/#techniques","text":"CGAL, Exact Constructions, Intersections","title":"Techniques"},{"location":"Algorithms%20Lab/exercises/w03/#solution","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 #include <iostream> // We will use C++ input/output via streams #include <CGAL/Exact_predicates_exact_constructions_kernel.h> typedef CGAL :: Exact_predicates_exact_constructions_kernel K ; typedef K :: Point_2 P ; typedef K :: Segment_2 L ; typedef K :: Ray_2 R ; bool testcase () { int n ; std :: cin >> n ; // Read the number of integers to follow if ( n == 0 ) return false ; long x , y , a , b ; std :: cin >> x >> y >> a >> b ; P p1 ( x , y ); P p2 ( a , b ); R ray ( p1 , p2 ); long r , s , t , u ; bool hit = false ; for ( int i = 0 ; i < n ; ++ i ){ std :: cin >> r >> s >> t >> u ; if ( ! hit ){ p1 = P ( r , s ); p2 = P ( t , u ); L l ( p1 , p2 ); if ( CGAL :: do_intersect ( l , ray )) hit = true ; } } if ( hit ) std :: cout << \"yes\" << std :: endl ; else std :: cout << \"no\" << std :: endl ; return true ; } int main () { std :: ios_base :: sync_with_stdio ( false ); // Always! while ( testcase ()); // Solve a particular test case }","title":"Solution"},{"location":"Algorithms%20Lab/exercises/w03/#first-hit","text":"","title":"First Hit"},{"location":"Algorithms%20Lab/exercises/w03/#problem_1","text":"Determine the intersection point at which a ray hits one of \\(n\\) segments first.","title":"Problem"},{"location":"Algorithms%20Lab/exercises/w03/#difficulties_1","text":"When to use inexact / exact kernel","title":"Difficulties"},{"location":"Algorithms%20Lab/exercises/w03/#techniques_1","text":"Clipping, Intersections, CGAL, Exact Kernel","title":"Techniques"},{"location":"Algorithms%20Lab/exercises/w03/#solution_1","text":"From sample solution. Clip the ray to minimize the number of intersection constructions (note that checking for intersection is a predicate operation - finite number of outputs). If we assume that the input data is random, clipping the ray reduces the expected number of constructions to \\(O(\\log n)\\) . To see this, let us define for each iteration \\(i\\) the random variable \\(x_i\\) which is \\(1\\) when segment \\(s_i\\) intersects the clipped ray \\(r_i\\) and \\(0\\) otherwise. \\(x_i\\) is \\(1\\) iff the distance \\(d_i < d_j, \\, j < i\\) . The expected value for this event is \\[E[x_i = 1] = 1 \\cdot p(x_i = 1) = \\frac{i!}{(i+1)!} = \\frac{1}{(i+1)}\\] Therefore, the total expected value for the number of intersection events is: \\[E \\left[\\sum_{i=0}^{n-1}{x_i = 1} \\right] = \\sum_{i=1}^n \\frac{1}{i} = O(\\log n)\\] 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 #include <CGAL/Exact_predicates_exact_constructions_kernel.h> #include <vector> #include <algorithm> #include <type_traits> #include <stdexcept> typedef CGAL :: Exact_predicates_exact_constructions_kernel K ; typedef std :: result_of < K :: Intersect_2 ( K :: Ray_2 , K :: Segment_2 ) >:: type IT ; // round down to next double (as defined in the tutorial) double floor_to_double ( const K :: FT & x ) { double a = std :: floor ( CGAL :: to_double ( x )); while ( a > x ) a -= 1 ; while ( a + 1 <= x ) a += 1 ; return a ; } // clip/set target of s to o void shorten_segment ( K :: Segment_2 & s , const IT & o ) { if ( const K :: Point_2 * p = boost :: get < K :: Point_2 > ( &* o )) s = K :: Segment_2 ( s . source (), * p ); else if ( const K :: Segment_2 * t = boost :: get < K :: Segment_2 > ( &* o )) // select endpoint of *t closer to s.source() if ( CGAL :: collinear_are_ordered_along_line ( s . source (), t -> source (), t -> target ())) s = K :: Segment_2 ( s . source (), t -> source ()); else s = K :: Segment_2 ( s . source (), t -> target ()); else throw std :: runtime_error ( \"Strange segment intersection.\" ); } void find_hit ( std :: size_t n ) { // read input long x1 , y1 , x2 , y2 ; std :: cin >> x1 >> y1 >> x2 >> y2 ; K :: Ray_2 r ( K :: Point_2 ( x1 , y1 ), K :: Point_2 ( x2 , y2 )); std :: vector < K :: Segment_2 > segs ; segs . reserve ( n ); for ( std :: size_t i = 0 ; i < n ; ++ i ) { std :: cin >> x1 >> y1 >> x2 >> y2 ; segs . push_back ( K :: Segment_2 ( K :: Point_2 ( x1 , y1 ), K :: Point_2 ( x2 , y2 ))); } std :: random_shuffle ( segs . begin (), segs . end ()); // clip the ray at each segment hit (cuts down on the number of intersection // points to be constructed: for a uniformly random order of segments, the // expected number of constructions is logarithmic in the number of segments // that intersect the initial ray.) K :: Segment_2 rc ( r . source (), r . point ( 1 )); // find some segment hit by r std :: size_t i = 0 ; for (; i < n ; ++ i ) if ( CGAL :: do_intersect ( segs [ i ], r )) { shorten_segment ( rc , CGAL :: intersection ( segs [ i ], r )); break ; } if ( i == n ) { std :: cout << \"no \\n \" ; return ; } // check remaining segments against rc while ( ++ i < n ) if ( CGAL :: do_intersect ( segs [ i ], rc )) shorten_segment ( rc , CGAL :: intersection ( segs [ i ], r )); // not rc! std :: cout << floor_to_double ( rc . target (). x ()) << \" \" << floor_to_double ( rc . target (). y ()) << \" \\n \" ; } int main () { std :: ios_base :: sync_with_stdio ( false ); std :: cout << std :: setiosflags ( std :: ios :: fixed ) << std :: setprecision ( 0 ); for ( std :: size_t n ; std :: cin >> n && n > 0 ;) find_hit ( n ); }","title":"Solution"},{"location":"Algorithms%20Lab/exercises/w03/#antenna","text":"","title":"Antenna"},{"location":"Algorithms%20Lab/exercises/w03/#problem_2","text":"Find minimum enclosing circle","title":"Problem"},{"location":"Algorithms%20Lab/exercises/w03/#difficulties_2","text":"Kernel with sqrt too slow (only 90%)","title":"Difficulties"},{"location":"Algorithms%20Lab/exercises/w03/#techniques_2","text":"Min_Circle_2, Ceil to double","title":"Techniques"},{"location":"Algorithms%20Lab/exercises/w03/#solution_2","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 #include <iostream> #include <vector> // CGAL #include <CGAL/Exact_predicates_exact_constructions_kernel_with_sqrt.h> #include <CGAL/Min_circle_2.h> #include <CGAL/Min_circle_2_traits_2.h> typedef CGAL :: Exact_predicates_exact_constructions_kernel_with_sqrt K ; typedef CGAL :: Min_circle_2_traits_2 < K > Traits ; typedef CGAL :: Min_circle_2 < Traits > Min_circle ; template < typename T > double ceil_to_double ( const T & x ) { double a = std :: ceil ( CGAL :: to_double ( x )); while ( a < x ) a += 1 ; while ( a - 1 >= x ) a -= 1 ; return a ; } void antenna ( std :: size_t n ) { std :: vector < K :: Point_2 > points ; points . reserve ( n ); long x , y ; for ( std :: size_t i = 0 ; i < n ; ++ i ){ std :: cin >> x >> y ; points . push_back ( K :: Point_2 ( x , y )); } Min_circle mc ( points . begin (), points . end (), true ); Traits :: Circle c = mc . circle (); std :: cout << ceil_to_double ( CGAL :: sqrt ( c . squared_radius ())) << std :: endl ; } int main () { std :: ios_base :: sync_with_stdio ( false ); std :: cout << std :: setiosflags ( std :: ios :: fixed ) << std :: setprecision ( 0 ); for ( std :: size_t n ; std :: cin >> n && n > 0 ;) antenna ( n ); }","title":"Solution"},{"location":"Algorithms%20Lab/exercises/w03/#hiking-maps","text":"","title":"Hiking Maps"},{"location":"Algorithms%20Lab/exercises/w03/#problem_3","text":"Find consecutive range of maps that cover all hikes.","title":"Problem"},{"location":"Algorithms%20Lab/exercises/w03/#difficulties_3","text":"Instead of in-triangle tests we can also use right and left turn predicate operations","title":"Difficulties"},{"location":"Algorithms%20Lab/exercises/w03/#techniques_3","text":"Sliding window, Finding the correct kernel","title":"Techniques"},{"location":"Algorithms%20Lab/exercises/w03/#solution_3","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 // // Created by Krispin Wandel on 05.01.21. // #include <iostream> #include <vector> #include <set> // CGAL #include <CGAL/Exact_predicates_inexact_constructions_kernel.h> typedef CGAL :: Exact_predicates_inexact_constructions_kernel K ; // ====== From solution ====== // does triangle t contain point p? inline bool contains ( const std :: vector < K :: Point_2 > & t , const K :: Point_2 & p ) { return ! CGAL :: right_turn ( t [ 0 ], t [ 1 ], p ) && ! CGAL :: right_turn ( t [ 2 ], t [ 3 ], p ) && ! CGAL :: right_turn ( t [ 4 ], t [ 5 ], p ); } // =========================== void testcase () { // m - 1 = number of legs, n = number of maps size_t m , n ; std :: cin >> m >> n ; std :: vector < K :: Point_2 > points ; points . reserve ( m ); for ( size_t i = 0 ; i < m ; i ++ ) { int x , y ; std :: cin >> x >> y ; points . emplace_back ( K :: Point_2 ( x , y )); } std :: vector < std :: vector < int >> S ( n + 1 , std :: vector < int > ( m - 1 , 0 )); for ( size_t i = 1 ; i < n + 1 ; i ++ ) { // construct edges std :: vector < K :: Point_2 > t ; t . reserve ( 6 ); for ( size_t j = 0 ; j < 6 ; j ++ ) { int x , y ; std :: cin >> x >> y ; t . emplace_back ( K :: Point_2 ( x , y )); } // ====== From solution ====== // ensure correct (ccw) order for orientation tests for ( std :: size_t j = 0 ; j < 6 ; j += 2 ) if ( CGAL :: right_turn ( t [ j ], t [ j + 1 ], t [( j + 2 ) % 6 ])) std :: swap ( t [ j ], t [ j + 1 ]); // =========================== // check which points intersect with triangle i std :: vector < bool > inter ( m - 1 , false ); for ( int j = 0 ; j < m ; ++ j ) if ( contains ( t , points [ j ])) inter [ j ] = true ; // precompute partial sums // NOTE each leg is completely contained inside one or multiple triangles for ( size_t j = 0 ; j < m - 1 ; ++ j ) { S [ i ][ j ] += S [ i - 1 ][ j ]; // check whether leg j is contained in triangle i if ( inter [ j ] && inter [ j + 1 ]) S [ i ][ j ] += 1 ; } } // sliding window to find optimal begin b and end e std :: size_t b = 1 , e = 1 ; size_t min_range_size = std :: numeric_limits < int >:: max (); while ( e < n + 1 ) { // check if all legs are contained in maps b to e bool all_legs_are_contained = true ; // TODO could be speed up by only iterating over legs that are covered by new/removed triangle for ( int j = 0 ; j < m - 1 ; ++ j ) { if ( S [ e ][ j ] - S [ b - 1 ][ j ] == 0 ) { all_legs_are_contained = false ; break ; } } // advanced b and e if ( all_legs_are_contained ) { if ( e - b + 1 < min_range_size ) min_range_size = e - b + 1 ; b ++ ; if ( b > e ) e ++ ; } else e ++ ; } std :: cout << min_range_size << std :: endl ; } int main () { std :: ios_base :: sync_with_stdio ( false ); std :: cout << std :: setiosflags ( std :: ios :: fixed ) << std :: setprecision ( 0 ); std :: size_t c ; std :: cin >> c ; for ( int i = 0 ; i < c ; ++ i ) testcase (); }","title":"Solution"},{"location":"Algorithms%20Lab/exercises/w04/","text":"First Steps Problem Sum of minimum spanning tree and maximum distance from source. Difficulties Techniques Minimum Spanning Tree algrithm, Dijkstra Shortest Path Solution 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 #include <boost/graph/adjacency_list.hpp> #include <boost/graph/kruskal_min_spanning_tree.hpp> #include <boost/graph/dijkstra_shortest_paths.hpp> #include <iostream> #include <vector> #include <algorithm> typedef boost :: adjacency_list < boost :: vecS , boost :: vecS , boost :: undirectedS , // vertex property boost :: no_property , // edge property boost :: property < boost :: edge_weight_t , int >> graph ; typedef boost :: graph_traits < graph >:: edge_descriptor edge_desc ; typedef boost :: property_map < graph , boost :: edge_weight_t >:: type weight_map ; using namespace std ; void testcase () { int n , m ; cin >> n >> m ; // build weighted undirected graph graph G ( n ); weight_map weights = boost :: get ( boost :: edge_weight , G ); for ( int i = 0 ; i < m ; ++ i ) { int a , b ; cin >> a >> b ; int w ; cin >> w ; auto e = boost :: add_edge ( a , b , G ). first ; weights [ e ] = w ; } // minimum spanning tree std :: vector < edge_desc > mst ; // vector to store MST edges (not a property map!) boost :: kruskal_minimum_spanning_tree ( G , std :: back_inserter ( mst )); int sum = 0 ; for ( auto it : mst ) { sum += boost :: get ( boost :: edge_weight , G , it ); } cout << sum << \" \" ; // maximum distance from node 0 std :: vector < int > dist_map ( n ); boost :: dijkstra_shortest_paths ( G , 0 , boost :: distance_map ( boost :: make_iterator_property_map ( dist_map . begin (), boost :: get ( boost :: vertex_index , G )))); cout << * std :: max_element ( dist_map . begin (), dist_map . end ()) << endl ; } int main () { ios_base :: sync_with_stdio ( false ); int t ; cin >> t ; for ( int i = 0 ; i < t ; ++ i ) { testcase (); } } Ant Challenge Problem Find shortest path from a to b using a network of different minimum spanning trees. Difficulties Identify equivalence between minimum spanning tree algorithms Techniques Minimum Spanning Tree algrithm, Dijkstra Shortest Path Solution 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 // STL includes #include <iostream> #include <vector> // BGL includes #include <boost/graph/adjacency_list.hpp> #include <boost/graph/dijkstra_shortest_paths.hpp> #include <boost/graph/kruskal_min_spanning_tree.hpp> typedef boost :: adjacency_list < boost :: vecS , boost :: vecS , boost :: undirectedS , boost :: no_property , boost :: property < boost :: edge_weight_t , int > > weighted_graph ; typedef boost :: property_map < weighted_graph , boost :: edge_weight_t >:: type weight_map ; typedef boost :: graph_traits < weighted_graph >:: edge_descriptor edge_desc ; typedef boost :: graph_traits < weighted_graph >:: vertex_descriptor vertex_desc ; using namespace std ; int dijkstra_dist ( const weighted_graph & G , int s , int t ) { int n = boost :: num_vertices ( G ); std :: vector < int > dist_map ( n ); boost :: dijkstra_shortest_paths ( G , s , boost :: distance_map ( boost :: make_iterator_property_map ( dist_map . begin (), boost :: get ( boost :: vertex_index , G )))); return dist_map [ t ]; } void testcase () { int n , e , s , a , b ; /* * n = #trees * e = #edges * s = #species * a & b = start & finish tree * */ cin >> n >> e >> s >> a >> b ; vector < weighted_graph > gs ( s , weighted_graph ( n )); vector < weight_map > ws ; gs . reserve ( s ); ws . reserve ( s ); for ( int i = 0 ; i < s ; ++ i ) { ws . emplace_back ( boost :: get ( boost :: edge_weight , gs [ i ])); } for ( int i = 0 ; i < e ; ++ i ) { int t1 , t2 ; cin >> t1 >> t2 ; edge_desc ed ; for ( int j = 0 ; j < s ; ++ j ) { int w ; cin >> w ; ed = boost :: add_edge ( t1 , t2 , gs [ j ]). first ; ws [ j ][ ed ] = w ; } } // TODO why do we need hives? vector < int > hives ( s ); for ( int i = 0 ; i < s ; ++ i ) { cin >> hives [ i ]; } // create private network // => minimum spanning tree weighted_graph g ( n ); weight_map w = boost :: get ( boost :: edge_weight , g ); for ( int i = 0 ; i < s ; ++ i ) { std :: vector < edge_desc > mst ; // vector to store MST edges (not a property map!) boost :: kruskal_minimum_spanning_tree ( gs [ i ], std :: back_inserter ( mst )); edge_desc ed ; for ( auto it : mst ) { int v1 = boost :: source ( it , gs [ i ]); int v2 = boost :: target ( it , gs [ i ]); int weight = boost :: get ( boost :: edge_weight , gs [ i ], boost :: edge ( v1 , v2 , gs [ i ]). first ); ed = boost :: add_edge ( v1 , v2 , g ). first ; w [ ed ] = weight ; } } // dijkstra to find shortest path int dist = dijkstra_dist ( g , a , b ); std :: cout << dist << std :: endl ; } int main () { int t ; cin >> t ; while ( t -- ) testcase (); return 0 ; } -- Problem Difficulties Techniques Solution -- Problem Difficulties Techniques Solution","title":"week 4"},{"location":"Algorithms%20Lab/exercises/w04/#first-steps","text":"","title":"First Steps"},{"location":"Algorithms%20Lab/exercises/w04/#problem","text":"Sum of minimum spanning tree and maximum distance from source.","title":"Problem"},{"location":"Algorithms%20Lab/exercises/w04/#difficulties","text":"","title":"Difficulties"},{"location":"Algorithms%20Lab/exercises/w04/#techniques","text":"Minimum Spanning Tree algrithm, Dijkstra Shortest Path","title":"Techniques"},{"location":"Algorithms%20Lab/exercises/w04/#solution","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 #include <boost/graph/adjacency_list.hpp> #include <boost/graph/kruskal_min_spanning_tree.hpp> #include <boost/graph/dijkstra_shortest_paths.hpp> #include <iostream> #include <vector> #include <algorithm> typedef boost :: adjacency_list < boost :: vecS , boost :: vecS , boost :: undirectedS , // vertex property boost :: no_property , // edge property boost :: property < boost :: edge_weight_t , int >> graph ; typedef boost :: graph_traits < graph >:: edge_descriptor edge_desc ; typedef boost :: property_map < graph , boost :: edge_weight_t >:: type weight_map ; using namespace std ; void testcase () { int n , m ; cin >> n >> m ; // build weighted undirected graph graph G ( n ); weight_map weights = boost :: get ( boost :: edge_weight , G ); for ( int i = 0 ; i < m ; ++ i ) { int a , b ; cin >> a >> b ; int w ; cin >> w ; auto e = boost :: add_edge ( a , b , G ). first ; weights [ e ] = w ; } // minimum spanning tree std :: vector < edge_desc > mst ; // vector to store MST edges (not a property map!) boost :: kruskal_minimum_spanning_tree ( G , std :: back_inserter ( mst )); int sum = 0 ; for ( auto it : mst ) { sum += boost :: get ( boost :: edge_weight , G , it ); } cout << sum << \" \" ; // maximum distance from node 0 std :: vector < int > dist_map ( n ); boost :: dijkstra_shortest_paths ( G , 0 , boost :: distance_map ( boost :: make_iterator_property_map ( dist_map . begin (), boost :: get ( boost :: vertex_index , G )))); cout << * std :: max_element ( dist_map . begin (), dist_map . end ()) << endl ; } int main () { ios_base :: sync_with_stdio ( false ); int t ; cin >> t ; for ( int i = 0 ; i < t ; ++ i ) { testcase (); } }","title":"Solution"},{"location":"Algorithms%20Lab/exercises/w04/#ant-challenge","text":"","title":"Ant Challenge"},{"location":"Algorithms%20Lab/exercises/w04/#problem_1","text":"Find shortest path from a to b using a network of different minimum spanning trees.","title":"Problem"},{"location":"Algorithms%20Lab/exercises/w04/#difficulties_1","text":"Identify equivalence between minimum spanning tree algorithms","title":"Difficulties"},{"location":"Algorithms%20Lab/exercises/w04/#techniques_1","text":"Minimum Spanning Tree algrithm, Dijkstra Shortest Path","title":"Techniques"},{"location":"Algorithms%20Lab/exercises/w04/#solution_1","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 // STL includes #include <iostream> #include <vector> // BGL includes #include <boost/graph/adjacency_list.hpp> #include <boost/graph/dijkstra_shortest_paths.hpp> #include <boost/graph/kruskal_min_spanning_tree.hpp> typedef boost :: adjacency_list < boost :: vecS , boost :: vecS , boost :: undirectedS , boost :: no_property , boost :: property < boost :: edge_weight_t , int > > weighted_graph ; typedef boost :: property_map < weighted_graph , boost :: edge_weight_t >:: type weight_map ; typedef boost :: graph_traits < weighted_graph >:: edge_descriptor edge_desc ; typedef boost :: graph_traits < weighted_graph >:: vertex_descriptor vertex_desc ; using namespace std ; int dijkstra_dist ( const weighted_graph & G , int s , int t ) { int n = boost :: num_vertices ( G ); std :: vector < int > dist_map ( n ); boost :: dijkstra_shortest_paths ( G , s , boost :: distance_map ( boost :: make_iterator_property_map ( dist_map . begin (), boost :: get ( boost :: vertex_index , G )))); return dist_map [ t ]; } void testcase () { int n , e , s , a , b ; /* * n = #trees * e = #edges * s = #species * a & b = start & finish tree * */ cin >> n >> e >> s >> a >> b ; vector < weighted_graph > gs ( s , weighted_graph ( n )); vector < weight_map > ws ; gs . reserve ( s ); ws . reserve ( s ); for ( int i = 0 ; i < s ; ++ i ) { ws . emplace_back ( boost :: get ( boost :: edge_weight , gs [ i ])); } for ( int i = 0 ; i < e ; ++ i ) { int t1 , t2 ; cin >> t1 >> t2 ; edge_desc ed ; for ( int j = 0 ; j < s ; ++ j ) { int w ; cin >> w ; ed = boost :: add_edge ( t1 , t2 , gs [ j ]). first ; ws [ j ][ ed ] = w ; } } // TODO why do we need hives? vector < int > hives ( s ); for ( int i = 0 ; i < s ; ++ i ) { cin >> hives [ i ]; } // create private network // => minimum spanning tree weighted_graph g ( n ); weight_map w = boost :: get ( boost :: edge_weight , g ); for ( int i = 0 ; i < s ; ++ i ) { std :: vector < edge_desc > mst ; // vector to store MST edges (not a property map!) boost :: kruskal_minimum_spanning_tree ( gs [ i ], std :: back_inserter ( mst )); edge_desc ed ; for ( auto it : mst ) { int v1 = boost :: source ( it , gs [ i ]); int v2 = boost :: target ( it , gs [ i ]); int weight = boost :: get ( boost :: edge_weight , gs [ i ], boost :: edge ( v1 , v2 , gs [ i ]). first ); ed = boost :: add_edge ( v1 , v2 , g ). first ; w [ ed ] = weight ; } } // dijkstra to find shortest path int dist = dijkstra_dist ( g , a , b ); std :: cout << dist << std :: endl ; } int main () { int t ; cin >> t ; while ( t -- ) testcase (); return 0 ; }","title":"Solution"},{"location":"Algorithms%20Lab/exercises/w04/#-","text":"","title":"--"},{"location":"Algorithms%20Lab/exercises/w04/#problem_2","text":"","title":"Problem"},{"location":"Algorithms%20Lab/exercises/w04/#difficulties_2","text":"","title":"Difficulties"},{"location":"Algorithms%20Lab/exercises/w04/#techniques_2","text":"","title":"Techniques"},{"location":"Algorithms%20Lab/exercises/w04/#solution_2","text":"","title":"Solution"},{"location":"Algorithms%20Lab/exercises/w04/#-_1","text":"","title":"--"},{"location":"Algorithms%20Lab/exercises/w04/#problem_3","text":"","title":"Problem"},{"location":"Algorithms%20Lab/exercises/w04/#difficulties_3","text":"","title":"Difficulties"},{"location":"Algorithms%20Lab/exercises/w04/#techniques_3","text":"","title":"Techniques"},{"location":"Algorithms%20Lab/exercises/w04/#solution_3","text":"","title":"Solution"},{"location":"Algorithms%20Lab/exercises/w05/","text":"Boats Problem Difficulties Techniques Greedy, Stay Ahead argument Solution 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 #include <iostream> #include <vector> #include <limits> #include <algorithm> using namespace std ; void testcase () { int n ; cin >> n ; int end_prev_prev = std :: numeric_limits < int >:: min (); int end_prev = std :: numeric_limits < int >:: min (); int num_ships = 0 ; vector < pair < int , int >> pl ; // position and length pl . reserve ( n ); for ( int i = 0 ; i < n ; ++ i ) { int l , p ; cin >> l >> p ; pl . emplace_back ( make_pair ( p , l )); } sort ( pl . begin (), pl . end (), std :: less <> ()); for ( int i = 0 ; i < n ; ++ i ) { int p = pl [ i ]. first ; int l = pl [ i ]. second ; if ( end_prev > p ) { int p_new = end_prev_prev + l > p ? end_prev_prev + l : p ; if ( p_new < end_prev ) { end_prev = p_new ; } } else { num_ships ++ ; int p_new = end_prev + l > p ? end_prev + l : p ; end_prev_prev = end_prev ; end_prev = p_new ; } } cout << num_ships << endl ; } int main () { ios_base :: sync_with_stdio ( false ); int t ; cin >> t ; while ( t -- ) testcase (); } -- Problem Difficulties Techniques Solution -- Problem Difficulties Techniques Solution Asterix the Gaul Problem Knapsack problem Difficulties Look at \\(n\\) ! Techniques Split & List Solution","title":"week 5"},{"location":"Algorithms%20Lab/exercises/w05/#boats","text":"","title":"Boats"},{"location":"Algorithms%20Lab/exercises/w05/#problem","text":"","title":"Problem"},{"location":"Algorithms%20Lab/exercises/w05/#difficulties","text":"","title":"Difficulties"},{"location":"Algorithms%20Lab/exercises/w05/#techniques","text":"Greedy, Stay Ahead argument","title":"Techniques"},{"location":"Algorithms%20Lab/exercises/w05/#solution","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 #include <iostream> #include <vector> #include <limits> #include <algorithm> using namespace std ; void testcase () { int n ; cin >> n ; int end_prev_prev = std :: numeric_limits < int >:: min (); int end_prev = std :: numeric_limits < int >:: min (); int num_ships = 0 ; vector < pair < int , int >> pl ; // position and length pl . reserve ( n ); for ( int i = 0 ; i < n ; ++ i ) { int l , p ; cin >> l >> p ; pl . emplace_back ( make_pair ( p , l )); } sort ( pl . begin (), pl . end (), std :: less <> ()); for ( int i = 0 ; i < n ; ++ i ) { int p = pl [ i ]. first ; int l = pl [ i ]. second ; if ( end_prev > p ) { int p_new = end_prev_prev + l > p ? end_prev_prev + l : p ; if ( p_new < end_prev ) { end_prev = p_new ; } } else { num_ships ++ ; int p_new = end_prev + l > p ? end_prev + l : p ; end_prev_prev = end_prev ; end_prev = p_new ; } } cout << num_ships << endl ; } int main () { ios_base :: sync_with_stdio ( false ); int t ; cin >> t ; while ( t -- ) testcase (); }","title":"Solution"},{"location":"Algorithms%20Lab/exercises/w05/#-","text":"","title":"--"},{"location":"Algorithms%20Lab/exercises/w05/#problem_1","text":"","title":"Problem"},{"location":"Algorithms%20Lab/exercises/w05/#difficulties_1","text":"","title":"Difficulties"},{"location":"Algorithms%20Lab/exercises/w05/#techniques_1","text":"","title":"Techniques"},{"location":"Algorithms%20Lab/exercises/w05/#solution_1","text":"","title":"Solution"},{"location":"Algorithms%20Lab/exercises/w05/#-_1","text":"","title":"--"},{"location":"Algorithms%20Lab/exercises/w05/#problem_2","text":"","title":"Problem"},{"location":"Algorithms%20Lab/exercises/w05/#difficulties_2","text":"","title":"Difficulties"},{"location":"Algorithms%20Lab/exercises/w05/#techniques_2","text":"","title":"Techniques"},{"location":"Algorithms%20Lab/exercises/w05/#solution_2","text":"","title":"Solution"},{"location":"Algorithms%20Lab/exercises/w05/#asterix-the-gaul","text":"","title":"Asterix the Gaul"},{"location":"Algorithms%20Lab/exercises/w05/#problem_3","text":"Knapsack problem","title":"Problem"},{"location":"Algorithms%20Lab/exercises/w05/#difficulties_3","text":"Look at \\(n\\) !","title":"Difficulties"},{"location":"Algorithms%20Lab/exercises/w05/#techniques_3","text":"Split & List","title":"Techniques"},{"location":"Algorithms%20Lab/exercises/w05/#solution_3","text":"","title":"Solution"},{"location":"Algorithms%20Lab/exercises/w07/","text":"Maximize Problem Difficulties Techniques Solution Diet Problem Difficulties Techniques Solution Inball Problem Find radius of largest ball that fits into a \\(p\\) dimensional polyhedron Difficulties Don't forget to set lower bounds. Changing problem into a LP. Techniques Linear Programming, Linear Algebra Solution 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 #include <iostream> #include <vector> #include <CGAL/QP_models.h> #include <CGAL/QP_functions.h> #include <CGAL/Gmpz.h> // choose input type (input coefficients must fit) typedef int IT ; // choose exact type for solver (CGAL::Gmpz or CGAL::Gmpq) typedef CGAL :: Gmpz ET ; // program and solution types typedef CGAL :: Quadratic_program < IT > Program ; typedef CGAL :: Quadratic_program_solution < ET > Solution ; using namespace std ; bool testcase () { int n ; // number of inequalities cin >> n ; if ( n == 0 ) return false ; int p ; // dimension cin >> p ; Program lp ( CGAL :: SMALLER , false , 0 , false , 0 ); /** * a' (x + r * a / |a|) <= b * x = [x', r]' * A = [|a| * a', <a,a>] * b = [|a| * b] */ const int R = p ; // cgal minimizes objective -> change sign lp . set_c ( R , -1 ); vector < int > a_i ( n ); for ( int i = 0 ; i < n ; ++ i ) { for ( int j = 0 ; j < p ; ++ j ) cin >> a_i [ j ]; int b_i ; cin >> b_i ; double a2 = 0 ; for ( int j = 0 ; j < p ; ++ j ) a2 += pow ( a_i [ j ], 2 ); int norm_a_i = ( int ) sqrt ( a2 ); for ( int j = 0 ; j < p ; ++ j ) lp . set_a ( j , i , norm_a_i * a_i [ j ]); lp . set_a ( R , i , a2 ); lp . set_b ( i , norm_a_i * b_i ); } // set lower bound on r lp . set_l ( R , true , 0 ); Solution s = CGAL :: solve_linear_program ( lp , ET ()); if ( s . is_infeasible ()) cout << \"none\" << endl ; else if ( s . is_unbounded ()) cout << \"inf\" << endl ; else { // Solution::Variable_value_iterator opt = s.variable_values_end()-1; Solution :: Variable_value_iterator opt = s . variable_values_begin () + p ; // cout << floor(-s.objective_value_numerator().to_double() / s.objective_value_denominator().to_double()) << endl; cout << floor ( opt -> numerator (). to_double () / opt -> denominator (). to_double ()) << endl ; } return true ; } int main () { ios_base :: sync_with_stdio ( false ); cout << setprecision ( 0 ) << fixed ; while ( testcase ()); } Inball Problem Difficulties Techniques Solution","title":"week 7"},{"location":"Algorithms%20Lab/exercises/w07/#maximize","text":"","title":"Maximize"},{"location":"Algorithms%20Lab/exercises/w07/#problem","text":"","title":"Problem"},{"location":"Algorithms%20Lab/exercises/w07/#difficulties","text":"","title":"Difficulties"},{"location":"Algorithms%20Lab/exercises/w07/#techniques","text":"","title":"Techniques"},{"location":"Algorithms%20Lab/exercises/w07/#solution","text":"","title":"Solution"},{"location":"Algorithms%20Lab/exercises/w07/#diet","text":"","title":"Diet"},{"location":"Algorithms%20Lab/exercises/w07/#problem_1","text":"","title":"Problem"},{"location":"Algorithms%20Lab/exercises/w07/#difficulties_1","text":"","title":"Difficulties"},{"location":"Algorithms%20Lab/exercises/w07/#techniques_1","text":"","title":"Techniques"},{"location":"Algorithms%20Lab/exercises/w07/#solution_1","text":"","title":"Solution"},{"location":"Algorithms%20Lab/exercises/w07/#inball","text":"","title":"Inball"},{"location":"Algorithms%20Lab/exercises/w07/#problem_2","text":"Find radius of largest ball that fits into a \\(p\\) dimensional polyhedron","title":"Problem"},{"location":"Algorithms%20Lab/exercises/w07/#difficulties_2","text":"Don't forget to set lower bounds. Changing problem into a LP.","title":"Difficulties"},{"location":"Algorithms%20Lab/exercises/w07/#techniques_2","text":"Linear Programming, Linear Algebra","title":"Techniques"},{"location":"Algorithms%20Lab/exercises/w07/#solution_2","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 #include <iostream> #include <vector> #include <CGAL/QP_models.h> #include <CGAL/QP_functions.h> #include <CGAL/Gmpz.h> // choose input type (input coefficients must fit) typedef int IT ; // choose exact type for solver (CGAL::Gmpz or CGAL::Gmpq) typedef CGAL :: Gmpz ET ; // program and solution types typedef CGAL :: Quadratic_program < IT > Program ; typedef CGAL :: Quadratic_program_solution < ET > Solution ; using namespace std ; bool testcase () { int n ; // number of inequalities cin >> n ; if ( n == 0 ) return false ; int p ; // dimension cin >> p ; Program lp ( CGAL :: SMALLER , false , 0 , false , 0 ); /** * a' (x + r * a / |a|) <= b * x = [x', r]' * A = [|a| * a', <a,a>] * b = [|a| * b] */ const int R = p ; // cgal minimizes objective -> change sign lp . set_c ( R , -1 ); vector < int > a_i ( n ); for ( int i = 0 ; i < n ; ++ i ) { for ( int j = 0 ; j < p ; ++ j ) cin >> a_i [ j ]; int b_i ; cin >> b_i ; double a2 = 0 ; for ( int j = 0 ; j < p ; ++ j ) a2 += pow ( a_i [ j ], 2 ); int norm_a_i = ( int ) sqrt ( a2 ); for ( int j = 0 ; j < p ; ++ j ) lp . set_a ( j , i , norm_a_i * a_i [ j ]); lp . set_a ( R , i , a2 ); lp . set_b ( i , norm_a_i * b_i ); } // set lower bound on r lp . set_l ( R , true , 0 ); Solution s = CGAL :: solve_linear_program ( lp , ET ()); if ( s . is_infeasible ()) cout << \"none\" << endl ; else if ( s . is_unbounded ()) cout << \"inf\" << endl ; else { // Solution::Variable_value_iterator opt = s.variable_values_end()-1; Solution :: Variable_value_iterator opt = s . variable_values_begin () + p ; // cout << floor(-s.objective_value_numerator().to_double() / s.objective_value_denominator().to_double()) << endl; cout << floor ( opt -> numerator (). to_double () / opt -> denominator (). to_double ()) << endl ; } return true ; } int main () { ios_base :: sync_with_stdio ( false ); cout << setprecision ( 0 ) << fixed ; while ( testcase ()); }","title":"Solution"},{"location":"Algorithms%20Lab/exercises/w07/#inball_1","text":"","title":"Inball"},{"location":"Algorithms%20Lab/exercises/w07/#problem_3","text":"","title":"Problem"},{"location":"Algorithms%20Lab/exercises/w07/#difficulties_3","text":"","title":"Difficulties"},{"location":"Algorithms%20Lab/exercises/w07/#techniques_3","text":"","title":"Techniques"},{"location":"Algorithms%20Lab/exercises/w07/#solution_3","text":"","title":"Solution"},{"location":"Algorithms%20Lab/exercises/w08/","text":"Bistro Problem Difficulties Techniques Delaunay triangulation Solution 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 #include <iostream> #include <vector> #include <CGAL/Exact_predicates_inexact_constructions_kernel.h> #include <CGAL/Delaunay_triangulation_2.h> typedef CGAL :: Exact_predicates_inexact_constructions_kernel K ; typedef CGAL :: Delaunay_triangulation_2 < K > Triangulation ; using namespace std ; bool testcase (){ int n ; // number of existing restaurant location cin >> n ; if ( n == 0 ) return false ; vector < K :: Point_2 > pts ; pts . reserve ( n ); for ( int i = 0 ; i < n ; ++ i ) { int x , y ; cin >> x >> y ; pts . emplace_back ( K :: Point_2 ( x , y )); } Triangulation t ; t . insert ( pts . begin (), pts . end ()); int m ; // number of possible new locations cin >> m ; for ( int i = 0 ; i < m ; ++ i ) { int x , y ; cin >> x >> y ; K :: Point_2 q ( x , y ); auto p = t . nearest_vertex ( q ); K :: FT d2 = CGAL :: squared_distance ( p -> point (), q ); // NOTE squared distance should fit in double cout << CGAL :: to_double ( d2 ) << endl ; } return true ; } int main (){ ios_base :: sync_with_stdio ( false ); cout << setprecision ( 0 ) << fixed ; while ( testcase ()); } Germs Problem Difficulties Implementation, sort before calling min, indices Techniques Delaunay Triangulation, Sort Solution Note sample solution is much nicer. You can initiate exact kernel field types from inexact kernel field types . Note, having vertex info would be enough. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 #include <CGAL/Exact_predicates_inexact_constructions_kernel.h> #include <CGAL/Delaunay_triangulation_2.h> #include <CGAL/Triangulation_vertex_base_with_info_2.h> #include <CGAL/Triangulation_face_base_2.h> #include <boost/pending/disjoint_sets.hpp> #include <vector> #include <tuple> #include <algorithm> #include <iostream> // Epic kernel is enough, no constructions needed, provided the squared distance // fits into a double (!) typedef CGAL :: Exact_predicates_inexact_constructions_kernel K ; // we want to store an index with each vertex typedef int Index ; typedef CGAL :: Triangulation_vertex_base_with_info_2 < Index , K > Vb ; typedef CGAL :: Triangulation_face_base_2 < K > Fb ; typedef CGAL :: Triangulation_data_structure_2 < Vb , Fb > Tds ; typedef CGAL :: Delaunay_triangulation_2 < K , Tds > Delaunay ; typedef std :: tuple < Index , Index , K :: FT > Edge ; typedef std :: vector < Edge > EdgeV ; typedef std :: pair < K :: Point_2 , Index > IPoint ; using namespace std ; bool testcase () { int n ; cin >> n ; if ( n == 0 ) return false ; // dish int l , b , r , t ; cin >> l >> b >> r >> t ; std :: vector < IPoint > points ; points . reserve ( n ); int num_dead_cells = 0 ; vector < bool > is_alive ( 2 * n , true ); for ( Index i = 0 ; i < n ; ++ i ) { int x , y ; std :: cin >> x >> y ; points . emplace_back ( K :: Point_2 ( x , y ), i ); // ignore if on boundary if ( x == l || x == r || y == b || y == t ) { num_dead_cells ++ ; is_alive [ i ] = false ; } else { int dl = x - l ; int db = y - b ; int dr = r - x ; int dt = t - y ; vector < pair < int , int >> dist = { make_pair ( dl , 0 ), make_pair ( db , 1 ), make_pair ( dr , 2 ), make_pair ( dt , 3 )}; sort ( dist . begin (), dist . end ()); auto dm = std :: min ( dist . begin (), dist . end ()); K :: Point_2 pt ; switch ( dm -> second ) { case 0 : pt = K :: Point_2 ( l - dl , y ); break ; case 1 : pt = K :: Point_2 ( x , b - db ); break ; case 2 : pt = K :: Point_2 ( r + dr , y ); break ; case 3 : pt = K :: Point_2 ( x , t + dt ); } points . emplace_back ( pt , n + i ); } } // Delaunay triangulation contains nearest neighbour graph. // Bacteria will die from one of its nearest neighbours or from boundary // => sort edges of Delaunay triangulation + edges to border according to length Delaunay td ; // triangulation delaunay td . insert ( points . begin (), points . end ()); // O(n log n) // sort edges according to squared distance EdgeV edges ; edges . reserve ( 3 * n ); // there can be no more in a planar graph for ( auto e = td . finite_edges_begin (); e != td . finite_edges_end (); ++ e ) { Index i1 = e -> first -> vertex (( e -> second + 1 ) % 3 ) -> info (); Index i2 = e -> first -> vertex (( e -> second + 2 ) % 3 ) -> info (); // ensure smaller index comes first if ( i1 > i2 ) std :: swap ( i1 , i2 ); edges . emplace_back ( i1 , i2 , td . segment ( e ). squared_length ()); } std :: sort ( edges . begin (), edges . end (), []( const Edge & e1 , const Edge & e2 ) -> bool { return std :: get < 2 > ( e1 ) < std :: get < 2 > ( e2 ); }); // go over sorted edges int first = -1 ; // time at which first cell dies int m = -1 ; // time at which more than median/half of cells is dead int last = 0 ; // time at which last cell dies // r(t) = t^2 + 0.5 // 2 * r(t) < d // (2*t^2 + 1)^2 < d^2 // 4*t^4 + 4*t^2 + 1 < d^2 if ( num_dead_cells > 0 ) first = 0 ; if ( num_dead_cells > n / 2 ) m = 0 ; for ( auto e : edges ) { Index v1 = std :: get < 0 > ( e ); Index v2 = std :: get < 1 > ( e ); bool do_check = false ; if ( v1 < n && is_alive [ v1 ]) do_check = true ; if ( v2 < n && is_alive [ v2 ]) do_check = true ; if ( do_check ){ double d2 = get < 2 > ( e ); // TODO while loop could be improved by starting with a time that is close to the result // NOTE last^4 should fit into double since t^2 < x < 2^25 => t^4 < 2^50 while ( d2 > 4 * pow (( double ) last , 4 ) + 4 * pow (( double ) last , 2 ) + 1 ) last ++ ; if ( is_alive [ v1 ]) { is_alive [ v1 ] = false ; if ( v1 < n ) num_dead_cells ++ ; } if ( is_alive [ v2 ]) { is_alive [ v2 ] = false ; if ( v2 < n ) num_dead_cells ++ ; } if ( first == -1 ) first = last ; if ( num_dead_cells > n / 2 && m == -1 ) m = last ; } } cout << first << \" \" << m << \" \" << last << endl ; return true ; } int main () { ios_base :: sync_with_stdio ( false ); while ( testcase ()); } -- Problem Difficulties Techniques Solution -- Problem Difficulties Techniques Solution","title":"week 8"},{"location":"Algorithms%20Lab/exercises/w08/#bistro","text":"","title":"Bistro"},{"location":"Algorithms%20Lab/exercises/w08/#problem","text":"","title":"Problem"},{"location":"Algorithms%20Lab/exercises/w08/#difficulties","text":"","title":"Difficulties"},{"location":"Algorithms%20Lab/exercises/w08/#techniques","text":"Delaunay triangulation","title":"Techniques"},{"location":"Algorithms%20Lab/exercises/w08/#solution","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 #include <iostream> #include <vector> #include <CGAL/Exact_predicates_inexact_constructions_kernel.h> #include <CGAL/Delaunay_triangulation_2.h> typedef CGAL :: Exact_predicates_inexact_constructions_kernel K ; typedef CGAL :: Delaunay_triangulation_2 < K > Triangulation ; using namespace std ; bool testcase (){ int n ; // number of existing restaurant location cin >> n ; if ( n == 0 ) return false ; vector < K :: Point_2 > pts ; pts . reserve ( n ); for ( int i = 0 ; i < n ; ++ i ) { int x , y ; cin >> x >> y ; pts . emplace_back ( K :: Point_2 ( x , y )); } Triangulation t ; t . insert ( pts . begin (), pts . end ()); int m ; // number of possible new locations cin >> m ; for ( int i = 0 ; i < m ; ++ i ) { int x , y ; cin >> x >> y ; K :: Point_2 q ( x , y ); auto p = t . nearest_vertex ( q ); K :: FT d2 = CGAL :: squared_distance ( p -> point (), q ); // NOTE squared distance should fit in double cout << CGAL :: to_double ( d2 ) << endl ; } return true ; } int main (){ ios_base :: sync_with_stdio ( false ); cout << setprecision ( 0 ) << fixed ; while ( testcase ()); }","title":"Solution"},{"location":"Algorithms%20Lab/exercises/w08/#germs","text":"","title":"Germs"},{"location":"Algorithms%20Lab/exercises/w08/#problem_1","text":"","title":"Problem"},{"location":"Algorithms%20Lab/exercises/w08/#difficulties_1","text":"Implementation, sort before calling min, indices","title":"Difficulties"},{"location":"Algorithms%20Lab/exercises/w08/#techniques_1","text":"Delaunay Triangulation, Sort","title":"Techniques"},{"location":"Algorithms%20Lab/exercises/w08/#solution_1","text":"Note sample solution is much nicer. You can initiate exact kernel field types from inexact kernel field types . Note, having vertex info would be enough. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 #include <CGAL/Exact_predicates_inexact_constructions_kernel.h> #include <CGAL/Delaunay_triangulation_2.h> #include <CGAL/Triangulation_vertex_base_with_info_2.h> #include <CGAL/Triangulation_face_base_2.h> #include <boost/pending/disjoint_sets.hpp> #include <vector> #include <tuple> #include <algorithm> #include <iostream> // Epic kernel is enough, no constructions needed, provided the squared distance // fits into a double (!) typedef CGAL :: Exact_predicates_inexact_constructions_kernel K ; // we want to store an index with each vertex typedef int Index ; typedef CGAL :: Triangulation_vertex_base_with_info_2 < Index , K > Vb ; typedef CGAL :: Triangulation_face_base_2 < K > Fb ; typedef CGAL :: Triangulation_data_structure_2 < Vb , Fb > Tds ; typedef CGAL :: Delaunay_triangulation_2 < K , Tds > Delaunay ; typedef std :: tuple < Index , Index , K :: FT > Edge ; typedef std :: vector < Edge > EdgeV ; typedef std :: pair < K :: Point_2 , Index > IPoint ; using namespace std ; bool testcase () { int n ; cin >> n ; if ( n == 0 ) return false ; // dish int l , b , r , t ; cin >> l >> b >> r >> t ; std :: vector < IPoint > points ; points . reserve ( n ); int num_dead_cells = 0 ; vector < bool > is_alive ( 2 * n , true ); for ( Index i = 0 ; i < n ; ++ i ) { int x , y ; std :: cin >> x >> y ; points . emplace_back ( K :: Point_2 ( x , y ), i ); // ignore if on boundary if ( x == l || x == r || y == b || y == t ) { num_dead_cells ++ ; is_alive [ i ] = false ; } else { int dl = x - l ; int db = y - b ; int dr = r - x ; int dt = t - y ; vector < pair < int , int >> dist = { make_pair ( dl , 0 ), make_pair ( db , 1 ), make_pair ( dr , 2 ), make_pair ( dt , 3 )}; sort ( dist . begin (), dist . end ()); auto dm = std :: min ( dist . begin (), dist . end ()); K :: Point_2 pt ; switch ( dm -> second ) { case 0 : pt = K :: Point_2 ( l - dl , y ); break ; case 1 : pt = K :: Point_2 ( x , b - db ); break ; case 2 : pt = K :: Point_2 ( r + dr , y ); break ; case 3 : pt = K :: Point_2 ( x , t + dt ); } points . emplace_back ( pt , n + i ); } } // Delaunay triangulation contains nearest neighbour graph. // Bacteria will die from one of its nearest neighbours or from boundary // => sort edges of Delaunay triangulation + edges to border according to length Delaunay td ; // triangulation delaunay td . insert ( points . begin (), points . end ()); // O(n log n) // sort edges according to squared distance EdgeV edges ; edges . reserve ( 3 * n ); // there can be no more in a planar graph for ( auto e = td . finite_edges_begin (); e != td . finite_edges_end (); ++ e ) { Index i1 = e -> first -> vertex (( e -> second + 1 ) % 3 ) -> info (); Index i2 = e -> first -> vertex (( e -> second + 2 ) % 3 ) -> info (); // ensure smaller index comes first if ( i1 > i2 ) std :: swap ( i1 , i2 ); edges . emplace_back ( i1 , i2 , td . segment ( e ). squared_length ()); } std :: sort ( edges . begin (), edges . end (), []( const Edge & e1 , const Edge & e2 ) -> bool { return std :: get < 2 > ( e1 ) < std :: get < 2 > ( e2 ); }); // go over sorted edges int first = -1 ; // time at which first cell dies int m = -1 ; // time at which more than median/half of cells is dead int last = 0 ; // time at which last cell dies // r(t) = t^2 + 0.5 // 2 * r(t) < d // (2*t^2 + 1)^2 < d^2 // 4*t^4 + 4*t^2 + 1 < d^2 if ( num_dead_cells > 0 ) first = 0 ; if ( num_dead_cells > n / 2 ) m = 0 ; for ( auto e : edges ) { Index v1 = std :: get < 0 > ( e ); Index v2 = std :: get < 1 > ( e ); bool do_check = false ; if ( v1 < n && is_alive [ v1 ]) do_check = true ; if ( v2 < n && is_alive [ v2 ]) do_check = true ; if ( do_check ){ double d2 = get < 2 > ( e ); // TODO while loop could be improved by starting with a time that is close to the result // NOTE last^4 should fit into double since t^2 < x < 2^25 => t^4 < 2^50 while ( d2 > 4 * pow (( double ) last , 4 ) + 4 * pow (( double ) last , 2 ) + 1 ) last ++ ; if ( is_alive [ v1 ]) { is_alive [ v1 ] = false ; if ( v1 < n ) num_dead_cells ++ ; } if ( is_alive [ v2 ]) { is_alive [ v2 ] = false ; if ( v2 < n ) num_dead_cells ++ ; } if ( first == -1 ) first = last ; if ( num_dead_cells > n / 2 && m == -1 ) m = last ; } } cout << first << \" \" << m << \" \" << last << endl ; return true ; } int main () { ios_base :: sync_with_stdio ( false ); while ( testcase ()); }","title":"Solution"},{"location":"Algorithms%20Lab/exercises/w08/#-","text":"","title":"--"},{"location":"Algorithms%20Lab/exercises/w08/#problem_2","text":"","title":"Problem"},{"location":"Algorithms%20Lab/exercises/w08/#difficulties_2","text":"","title":"Difficulties"},{"location":"Algorithms%20Lab/exercises/w08/#techniques_2","text":"","title":"Techniques"},{"location":"Algorithms%20Lab/exercises/w08/#solution_2","text":"","title":"Solution"},{"location":"Algorithms%20Lab/exercises/w08/#-_1","text":"","title":"--"},{"location":"Algorithms%20Lab/exercises/w08/#problem_3","text":"","title":"Problem"},{"location":"Algorithms%20Lab/exercises/w08/#difficulties_3","text":"","title":"Difficulties"},{"location":"Algorithms%20Lab/exercises/w08/#techniques_3","text":"","title":"Techniques"},{"location":"Algorithms%20Lab/exercises/w08/#solution_3","text":"","title":"Solution"},{"location":"Algorithms%20Lab/pows/pows/","text":"Deck of Cards Problem Find an interval \\([i,j], \\ i \\leq j\\) such that $$ \\left| \\sum_{l=i}^j v_l - k \\right|, \\quad v_l \\geq 0 $$ is minimized. If there are multiple solutions, take the one that is lexicographically smaller (iff \\(i < i'\\) or \\(i \\leq i'\\) and \\(j < j'\\) ). Difficulties Getting indices right Techniques Sliding window, Pre-computation of partial sums Solution 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 #include <iostream> // We will use C++ input/output via streams #include <vector> #include <limits> #include <cmath> void testcase () { int n ; std :: cin >> n ; // Read the number of integers to follow int k ; std :: cin >> k ; std :: vector < int > values ( n ); for ( int i = 0 ; i < n ; ++ i ){ int v_i ; std :: cin >> v_i ; values [ i ] = v_i ; } // pre-compute partial sums std :: vector < int > S ( n + 1 ); S [ 0 ] = 0 ; for ( int i = 1 ; i < n + 1 ; ++ i ){ S [ i ] = S [ i -1 ] + values [ i -1 ]; } // sliding window int min_diff = std :: numeric_limits < int >:: max (); int i = 0 , j = 0 , i_min = 0 , j_min = 0 ; while ( j < n ){ int d = S [ j + 1 ] - S [ i + 1-1 ] - k ; int diff = std :: abs ( d ); if ( diff < min_diff ){ min_diff = diff ; i_min = i ; j_min = j ; } if ( d > 0 ){ if ( i < j ){ i ++ ; } else { j ++ ; } } else { j ++ ; } } std :: cout << i_min << \" \" << j_min << std :: endl ; } int main () { std :: ios_base :: sync_with_stdio ( false ); // Always! int t ; std :: cin >> t ; for ( int i = 0 ; i < t ; ++ i ) testcase (); // Solve a particular test case } From Russia with Love Problem Find minimal optimal winnings for player k regardless Difficulties getting indices right Techniques Dynamic Programming Solution 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 #include <iostream> // We will use C++ input/output via streams #include <vector> #include <limits> #include <cmath> typedef std :: vector < std :: vector < int >> VVI ; int step ( int i , int j , int m , std :: vector < int >& x , VVI & S ){ if ( i == j ) return x [ i ]; if ( i > j ) return 0 ; if ( S [ i ][ j ] != -1 ) return S [ i ][ j ]; int min_winnings_left = std :: numeric_limits < int >:: max (); int min_winnings_right = std :: numeric_limits < int >:: max (); for ( int l = 0 ; l <= m -1 ; ++ l ){ min_winnings_left = std :: min ( x [ i ] + step ( i + 1 + l , j - ( m -1 - l ), m , x , S ), min_winnings_left ); min_winnings_right = std :: min ( x [ j ] + step ( i + l , j -1 - ( m -1 - l ), m , x , S ), min_winnings_right ); } S [ i ][ j ] = std :: max ( min_winnings_left , min_winnings_right ); return S [ i ][ j ]; } void testcase () { int n ; std :: cin >> n ; // number of coins int m ; std :: cin >> m ; // number of passengers int k ; std :: cin >> k ; // id of passenger whose winnings we should maximize std :: vector < int > x ( n ); for ( int i = 0 ; i < n ; ++ i ){ std :: cin >> x [ i ]; } VVI S ( n , std :: vector < int > ( n , -1 )); int min_winnings = std :: numeric_limits < int >:: max (); int i = 0 , j = n -1 ; for ( int l = 0 ; l <= k ; ++ l ){ // k == #passengers before k min_winnings = std :: min ( step ( i + l , j - ( k - l ), m , x , S ), min_winnings ); } std :: cout << min_winnings << std :: endl ; } int main () { std :: ios_base :: sync_with_stdio ( false ); // Always! int t ; std :: cin >> t ; for ( int i = 0 ; i < t ; ++ i ) testcase (); // Solve a particular test case } Defensive Line Problem Difficulties Formulating as dynamic program, getting indices and < and > correct. Wrong data structure. Thinking too complicate. Keep code simple. Techniques Dynamic Program, sliding window Solution 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 #include <iostream> #include <vector> #include <utility> #include <algorithm> using namespace std ; int step ( int seg_i , int m_start , int m , int num_segments , std :: vector < int > & to , std :: vector < std :: pair < int , int >> & segments , std :: vector < std :: vector < int >> & memo ) { // all attackers already busy if ( m_start == m ) return 0 ; // invalid configuration if ( seg_i >= num_segments && m_start < m ) return -1000000000 ; // small number avoids check // check memory if ( memo [ seg_i ][ m_start ] != -2 ) return memo [ seg_i ][ m_start ]; int without_seg_i = step ( seg_i + 1 , m_start , m , num_segments , to , segments , memo ); int with_seg_i = segments [ seg_i ]. second - segments [ seg_i ]. first + 1 + step ( to [ seg_i ], m_start + 1 , m , num_segments , to , segments , memo ); // save to memory memo [ seg_i ][ m_start ] = std :: max ( without_seg_i , with_seg_i ); return memo [ seg_i ][ m_start ]; } void testcase () { int n , m ; int k ; std :: cin >> n >> m >> k ; // pre compute partial sums vector < int > s ( n + 1 , 0 ); for ( int i = 1 ; i < n + 1 ; ++ i ) { std :: cin >> s [ i ]; s [ i ] += s [ i - 1 ]; } // sliding window to find segments int i = 1 , j = 1 ; std :: vector < std :: pair < int , int >> segments ; segments . reserve ( n ); std :: vector < int > start ( n + 1 , -1 ), end ( n + 1 , -1 ); while ( j < n + 1 ) { int def_value = s [ j ] - s [ i - 1 ]; if ( def_value == k ) { segments . emplace_back ( i , j ); int seg_id = segments . size () - 1 ; end [ j ] = seg_id ; start [ i ] = seg_id ; i ++ ; j ++ ; } else if ( def_value > k ) { i ++ ; if ( i > j ) j ++ ; } else { j ++ ; } } int num_segments = segments . size (); // compute *to* vector to save computation std :: vector < int > to ( num_segments , num_segments ); std :: vector < int > closed ; for ( int l = 1 ; l < n + 1 ; ++ l ) { if ( start [ l ] != -1 ) { // every segment gets iterated at most once // total runtime is O(2*n) for ( auto it : closed ) to [ it ] = start [ l ]; closed . clear (); } if ( end [ l ] != -1 ) closed . emplace_back ( end [ l ]); } // dynamic program std :: vector < std :: vector < int >> memo ( num_segments , std :: vector < int > ( m , -2 )); int max_value = step ( 0 , 0 , m , num_segments , to , segments , memo ); if ( max_value > -1 ) cout << max_value << endl ; else cout << \"fail\" << endl ; } int main () { std :: ios_base :: sync_with_stdio ( false ); int t ; std :: cin >> t ; for ( int i = 0 ; i < t ; ++ i ) { testcase (); } return 0 ; } MotorCycles Problem Find lucky bikers that driver forever and start from vertical line. Difficulties Runtime Analysis (How to proof runtime?), sorting with tracking permutation Techniques CGAL, Intersection Solution 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 #include <iostream> #include <vector> #include <algorithm> #include <stack> #include <CGAL/Exact_predicates_exact_constructions_kernel.h> typedef CGAL :: Exact_predicates_exact_constructions_kernel K ; typedef K :: Ray_2 R ; typedef K :: Point_2 P ; using namespace std ; void testcase () { int n ; cin >> n ; vector < pair < long , int >> y1_n_id ( n ); y1_n_id . reserve ( n ); vector < R > rays ( n ); rays . reserve ( n ); for ( int i = 0 ; i < n ; ++ i ) { long y1 , x2 , y2 ; cin >> y1 >> x2 >> y2 ; rays [ i ] = R ( P ( 0 , y1 ), P ( x2 , y2 )); y1_n_id [ i ] = make_pair ( y1 , i ); } sort ( y1_n_id . begin (), y1_n_id . end (), std :: greater <> ()); vector < int > luckyDrivers ; for ( int i = 0 ; i < n ; ++ i ) { int rid = y1_n_id [ i ]. second ; auto ray = rays [ rid ]; /* * NOTE the runtime is O(n) even though we iterate over lucky drivers. * However, since we stop the iteration as soon as there is no intersection. * Hence, every lucky driver except the last one will be iterated at most twice. * If the next ray r2 is parallel to r1, r2 will be a lucky * driver as well. If that is the case and there is another ray r3 that * intersects with r2, then also r3 intersects with r1 and r1 will be deleted. */ while ( true ) { if ( luckyDrivers . empty ()) { luckyDrivers . emplace_back ( rid ); break ; } else { auto ray2 = rays [ luckyDrivers . back ()]; // check if drivers intersect if ( CGAL :: do_intersect ( ray , ray2 )) { auto o = CGAL :: intersection ( ray , ray2 ); if ( const P * op = boost :: get < P > ( &* o )) { auto d1 = CGAL :: squared_distance ( * op , ray . source ()); auto d2 = CGAL :: squared_distance ( * op , ray2 . source ()); // check which is first if ( d1 <= d2 ) { luckyDrivers . pop_back (); } else { break ; } } } else { luckyDrivers . emplace_back ( rid ); break ; } } } } sort ( luckyDrivers . begin (), luckyDrivers . end ()); for ( auto id : luckyDrivers ) cout << id << \" \" ; cout << endl ; } int main () { ios_base :: sync_with_stdio ( false ); int t ; cin >> t ; while ( t -- ) testcase (); } Tracking Problem Difficulties Techniques Solution Octopussy Problem Difficulties Proofing greedy (Proof by replacement), Reading things correctly Techniques Greedy Solution Propagate minimum time from root to leaf nodes. Take always the node with the smallest time. Proof of correctness (proof by replacement (TODO?)): Let \\(V\\) denote the set of nodes that we have already visited. Let \\(v_n\\) denote the node that the greedy algorithm will visit next. Assume that we do not arrive in time for \\(v_n\\) , however, let's further assume that there is an optimal solution that arrives at \\(v_n\\) in time. Note that by design all nodes in \\(V\\) have to be visited before \\(v_n\\) . In order to arrive at \\(v_n\\) in time we would have to remove at least one node from \\(V\\) . However, this is a contradiction to our observation that all nodes in \\(V\\) have to be visited before \\(v_n\\) . Hence, if the greedy algorithm cannot visit all nodes in time then there is also no optimal solution that would achieve that. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 // // Created by Krispin Wandel on 15.01.21. // #include <iostream> #include <vector> #include <queue> using namespace std ; void testcase () { int n ; cin >> n ; vector < int > t ( n ); for ( int i = 0 ; i < n ; ++ i ) { cin >> t [ i ]; } vector < int > min_t ( n ); min_t [ 0 ] = t [ 0 ]; for ( int i = 1 ; i < n ; i += 2 ) { // children c_i,1 and c_i,2 of i: // c_i,1 = 2 * i + 1, // c_i,2 = 2 * i + 2 int parent = ( i - 1 ) / 2 ; min_t [ i ] = min ( min_t [ parent ] - 1 , t [ i ]); min_t [ i + 1 ] = min ( min_t [ parent ] - 1 , t [ i + 1 ]); } int counter = 0 ; bool is_possible = true ; vector < bool > visited ( n , false ); priority_queue < int , std :: vector < pair < int , int >> , std :: greater <>> pq ; // push leaf nodes for ( int i = ( n - 1 ) / 2 ; i < n ; ++ i ) { pq . push ( make_pair ( min_t [ i ], i )); } while ( ! pq . empty ()) { // get child with smallest min_t auto sel = pq . top (); pq . pop (); // check if we are in time if ( counter < sel . first ) { counter ++ ; } else { is_possible = false ; break ; } // push children to pq int i = sel . second ; visited [ i ] = true ; if ( i > 0 ) { bool is_second_child = i % 2 == 0 ; int parent = ( i - is_second_child * 2 - ! is_second_child * 1 ) / 2 ; // only checkout parent is neighbour has been visited as well if ( visited [ i - is_second_child + ! is_second_child ]) pq . push ( make_pair ( min_t [ parent ], parent )); } } if ( is_possible ) cout << \"yes\" ; else cout << \"no\" ; cout << endl ; } int main () { int t ; cin >> t ; while ( t -- ) testcase (); } Surveillance Photographs Problem Difficulties Do not run breadth first search on maxflow graph. Reading things correctly. For first test set: police men starts and ends at the same police station. Techniques Maximum Flow, Breadth First Search Solution 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 #include <iostream> #include <vector> #include <set> // BGL include #include <boost/graph/adjacency_list.hpp> // BGL flow include *NEW* #include <boost/graph/push_relabel_max_flow.hpp> #include <boost/graph/breadth_first_search.hpp> #include <boost/graph/properties.hpp> // Graph Type with nested interior edge properties for flow algorithms typedef boost :: adjacency_list_traits < boost :: vecS , boost :: vecS , boost :: directedS > traits ; typedef boost :: adjacency_list < boost :: vecS , boost :: vecS , boost :: directedS , boost :: no_property , boost :: property < boost :: edge_capacity_t , long , boost :: property < boost :: edge_residual_capacity_t , long , boost :: property < boost :: edge_reverse_t , traits :: edge_descriptor >>>> graph ; typedef boost :: adjacency_list < boost :: vecS , boost :: vecS , boost :: directedS > graph2 ; typedef traits :: vertex_descriptor vertex_desc ; typedef traits :: edge_descriptor edge_desc ; // For BFS typedef boost :: default_color_type color ; class edge_adder { graph & G ; public : explicit edge_adder ( graph & G ) : G ( G ) {} void add_edge ( int from , int to , long capacity ) { auto c_map = boost :: get ( boost :: edge_capacity , G ); auto r_map = boost :: get ( boost :: edge_reverse , G ); const auto e = boost :: add_edge ( from , to , G ). first ; const auto rev_e = boost :: add_edge ( to , from , G ). first ; c_map [ e ] = capacity ; c_map [ rev_e ] = 0 ; // reverse edge has no capacity! r_map [ e ] = rev_e ; r_map [ rev_e ] = e ; } }; using namespace std ; void testcase () { int n , m , k , l ; cin >> n >> m >> k >> l ; /** * n = #intersections * m = #one-way streets * k = #police stations * l = #photographs */ graph G ( n ); graph2 G2 ( n ); edge_adder adder ( G ); set < int > police ; vector < int > num_police ( n , 0 ); for ( int i = 0 ; i < k ; ++ i ) { int x ; cin >> x ; num_police [ x ] ++ ; police . insert ( x ); } set < int > photo ; vector < int > num_photo ( n , 0 ); for ( int i = 0 ; i < l ; ++ i ) { int x ; cin >> x ; num_photo [ x ] ++ ; photo . insert ( x ); } for ( int i = 0 ; i < m ; ++ i ) { int x , y ; cin >> x >> y ; adder . add_edge ( x , y , 1 ); boost :: add_edge ( x , y , G2 ); } // for each police station check which photos are reachable vector < vector < int >> police_to_photo ( n , vector < int > ()); for ( int x : police ) { // breadth first search std :: vector < color > vertex_color ( n ); // exterior property map // O(n + m) boost :: breadth_first_search ( G2 , x , boost :: color_map ( boost :: make_iterator_property_map ( vertex_color . begin (), boost :: get ( boost :: vertex_index , G )))); // O(n) const color black = boost :: color_traits < color >:: black (); // visited by BFS // const color white = boost::color_traits<color>::white(); for ( int xp : photo ) { if ( vertex_color [ xp ] == black ) { police_to_photo [ x ]. emplace_back ( xp ); } } } // add capacity to photo nodes for ( int x : photo ) { adder . add_edge ( n + x , x , num_photo [ x ]); } // Add special vertices source and sink const vertex_desc v_source = boost :: add_vertex ( G ); const vertex_desc v_sink = boost :: add_vertex ( G ); // create flow graph to solve problem for ( int x : police ) { vertex_desc v_source_police = boost :: add_vertex ( G ); adder . add_edge ( v_source , v_source_police , num_police [ x ]); for ( int xp : police_to_photo [ x ]) { // NOTE capacity for this edge could be infinity adder . add_edge ( v_source_police , n + xp , num_photo [ xp ]); } adder . add_edge ( x , v_sink , num_police [ x ]); } // check max flow long flow = boost :: push_relabel_max_flow ( G , v_source , v_sink ); cout << flow << endl ; } int main () { ios_base :: sync_with_stdio ( false ); int t ; cin >> t ; while ( t -- ) testcase (); }","title":"Problems of the week"},{"location":"Algorithms%20Lab/pows/pows/#deck-of-cards","text":"","title":"Deck of Cards"},{"location":"Algorithms%20Lab/pows/pows/#problem","text":"Find an interval \\([i,j], \\ i \\leq j\\) such that $$ \\left| \\sum_{l=i}^j v_l - k \\right|, \\quad v_l \\geq 0 $$ is minimized. If there are multiple solutions, take the one that is lexicographically smaller (iff \\(i < i'\\) or \\(i \\leq i'\\) and \\(j < j'\\) ).","title":"Problem"},{"location":"Algorithms%20Lab/pows/pows/#difficulties","text":"Getting indices right","title":"Difficulties"},{"location":"Algorithms%20Lab/pows/pows/#techniques","text":"Sliding window, Pre-computation of partial sums","title":"Techniques"},{"location":"Algorithms%20Lab/pows/pows/#solution","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 #include <iostream> // We will use C++ input/output via streams #include <vector> #include <limits> #include <cmath> void testcase () { int n ; std :: cin >> n ; // Read the number of integers to follow int k ; std :: cin >> k ; std :: vector < int > values ( n ); for ( int i = 0 ; i < n ; ++ i ){ int v_i ; std :: cin >> v_i ; values [ i ] = v_i ; } // pre-compute partial sums std :: vector < int > S ( n + 1 ); S [ 0 ] = 0 ; for ( int i = 1 ; i < n + 1 ; ++ i ){ S [ i ] = S [ i -1 ] + values [ i -1 ]; } // sliding window int min_diff = std :: numeric_limits < int >:: max (); int i = 0 , j = 0 , i_min = 0 , j_min = 0 ; while ( j < n ){ int d = S [ j + 1 ] - S [ i + 1-1 ] - k ; int diff = std :: abs ( d ); if ( diff < min_diff ){ min_diff = diff ; i_min = i ; j_min = j ; } if ( d > 0 ){ if ( i < j ){ i ++ ; } else { j ++ ; } } else { j ++ ; } } std :: cout << i_min << \" \" << j_min << std :: endl ; } int main () { std :: ios_base :: sync_with_stdio ( false ); // Always! int t ; std :: cin >> t ; for ( int i = 0 ; i < t ; ++ i ) testcase (); // Solve a particular test case }","title":"Solution"},{"location":"Algorithms%20Lab/pows/pows/#from-russia-with-love","text":"","title":"From Russia with Love"},{"location":"Algorithms%20Lab/pows/pows/#problem_1","text":"Find minimal optimal winnings for player k regardless","title":"Problem"},{"location":"Algorithms%20Lab/pows/pows/#difficulties_1","text":"getting indices right","title":"Difficulties"},{"location":"Algorithms%20Lab/pows/pows/#techniques_1","text":"Dynamic Programming","title":"Techniques"},{"location":"Algorithms%20Lab/pows/pows/#solution_1","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 #include <iostream> // We will use C++ input/output via streams #include <vector> #include <limits> #include <cmath> typedef std :: vector < std :: vector < int >> VVI ; int step ( int i , int j , int m , std :: vector < int >& x , VVI & S ){ if ( i == j ) return x [ i ]; if ( i > j ) return 0 ; if ( S [ i ][ j ] != -1 ) return S [ i ][ j ]; int min_winnings_left = std :: numeric_limits < int >:: max (); int min_winnings_right = std :: numeric_limits < int >:: max (); for ( int l = 0 ; l <= m -1 ; ++ l ){ min_winnings_left = std :: min ( x [ i ] + step ( i + 1 + l , j - ( m -1 - l ), m , x , S ), min_winnings_left ); min_winnings_right = std :: min ( x [ j ] + step ( i + l , j -1 - ( m -1 - l ), m , x , S ), min_winnings_right ); } S [ i ][ j ] = std :: max ( min_winnings_left , min_winnings_right ); return S [ i ][ j ]; } void testcase () { int n ; std :: cin >> n ; // number of coins int m ; std :: cin >> m ; // number of passengers int k ; std :: cin >> k ; // id of passenger whose winnings we should maximize std :: vector < int > x ( n ); for ( int i = 0 ; i < n ; ++ i ){ std :: cin >> x [ i ]; } VVI S ( n , std :: vector < int > ( n , -1 )); int min_winnings = std :: numeric_limits < int >:: max (); int i = 0 , j = n -1 ; for ( int l = 0 ; l <= k ; ++ l ){ // k == #passengers before k min_winnings = std :: min ( step ( i + l , j - ( k - l ), m , x , S ), min_winnings ); } std :: cout << min_winnings << std :: endl ; } int main () { std :: ios_base :: sync_with_stdio ( false ); // Always! int t ; std :: cin >> t ; for ( int i = 0 ; i < t ; ++ i ) testcase (); // Solve a particular test case }","title":"Solution"},{"location":"Algorithms%20Lab/pows/pows/#defensive-line","text":"","title":"Defensive Line"},{"location":"Algorithms%20Lab/pows/pows/#problem_2","text":"","title":"Problem"},{"location":"Algorithms%20Lab/pows/pows/#difficulties_2","text":"Formulating as dynamic program, getting indices and < and > correct. Wrong data structure. Thinking too complicate. Keep code simple.","title":"Difficulties"},{"location":"Algorithms%20Lab/pows/pows/#techniques_2","text":"Dynamic Program, sliding window","title":"Techniques"},{"location":"Algorithms%20Lab/pows/pows/#solution_2","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 #include <iostream> #include <vector> #include <utility> #include <algorithm> using namespace std ; int step ( int seg_i , int m_start , int m , int num_segments , std :: vector < int > & to , std :: vector < std :: pair < int , int >> & segments , std :: vector < std :: vector < int >> & memo ) { // all attackers already busy if ( m_start == m ) return 0 ; // invalid configuration if ( seg_i >= num_segments && m_start < m ) return -1000000000 ; // small number avoids check // check memory if ( memo [ seg_i ][ m_start ] != -2 ) return memo [ seg_i ][ m_start ]; int without_seg_i = step ( seg_i + 1 , m_start , m , num_segments , to , segments , memo ); int with_seg_i = segments [ seg_i ]. second - segments [ seg_i ]. first + 1 + step ( to [ seg_i ], m_start + 1 , m , num_segments , to , segments , memo ); // save to memory memo [ seg_i ][ m_start ] = std :: max ( without_seg_i , with_seg_i ); return memo [ seg_i ][ m_start ]; } void testcase () { int n , m ; int k ; std :: cin >> n >> m >> k ; // pre compute partial sums vector < int > s ( n + 1 , 0 ); for ( int i = 1 ; i < n + 1 ; ++ i ) { std :: cin >> s [ i ]; s [ i ] += s [ i - 1 ]; } // sliding window to find segments int i = 1 , j = 1 ; std :: vector < std :: pair < int , int >> segments ; segments . reserve ( n ); std :: vector < int > start ( n + 1 , -1 ), end ( n + 1 , -1 ); while ( j < n + 1 ) { int def_value = s [ j ] - s [ i - 1 ]; if ( def_value == k ) { segments . emplace_back ( i , j ); int seg_id = segments . size () - 1 ; end [ j ] = seg_id ; start [ i ] = seg_id ; i ++ ; j ++ ; } else if ( def_value > k ) { i ++ ; if ( i > j ) j ++ ; } else { j ++ ; } } int num_segments = segments . size (); // compute *to* vector to save computation std :: vector < int > to ( num_segments , num_segments ); std :: vector < int > closed ; for ( int l = 1 ; l < n + 1 ; ++ l ) { if ( start [ l ] != -1 ) { // every segment gets iterated at most once // total runtime is O(2*n) for ( auto it : closed ) to [ it ] = start [ l ]; closed . clear (); } if ( end [ l ] != -1 ) closed . emplace_back ( end [ l ]); } // dynamic program std :: vector < std :: vector < int >> memo ( num_segments , std :: vector < int > ( m , -2 )); int max_value = step ( 0 , 0 , m , num_segments , to , segments , memo ); if ( max_value > -1 ) cout << max_value << endl ; else cout << \"fail\" << endl ; } int main () { std :: ios_base :: sync_with_stdio ( false ); int t ; std :: cin >> t ; for ( int i = 0 ; i < t ; ++ i ) { testcase (); } return 0 ; }","title":"Solution"},{"location":"Algorithms%20Lab/pows/pows/#motorcycles","text":"","title":"MotorCycles"},{"location":"Algorithms%20Lab/pows/pows/#problem_3","text":"Find lucky bikers that driver forever and start from vertical line.","title":"Problem"},{"location":"Algorithms%20Lab/pows/pows/#difficulties_3","text":"Runtime Analysis (How to proof runtime?), sorting with tracking permutation","title":"Difficulties"},{"location":"Algorithms%20Lab/pows/pows/#techniques_3","text":"CGAL, Intersection","title":"Techniques"},{"location":"Algorithms%20Lab/pows/pows/#solution_3","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 #include <iostream> #include <vector> #include <algorithm> #include <stack> #include <CGAL/Exact_predicates_exact_constructions_kernel.h> typedef CGAL :: Exact_predicates_exact_constructions_kernel K ; typedef K :: Ray_2 R ; typedef K :: Point_2 P ; using namespace std ; void testcase () { int n ; cin >> n ; vector < pair < long , int >> y1_n_id ( n ); y1_n_id . reserve ( n ); vector < R > rays ( n ); rays . reserve ( n ); for ( int i = 0 ; i < n ; ++ i ) { long y1 , x2 , y2 ; cin >> y1 >> x2 >> y2 ; rays [ i ] = R ( P ( 0 , y1 ), P ( x2 , y2 )); y1_n_id [ i ] = make_pair ( y1 , i ); } sort ( y1_n_id . begin (), y1_n_id . end (), std :: greater <> ()); vector < int > luckyDrivers ; for ( int i = 0 ; i < n ; ++ i ) { int rid = y1_n_id [ i ]. second ; auto ray = rays [ rid ]; /* * NOTE the runtime is O(n) even though we iterate over lucky drivers. * However, since we stop the iteration as soon as there is no intersection. * Hence, every lucky driver except the last one will be iterated at most twice. * If the next ray r2 is parallel to r1, r2 will be a lucky * driver as well. If that is the case and there is another ray r3 that * intersects with r2, then also r3 intersects with r1 and r1 will be deleted. */ while ( true ) { if ( luckyDrivers . empty ()) { luckyDrivers . emplace_back ( rid ); break ; } else { auto ray2 = rays [ luckyDrivers . back ()]; // check if drivers intersect if ( CGAL :: do_intersect ( ray , ray2 )) { auto o = CGAL :: intersection ( ray , ray2 ); if ( const P * op = boost :: get < P > ( &* o )) { auto d1 = CGAL :: squared_distance ( * op , ray . source ()); auto d2 = CGAL :: squared_distance ( * op , ray2 . source ()); // check which is first if ( d1 <= d2 ) { luckyDrivers . pop_back (); } else { break ; } } } else { luckyDrivers . emplace_back ( rid ); break ; } } } } sort ( luckyDrivers . begin (), luckyDrivers . end ()); for ( auto id : luckyDrivers ) cout << id << \" \" ; cout << endl ; } int main () { ios_base :: sync_with_stdio ( false ); int t ; cin >> t ; while ( t -- ) testcase (); }","title":"Solution"},{"location":"Algorithms%20Lab/pows/pows/#tracking","text":"","title":"Tracking"},{"location":"Algorithms%20Lab/pows/pows/#problem_4","text":"","title":"Problem"},{"location":"Algorithms%20Lab/pows/pows/#difficulties_4","text":"","title":"Difficulties"},{"location":"Algorithms%20Lab/pows/pows/#techniques_4","text":"","title":"Techniques"},{"location":"Algorithms%20Lab/pows/pows/#solution_4","text":"","title":"Solution"},{"location":"Algorithms%20Lab/pows/pows/#octopussy","text":"","title":"Octopussy"},{"location":"Algorithms%20Lab/pows/pows/#problem_5","text":"","title":"Problem"},{"location":"Algorithms%20Lab/pows/pows/#difficulties_5","text":"Proofing greedy (Proof by replacement), Reading things correctly","title":"Difficulties"},{"location":"Algorithms%20Lab/pows/pows/#techniques_5","text":"Greedy","title":"Techniques"},{"location":"Algorithms%20Lab/pows/pows/#solution_5","text":"Propagate minimum time from root to leaf nodes. Take always the node with the smallest time. Proof of correctness (proof by replacement (TODO?)): Let \\(V\\) denote the set of nodes that we have already visited. Let \\(v_n\\) denote the node that the greedy algorithm will visit next. Assume that we do not arrive in time for \\(v_n\\) , however, let's further assume that there is an optimal solution that arrives at \\(v_n\\) in time. Note that by design all nodes in \\(V\\) have to be visited before \\(v_n\\) . In order to arrive at \\(v_n\\) in time we would have to remove at least one node from \\(V\\) . However, this is a contradiction to our observation that all nodes in \\(V\\) have to be visited before \\(v_n\\) . Hence, if the greedy algorithm cannot visit all nodes in time then there is also no optimal solution that would achieve that. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 // // Created by Krispin Wandel on 15.01.21. // #include <iostream> #include <vector> #include <queue> using namespace std ; void testcase () { int n ; cin >> n ; vector < int > t ( n ); for ( int i = 0 ; i < n ; ++ i ) { cin >> t [ i ]; } vector < int > min_t ( n ); min_t [ 0 ] = t [ 0 ]; for ( int i = 1 ; i < n ; i += 2 ) { // children c_i,1 and c_i,2 of i: // c_i,1 = 2 * i + 1, // c_i,2 = 2 * i + 2 int parent = ( i - 1 ) / 2 ; min_t [ i ] = min ( min_t [ parent ] - 1 , t [ i ]); min_t [ i + 1 ] = min ( min_t [ parent ] - 1 , t [ i + 1 ]); } int counter = 0 ; bool is_possible = true ; vector < bool > visited ( n , false ); priority_queue < int , std :: vector < pair < int , int >> , std :: greater <>> pq ; // push leaf nodes for ( int i = ( n - 1 ) / 2 ; i < n ; ++ i ) { pq . push ( make_pair ( min_t [ i ], i )); } while ( ! pq . empty ()) { // get child with smallest min_t auto sel = pq . top (); pq . pop (); // check if we are in time if ( counter < sel . first ) { counter ++ ; } else { is_possible = false ; break ; } // push children to pq int i = sel . second ; visited [ i ] = true ; if ( i > 0 ) { bool is_second_child = i % 2 == 0 ; int parent = ( i - is_second_child * 2 - ! is_second_child * 1 ) / 2 ; // only checkout parent is neighbour has been visited as well if ( visited [ i - is_second_child + ! is_second_child ]) pq . push ( make_pair ( min_t [ parent ], parent )); } } if ( is_possible ) cout << \"yes\" ; else cout << \"no\" ; cout << endl ; } int main () { int t ; cin >> t ; while ( t -- ) testcase (); }","title":"Solution"},{"location":"Algorithms%20Lab/pows/pows/#surveillance-photographs","text":"","title":"Surveillance Photographs"},{"location":"Algorithms%20Lab/pows/pows/#problem_6","text":"","title":"Problem"},{"location":"Algorithms%20Lab/pows/pows/#difficulties_6","text":"Do not run breadth first search on maxflow graph. Reading things correctly. For first test set: police men starts and ends at the same police station.","title":"Difficulties"},{"location":"Algorithms%20Lab/pows/pows/#techniques_6","text":"Maximum Flow, Breadth First Search","title":"Techniques"},{"location":"Algorithms%20Lab/pows/pows/#solution_6","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 #include <iostream> #include <vector> #include <set> // BGL include #include <boost/graph/adjacency_list.hpp> // BGL flow include *NEW* #include <boost/graph/push_relabel_max_flow.hpp> #include <boost/graph/breadth_first_search.hpp> #include <boost/graph/properties.hpp> // Graph Type with nested interior edge properties for flow algorithms typedef boost :: adjacency_list_traits < boost :: vecS , boost :: vecS , boost :: directedS > traits ; typedef boost :: adjacency_list < boost :: vecS , boost :: vecS , boost :: directedS , boost :: no_property , boost :: property < boost :: edge_capacity_t , long , boost :: property < boost :: edge_residual_capacity_t , long , boost :: property < boost :: edge_reverse_t , traits :: edge_descriptor >>>> graph ; typedef boost :: adjacency_list < boost :: vecS , boost :: vecS , boost :: directedS > graph2 ; typedef traits :: vertex_descriptor vertex_desc ; typedef traits :: edge_descriptor edge_desc ; // For BFS typedef boost :: default_color_type color ; class edge_adder { graph & G ; public : explicit edge_adder ( graph & G ) : G ( G ) {} void add_edge ( int from , int to , long capacity ) { auto c_map = boost :: get ( boost :: edge_capacity , G ); auto r_map = boost :: get ( boost :: edge_reverse , G ); const auto e = boost :: add_edge ( from , to , G ). first ; const auto rev_e = boost :: add_edge ( to , from , G ). first ; c_map [ e ] = capacity ; c_map [ rev_e ] = 0 ; // reverse edge has no capacity! r_map [ e ] = rev_e ; r_map [ rev_e ] = e ; } }; using namespace std ; void testcase () { int n , m , k , l ; cin >> n >> m >> k >> l ; /** * n = #intersections * m = #one-way streets * k = #police stations * l = #photographs */ graph G ( n ); graph2 G2 ( n ); edge_adder adder ( G ); set < int > police ; vector < int > num_police ( n , 0 ); for ( int i = 0 ; i < k ; ++ i ) { int x ; cin >> x ; num_police [ x ] ++ ; police . insert ( x ); } set < int > photo ; vector < int > num_photo ( n , 0 ); for ( int i = 0 ; i < l ; ++ i ) { int x ; cin >> x ; num_photo [ x ] ++ ; photo . insert ( x ); } for ( int i = 0 ; i < m ; ++ i ) { int x , y ; cin >> x >> y ; adder . add_edge ( x , y , 1 ); boost :: add_edge ( x , y , G2 ); } // for each police station check which photos are reachable vector < vector < int >> police_to_photo ( n , vector < int > ()); for ( int x : police ) { // breadth first search std :: vector < color > vertex_color ( n ); // exterior property map // O(n + m) boost :: breadth_first_search ( G2 , x , boost :: color_map ( boost :: make_iterator_property_map ( vertex_color . begin (), boost :: get ( boost :: vertex_index , G )))); // O(n) const color black = boost :: color_traits < color >:: black (); // visited by BFS // const color white = boost::color_traits<color>::white(); for ( int xp : photo ) { if ( vertex_color [ xp ] == black ) { police_to_photo [ x ]. emplace_back ( xp ); } } } // add capacity to photo nodes for ( int x : photo ) { adder . add_edge ( n + x , x , num_photo [ x ]); } // Add special vertices source and sink const vertex_desc v_source = boost :: add_vertex ( G ); const vertex_desc v_sink = boost :: add_vertex ( G ); // create flow graph to solve problem for ( int x : police ) { vertex_desc v_source_police = boost :: add_vertex ( G ); adder . add_edge ( v_source , v_source_police , num_police [ x ]); for ( int xp : police_to_photo [ x ]) { // NOTE capacity for this edge could be infinity adder . add_edge ( v_source_police , n + xp , num_photo [ xp ]); } adder . add_edge ( x , v_sink , num_police [ x ]); } // check max flow long flow = boost :: push_relabel_max_flow ( G , v_source , v_sink ); cout << flow << endl ; } int main () { ios_base :: sync_with_stdio ( false ); int t ; cin >> t ; while ( t -- ) testcase (); }","title":"Solution"},{"location":"Sem6/ASL/asl/","text":"Advanced Systems Lab lectures Lecture 2 - Performance Cost Analysis \\(\\Theta\\) , \\(\\Omega\\) and \\(O\\) describe sets and are related through: \\[\\Theta = \\Omega \\cap O\\] What can be analyzed? Runtime Space (= memory footprint) Data movement (e.g. between cache and memory) Memory accesses only add a constant factor to the asymptopic runtime. Goal: Exact cost of an algorithm Cost = number of relevant (e.g. adds, mults, divs) operations, only the operations that constitute the mathematical algorithm . How to do cost analysis? Define suitable cost measure Count in algorithm or code (Recursive function -> solve recurrence) Instrument Code (?) Performance Counters Cost Analysis enables Performance Analysis which is bounded by machine's peak performance : \\[ \\text{performance} = \\frac{\\text{cost}}{\\text{runtime or cycles}}\\] Lecture 3 - Architecture/ Microarchitecture and Intel Core Architecture = instruction set architecture = ISA = Part of processor design that needs to understand to write assembly code. (intstruction set specifications, registers) x86 backwards compatible to 8086 processor. ISA SIMD Vector extensions Parallel computation on short integer/float vectors (length 2-8) Useful and easy to build FMA = Fused Multiply-Add Only one rounding step \\(\\rightarrow\\) better accuracy Microarchitecture = Implementation of the architecture ld = load, st = store CISC ops (Complex instruction set computer) -> decoded -> RISC ops (Reduced instruction set computer) DCache = Double Cache ICache = Instruction Cache Runtime Lower Bounds (Cycles) TODO why 50% peak performance when n/4 In Haswell, to write a variable, the variable has to be loaded as well. Operational Intensity \\[ I(n) = \\frac{W(n)}{Q(n)} \\] where \\(W(n)\\) = number of flops and \\(Q(n)\\) = number of memory transfers (usually only reads) in bytes . Memory/Compute Bound Compute bound = high operational density memory bound = low operational density Later: Roofline model Superscalar Computer Multiple instructions per cycle Mapping of execution units to ports Instructions are pipelined (latency = number of cycles a operation takes to execute) However, we cannot issue a division every cycle (look at throughput) fma can be used for add and mult Lecture 4 - Optimizing for Instruction-Level Parallelism How to get OP / cycle close to throughput? Example: Reduce OP (OP = * or +) Naive Approach Time (Cycles): N * Latency With K Accumulators Time Minimum achievable (is we get close to throughput): ceil(N / throughput) + latency - 1 K = #accumulators = ceil(latency/ gap) = ceil(latency * throughput) Note: Loop unrolling factor L equals K. Loop untrolling does not help. May be needed to enable additional transformations (e.g. reassociation Reassociation changes result for floating point OPs ) Lecture 5 - Compiler Optimizations Pre-computations - TODO - Strength Reduction (replace mult/div with sum/diff) - Share Common Subexpressions (exploit arithmetic preoperties) Function inlining Optimization Blockers: - Procedure Calls - Memory Aliasing -> remove -> allocating register Lecture 6 - SIMD extensions, AVX, vectorization SSE nearly obsolete - replaced by AVX mm = multi media xmm, ymm, zmm Lexture 7 - SIMD extensions, AVX, vectorization cont'd AVX Intrinsics We can use intrinsics operations to avoid memory aliasing image filters (moving average) Furier butterfly operations Lecture 8 - Memory hierarchy, locality, caches Processor-memory bottleneck Locality temporal (loops, also in code) spatial (also registers count, tranfer data in blocks 64 Byte) Policies of Cache Placement Replacement Types of Cache Misses Compulsory (cold): Occurs on first access to a block Capacity: Working set is larger than the cache Conflict: Cache large enough, but multiple data objects all map to the same slot Cache structure E = ?, B = block size, S = number of sets Cache performance metrics miss rate hit time miss penalty Writes Write-back/ write-allocate Write-through/ no-write-allocate Lecture 9 - Memory hierarchy, locality, caches cont'd S = W = C = update only updates one double use blocks in Matrix-Matrix-Multiplications for locality The Killer: Two-Power Strided Working Sets - Occurence: - Image processing Lecture 11 - Roofline model log - log plot -> polynomials become lines Roofline -> one takes only data movements into account and NOT data dependencies (which could still lead to tighter memory bounds) For data movement only consider the highest order time. If data is used more than once, we only give a lower bound because we neglect potential cache misses. TOOD Roofline for parallel code -> FLOPS/cycle does not increase but only bandwidth?? Dense linear algebra, LAPACK/BLAS, ATLAS, fast MMM LAPACK relies on low level BLAS functions BLAS functions have to be re-implemented for each new processor ATLAS first determines various hardware parameters (such as latency) through measurements, and then performs an excessive search over a pre-defined search space of parameters needed to generate BLAS functions. In each search iteration the performance of the BLAS function is measured and used as feedback for the search direction. In 2005, model-based code generating (replace search with model) TODO recap some concepts Blocking for Registers Dependencies Read after write (or true dependency) Write after read (or antidependency) -> rename, compiler, hardware Write after write (or output dependency) -> rename Virtual Memory System Sparse Linear algebra Sparse MVM CSR format -> store col indices and row-start indices Poor temporal locality for x but spatial locality in all arrays Temporal locality in y Block MVM BCSR format -> store all blocks that are not completely zero More memory, less indices, temporal locality in x Block sizes hard to predict TODO recap model Discrete Fourier transform, fast Fourier transform","title":"Lectures"},{"location":"Sem6/ASL/asl/#advanced-systems-lab-lectures","text":"","title":"Advanced Systems Lab lectures"},{"location":"Sem6/ASL/asl/#lecture-2-performance-cost-analysis","text":"\\(\\Theta\\) , \\(\\Omega\\) and \\(O\\) describe sets and are related through: \\[\\Theta = \\Omega \\cap O\\] What can be analyzed? Runtime Space (= memory footprint) Data movement (e.g. between cache and memory) Memory accesses only add a constant factor to the asymptopic runtime. Goal: Exact cost of an algorithm Cost = number of relevant (e.g. adds, mults, divs) operations, only the operations that constitute the mathematical algorithm . How to do cost analysis? Define suitable cost measure Count in algorithm or code (Recursive function -> solve recurrence) Instrument Code (?) Performance Counters Cost Analysis enables Performance Analysis which is bounded by machine's peak performance : \\[ \\text{performance} = \\frac{\\text{cost}}{\\text{runtime or cycles}}\\]","title":"Lecture 2 - Performance Cost Analysis"},{"location":"Sem6/ASL/asl/#lecture-3-architecture-microarchitecture-and-intel-core","text":"","title":"Lecture 3 - Architecture/ Microarchitecture and Intel Core"},{"location":"Sem6/ASL/asl/#architecture","text":"= instruction set architecture = ISA = Part of processor design that needs to understand to write assembly code. (intstruction set specifications, registers) x86 backwards compatible to 8086 processor.","title":"Architecture"},{"location":"Sem6/ASL/asl/#isa-simd-vector-extensions","text":"Parallel computation on short integer/float vectors (length 2-8) Useful and easy to build","title":"ISA SIMD Vector extensions"},{"location":"Sem6/ASL/asl/#fma-fused-multiply-add","text":"Only one rounding step \\(\\rightarrow\\) better accuracy","title":"FMA = Fused Multiply-Add"},{"location":"Sem6/ASL/asl/#microarchitecture","text":"= Implementation of the architecture ld = load, st = store CISC ops (Complex instruction set computer) -> decoded -> RISC ops (Reduced instruction set computer) DCache = Double Cache ICache = Instruction Cache","title":"Microarchitecture"},{"location":"Sem6/ASL/asl/#runtime-lower-bounds-cycles","text":"TODO why 50% peak performance when n/4 In Haswell, to write a variable, the variable has to be loaded as well.","title":"Runtime Lower Bounds (Cycles)"},{"location":"Sem6/ASL/asl/#operational-intensity","text":"\\[ I(n) = \\frac{W(n)}{Q(n)} \\] where \\(W(n)\\) = number of flops and \\(Q(n)\\) = number of memory transfers (usually only reads) in bytes .","title":"Operational Intensity"},{"location":"Sem6/ASL/asl/#memorycompute-bound","text":"Compute bound = high operational density memory bound = low operational density Later: Roofline model","title":"Memory/Compute Bound"},{"location":"Sem6/ASL/asl/#superscalar-computer","text":"Multiple instructions per cycle","title":"Superscalar Computer"},{"location":"Sem6/ASL/asl/#mapping-of-execution-units-to-ports","text":"Instructions are pipelined (latency = number of cycles a operation takes to execute) However, we cannot issue a division every cycle (look at throughput) fma can be used for add and mult","title":"Mapping of execution units to ports"},{"location":"Sem6/ASL/asl/#lecture-4-optimizing-for-instruction-level-parallelism","text":"","title":"Lecture 4 - Optimizing for Instruction-Level Parallelism"},{"location":"Sem6/ASL/asl/#how-to-get-op-cycle-close-to-throughput","text":"Example: Reduce OP (OP = * or +)","title":"How to get OP / cycle close to throughput?"},{"location":"Sem6/ASL/asl/#naive-approach","text":"Time (Cycles): N * Latency","title":"Naive Approach"},{"location":"Sem6/ASL/asl/#with-k-accumulators","text":"Time Minimum achievable (is we get close to throughput): ceil(N / throughput) + latency - 1 K = #accumulators = ceil(latency/ gap) = ceil(latency * throughput) Note: Loop unrolling factor L equals K. Loop untrolling does not help. May be needed to enable additional transformations (e.g. reassociation Reassociation changes result for floating point OPs )","title":"With K Accumulators"},{"location":"Sem6/ASL/asl/#lecture-5-compiler-optimizations","text":"Pre-computations - TODO - Strength Reduction (replace mult/div with sum/diff) - Share Common Subexpressions (exploit arithmetic preoperties) Function inlining Optimization Blockers: - Procedure Calls - Memory Aliasing -> remove -> allocating register","title":"Lecture 5 - Compiler Optimizations"},{"location":"Sem6/ASL/asl/#lecture-6-simd-extensions-avx-vectorization","text":"SSE nearly obsolete - replaced by AVX mm = multi media xmm, ymm, zmm","title":"Lecture 6 - SIMD extensions, AVX, vectorization"},{"location":"Sem6/ASL/asl/#lexture-7-simd-extensions-avx-vectorization-contd","text":"AVX Intrinsics We can use intrinsics operations to avoid memory aliasing image filters (moving average) Furier butterfly operations","title":"Lexture 7 - SIMD extensions, AVX, vectorization cont'd"},{"location":"Sem6/ASL/asl/#lecture-8-memory-hierarchy-locality-caches","text":"","title":"Lecture 8 - Memory hierarchy, locality, caches"},{"location":"Sem6/ASL/asl/#processor-memory-bottleneck","text":"","title":"Processor-memory bottleneck"},{"location":"Sem6/ASL/asl/#locality","text":"temporal (loops, also in code) spatial (also registers count, tranfer data in blocks 64 Byte)","title":"Locality"},{"location":"Sem6/ASL/asl/#policies-of-cache","text":"Placement Replacement","title":"Policies of Cache"},{"location":"Sem6/ASL/asl/#types-of-cache-misses","text":"Compulsory (cold): Occurs on first access to a block Capacity: Working set is larger than the cache Conflict: Cache large enough, but multiple data objects all map to the same slot","title":"Types of Cache Misses"},{"location":"Sem6/ASL/asl/#cache-structure","text":"E = ?, B = block size, S = number of sets","title":"Cache structure"},{"location":"Sem6/ASL/asl/#cache-performance-metrics","text":"miss rate hit time miss penalty","title":"Cache performance metrics"},{"location":"Sem6/ASL/asl/#writes","text":"Write-back/ write-allocate Write-through/ no-write-allocate","title":"Writes"},{"location":"Sem6/ASL/asl/#lecture-9-memory-hierarchy-locality-caches-contd","text":"S = W = C = update only updates one double use blocks in Matrix-Matrix-Multiplications for locality The Killer: Two-Power Strided Working Sets - Occurence: - Image processing","title":"Lecture 9 - Memory hierarchy, locality, caches cont'd"},{"location":"Sem6/ASL/asl/#lecture-11-roofline-model","text":"log - log plot -> polynomials become lines Roofline -> one takes only data movements into account and NOT data dependencies (which could still lead to tighter memory bounds) For data movement only consider the highest order time. If data is used more than once, we only give a lower bound because we neglect potential cache misses. TOOD Roofline for parallel code -> FLOPS/cycle does not increase but only bandwidth??","title":"Lecture 11 - Roofline model"},{"location":"Sem6/ASL/asl/#dense-linear-algebra-lapackblas-atlas-fast-mmm","text":"LAPACK relies on low level BLAS functions BLAS functions have to be re-implemented for each new processor ATLAS first determines various hardware parameters (such as latency) through measurements, and then performs an excessive search over a pre-defined search space of parameters needed to generate BLAS functions. In each search iteration the performance of the BLAS function is measured and used as feedback for the search direction. In 2005, model-based code generating (replace search with model) TODO recap some concepts","title":"Dense linear algebra, LAPACK/BLAS, ATLAS, fast MMM"},{"location":"Sem6/ASL/asl/#blocking-for-registers","text":"","title":"Blocking for Registers"},{"location":"Sem6/ASL/asl/#dependencies","text":"Read after write (or true dependency) Write after read (or antidependency) -> rename, compiler, hardware Write after write (or output dependency) -> rename","title":"Dependencies"},{"location":"Sem6/ASL/asl/#virtual-memory-system","text":"","title":"Virtual Memory System"},{"location":"Sem6/ASL/asl/#sparse-linear-algebra","text":"","title":"Sparse Linear algebra"},{"location":"Sem6/ASL/asl/#sparse-mvm","text":"CSR format -> store col indices and row-start indices Poor temporal locality for x but spatial locality in all arrays Temporal locality in y","title":"Sparse MVM"},{"location":"Sem6/ASL/asl/#block-mvm","text":"BCSR format -> store all blocks that are not completely zero More memory, less indices, temporal locality in x Block sizes hard to predict TODO recap model","title":"Block MVM"},{"location":"Sem6/ASL/asl/#discrete-fourier-transform-fast-fourier-transform","text":"","title":"Discrete Fourier transform, fast Fourier transform"},{"location":"Sem6/ASL/project/","text":"T-SNE","title":"Project (t-SNE)"},{"location":"Sem6/ASL/project/#t-sne","text":"","title":"T-SNE"},{"location":"Sem6/ASL/homeworks/hw1/sol/","text":"Homework 1 Krispin Wandel, 15-941-388 NOTE For all compilations I used gcc 9.3.0 1 Get to know your machine a) - d) | Param | Value| | -- | -- | | Processor Manufacturer / Name / Number | Intel / i7 / i7-10700KF | CPU base frequency | 3.80 GHz | CPU maximum frequency| 5.10 GHz (with Intel\u00ae Turbo Boost Max Technology 3.0) | Development phase| Optimization e) My processor is based on the Skylake architecture and therefore supports FMA. FMA performs 2 floating point instructions and has a throughput of 2. There do not exist operations that perform more than 2 floating point operations or have throughput greater than 2. Hence, the theoretical peak performance is 4 flops / cycle . f) & g) | Operation | Latency [cycles] | Throughput [ops/cycle] | | - | - | - | | FMA| 4 | 2 | Comparison OP| 1 | 2 h) ADDSD gcc -S -fverbose-asm -O3 add.c i) For 80-bit operations and because of backwards compatibility. 2 Matrix Vector Multiplication a) [nothing to answer] b) \\(n^2\\) additions, \\(n^2\\) multiplications c) @import \"./results/ex02_fig1.svg\" d) Compiling the code with the -O0 flag results in low performance since no optimizations are performed. With the -O3 -fno-tree-vectorize flags, we can significantly increase the performance. However, the reduction operation in the inner loop of the compute function is a bottleneck for the computation because of serial computation and, thus, reduces the amount of ILP. Compiling the code with -O3 -ffast-math -march=native makes the program much faster. First, the -ffast-math flag gives the compiler more options to use arithmetic rules in such a way to increase ILP. Secondly, by replacing the -fno-tree-vectorize flag with -march=native we can further speedup the program by using CPU specific instructions, including vector instructions. However, from the experiment we can clearly see that the computation is inherently memory bound. The first drop in the green curve at \\(n=400\\) occurs because the data no longer fits into the L2 Cache. Another big drop at \\(n=1400\\) indicates that the L3 Cache is maxed out. 3 Performance Analysis and Bounds a) Since the algorithm only involves addition and multiplication, we define the cost measure as the count of floating point additions and multiplications. $$ C(n) = C_{\\text{add}} \\cdot n_{\\text{add}} + C_{\\text{mul}} \\cdot n_{\\text{mul}} $$ b) For combination we have to perform 2 additions and 4 multiplications. Hence, we get the following cost for a vector of length \\(n\\) : $$ \\begin{aligned} n_{\\text{add}} &= 2n \\ n_{\\text{mul}} &= 4n \\ C(n) &= C_{\\text{add}} \\cdot 2n + C_{\\text{mul}} \\cdot 4n \\end{aligned} $$ c) On Haswell, we can use 1 port for floating point additions and 2 ports for floating point multiplications. Therefore, the lower bound \\(l(n)\\) for the number of cycles is: $$ l(n) = \\max \\left(\\frac{2n}{1}, \\frac{4n}{2} \\right) = 2n $$ The operation can also be rewritten with 2 multiplications and 2 fma instructions: double t1 , t2 , t3 ; t1 = u [ i ] * u [ i ]; t2 = x [ i ] * y [ i ]; t3 = z [ i ] + t1 * u [ i ]; z [ i ] = t3 + t2 * z [ i ]; Since fma instructions can be scheduled on 2 ports, we get the following lower bound: $$ l_{\\text{FMA}}(n) = \\max \\left(\\frac{2n}{2}, \\frac{2n}{2} \\right) = n $$ We have to load \\(x, y, z, u\\) which results in a total of \\(4n\\) reads. Hence, we get the following answers: L1 Cache has a maximum load throughput of 8. Therefore, the lower bound for the number of cycles is: $$ l_{\\text{L1}}(n) = \\frac{4n}{8} = \\frac{n}{2} $$ RAM has a maximum load throughput of 2. Hence: $$ l_{\\text{RAM}}(n) = \\frac{4n}{2} = 2n $$ d) We need to read a total of $$ Q_{\\text{read}}(n) = 4n \\cdot8 \\, \\text{bytes}= 32n\\, \\text{bytes} $$ bytes (64 bits = 8 bytes). Since we have to perform \\(6n\\) floating point operations in total, we get: $$ I(n) \\leq \\frac{W(n)}{Q_{\\text{read}}(n)} = \\frac{6n \\, \\text{flops}}{32n \\, \\text{bytes}} = 0.1875 \\, \\frac{\\text{flops}}{\\text{bytes}} $$ 4 Scalar Product a) & b) @import \"./results/ex04_fig1_10accum.svg\" c) The highest performance I achieved was \\(1.68\\, \\frac{\\text{flops}}{\\text{cycle}}\\) using \\(K=10\\) accumulators that increase ILP. Theoretically, because both fAdd and fMult have a latency of 4 and throughput of 2 on my CPU, the best number of accumulators should be \\(K = 2 \\cdot (4+4) = 16\\) . However, I consistenly got better performance with only 10 accumulators. The red curve first increases which is likely due to the overhead of the accumulators for small \\(n\\) . However, the performance quickly drops at \\(n=4096\\) because the data does no longer fit into the L2 Cache and because the computation is inherently memory bound. Another drop occurs at \\(n=2^{20}\\) because the L3 Cache is maxed out. When the L3 Cache is full we can also see a drop in the blue curve for the same reason. Finally, one can observe that the blue curve decreases in the begginning, which might be because the compiler made some clever optimizations suitable only for small \\(n\\) . d) [nothing to answer] 5 ILP Analysis a) Throughput and gap for floating point addition and multiplication on Haswell: Operation Latency Gap MULT 5 2 ADD 3 1 Dependency graph : The given code snippet double artcomp ( double a , double b , double c ) { double r ; r = ( a + b ) * ( b + c ) + a * c ; return r ; } is equal to (without simplifying arithmetic): double artcomp ( double a , double b , double c ) { double r , t1 , t2 , t3 , t4 ; t1 = a * c ; t2 = a + b ; t3 = b + c ; t4 = t2 * t3 ; r = t1 + t4 ; return r ; } Best possible schedule of operations : Cycle Port 0 (MULT) Port 1 (MULT + ADD) 1 t1 t2 2 t1 t2, t3 3 t1 t2, t3 4 t1 t3 5 t1 t4 6 t4 7 t4 8 t4 9 t4 10 r 11 r 12 r \u2794 artcomp needs at least 12 cycles .","title":"Homework 1"},{"location":"Sem6/ASL/homeworks/hw1/sol/#homework-1","text":"Krispin Wandel, 15-941-388 NOTE For all compilations I used gcc 9.3.0","title":"Homework 1"},{"location":"Sem6/ASL/homeworks/hw1/sol/#1-get-to-know-your-machine","text":"a) - d) | Param | Value| | -- | -- | | Processor Manufacturer / Name / Number | Intel / i7 / i7-10700KF | CPU base frequency | 3.80 GHz | CPU maximum frequency| 5.10 GHz (with Intel\u00ae Turbo Boost Max Technology 3.0) | Development phase| Optimization e) My processor is based on the Skylake architecture and therefore supports FMA. FMA performs 2 floating point instructions and has a throughput of 2. There do not exist operations that perform more than 2 floating point operations or have throughput greater than 2. Hence, the theoretical peak performance is 4 flops / cycle . f) & g) | Operation | Latency [cycles] | Throughput [ops/cycle] | | - | - | - | | FMA| 4 | 2 | Comparison OP| 1 | 2 h) ADDSD gcc -S -fverbose-asm -O3 add.c i) For 80-bit operations and because of backwards compatibility.","title":"1 Get to know your machine"},{"location":"Sem6/ASL/homeworks/hw1/sol/#2-matrix-vector-multiplication","text":"a) [nothing to answer] b) \\(n^2\\) additions, \\(n^2\\) multiplications c) @import \"./results/ex02_fig1.svg\" d) Compiling the code with the -O0 flag results in low performance since no optimizations are performed. With the -O3 -fno-tree-vectorize flags, we can significantly increase the performance. However, the reduction operation in the inner loop of the compute function is a bottleneck for the computation because of serial computation and, thus, reduces the amount of ILP. Compiling the code with -O3 -ffast-math -march=native makes the program much faster. First, the -ffast-math flag gives the compiler more options to use arithmetic rules in such a way to increase ILP. Secondly, by replacing the -fno-tree-vectorize flag with -march=native we can further speedup the program by using CPU specific instructions, including vector instructions. However, from the experiment we can clearly see that the computation is inherently memory bound. The first drop in the green curve at \\(n=400\\) occurs because the data no longer fits into the L2 Cache. Another big drop at \\(n=1400\\) indicates that the L3 Cache is maxed out.","title":"2 Matrix Vector Multiplication"},{"location":"Sem6/ASL/homeworks/hw1/sol/#3-performance-analysis-and-bounds","text":"a) Since the algorithm only involves addition and multiplication, we define the cost measure as the count of floating point additions and multiplications. $$ C(n) = C_{\\text{add}} \\cdot n_{\\text{add}} + C_{\\text{mul}} \\cdot n_{\\text{mul}} $$ b) For combination we have to perform 2 additions and 4 multiplications. Hence, we get the following cost for a vector of length \\(n\\) : $$ \\begin{aligned} n_{\\text{add}} &= 2n \\ n_{\\text{mul}} &= 4n \\ C(n) &= C_{\\text{add}} \\cdot 2n + C_{\\text{mul}} \\cdot 4n \\end{aligned} $$ c) On Haswell, we can use 1 port for floating point additions and 2 ports for floating point multiplications. Therefore, the lower bound \\(l(n)\\) for the number of cycles is: $$ l(n) = \\max \\left(\\frac{2n}{1}, \\frac{4n}{2} \\right) = 2n $$ The operation can also be rewritten with 2 multiplications and 2 fma instructions: double t1 , t2 , t3 ; t1 = u [ i ] * u [ i ]; t2 = x [ i ] * y [ i ]; t3 = z [ i ] + t1 * u [ i ]; z [ i ] = t3 + t2 * z [ i ]; Since fma instructions can be scheduled on 2 ports, we get the following lower bound: $$ l_{\\text{FMA}}(n) = \\max \\left(\\frac{2n}{2}, \\frac{2n}{2} \\right) = n $$ We have to load \\(x, y, z, u\\) which results in a total of \\(4n\\) reads. Hence, we get the following answers: L1 Cache has a maximum load throughput of 8. Therefore, the lower bound for the number of cycles is: $$ l_{\\text{L1}}(n) = \\frac{4n}{8} = \\frac{n}{2} $$ RAM has a maximum load throughput of 2. Hence: $$ l_{\\text{RAM}}(n) = \\frac{4n}{2} = 2n $$ d) We need to read a total of $$ Q_{\\text{read}}(n) = 4n \\cdot8 \\, \\text{bytes}= 32n\\, \\text{bytes} $$ bytes (64 bits = 8 bytes). Since we have to perform \\(6n\\) floating point operations in total, we get: $$ I(n) \\leq \\frac{W(n)}{Q_{\\text{read}}(n)} = \\frac{6n \\, \\text{flops}}{32n \\, \\text{bytes}} = 0.1875 \\, \\frac{\\text{flops}}{\\text{bytes}} $$","title":"3 Performance Analysis and Bounds"},{"location":"Sem6/ASL/homeworks/hw1/sol/#4-scalar-product","text":"a) & b) @import \"./results/ex04_fig1_10accum.svg\" c) The highest performance I achieved was \\(1.68\\, \\frac{\\text{flops}}{\\text{cycle}}\\) using \\(K=10\\) accumulators that increase ILP. Theoretically, because both fAdd and fMult have a latency of 4 and throughput of 2 on my CPU, the best number of accumulators should be \\(K = 2 \\cdot (4+4) = 16\\) . However, I consistenly got better performance with only 10 accumulators. The red curve first increases which is likely due to the overhead of the accumulators for small \\(n\\) . However, the performance quickly drops at \\(n=4096\\) because the data does no longer fit into the L2 Cache and because the computation is inherently memory bound. Another drop occurs at \\(n=2^{20}\\) because the L3 Cache is maxed out. When the L3 Cache is full we can also see a drop in the blue curve for the same reason. Finally, one can observe that the blue curve decreases in the begginning, which might be because the compiler made some clever optimizations suitable only for small \\(n\\) . d) [nothing to answer]","title":"4 Scalar Product"},{"location":"Sem6/ASL/homeworks/hw1/sol/#5-ilp-analysis","text":"a) Throughput and gap for floating point addition and multiplication on Haswell: Operation Latency Gap MULT 5 2 ADD 3 1 Dependency graph : The given code snippet double artcomp ( double a , double b , double c ) { double r ; r = ( a + b ) * ( b + c ) + a * c ; return r ; } is equal to (without simplifying arithmetic): double artcomp ( double a , double b , double c ) { double r , t1 , t2 , t3 , t4 ; t1 = a * c ; t2 = a + b ; t3 = b + c ; t4 = t2 * t3 ; r = t1 + t4 ; return r ; } Best possible schedule of operations : Cycle Port 0 (MULT) Port 1 (MULT + ADD) 1 t1 t2 2 t1 t2, t3 3 t1 t2, t3 4 t1 t3 5 t1 t4 6 t4 7 t4 8 t4 9 t4 10 r 11 r 12 r \u2794 artcomp needs at least 12 cycles .","title":"5 ILP Analysis"},{"location":"Sem6/ASL/homeworks/hw2/hw2_sol/","text":"Homework 2 Krispin Wandel, 15-941-388 1. Optimization Blockers a) Results of optimizations: Algorithm Runtime [cycles] Speedup slow_performance1 53300 - slow_performance2 6740 7.91 maxperformance 2767 19.26 Code of slow_performance1 as reference: c++ {.line-numbers} void slow_performance1(float* x, float *y, float *z, int n) { for (int i = 0; i < n - 2; i++) { x[i] = x[i] / M_SQRT2 + y[i] * C1; x[i+1] += z[(i % 4) * 10] * C2; x[i+2] += sin ((2 * M_PI * i) / 3) * y[i+2]; } } slow_performance2 : First, I split the loop inside slow_performance1 into three seperate loops where in each loop I optimized lines 3-5 accordingly. For each loop I did the following optimization: 1) [Line 3] Instead of dividing through M_SQRT2 in each iteration we can simply pre-compute 1 / M_SQRT2 and then perform a much cheaper multiplication in each iteration. 2) [Line 4] z[(i % 4) * 10] * C2 can be pre-computed as well as it takes on only four values. We can then create a for-loop where in each iteration we assign those four values to the next four entries. 3) [Line 5] Similar to the previous optimization, we can pre-compute sin ((2 * M_PI * i) / 3) as it evaluates either to zero or to +/- \\(\\sin(2 \\pi / 3)\\) . Again,we assign those three values to the next three entries in each iteration of the for-loop. maxperformance : It turns out that by merging those three for loops one can perform further simplifications. As the loop variable in loop (2) of slow_performance2 is increased by four and in loop (3) increased by three, I merged those loops by iterating over the next 12 (the least common multiple of 3 and 4) entries in each step. One can then simplify all computations to only 2 floating point multiplications and additions per entry in \\(x\\) . b) As seen from the table above, the maximum speedup I got was 19.26. c) The cost is roughly: \\[ C = 2n \\cdot C_\\text{add} + 2n \\cdot C_\\text{mult} \\] \\(n=1022\\) in all tests. Hence, maxperformance has a performance of $$ \\frac{4088\\ \\text{flops}}{2767\\ \\text{cycles}} = 1.48 \\frac{\\text{flops}}{\\text{cycles}} $$ 2. Microbenchmarks The following table summarizes the results from my micro-benchmarks: Operation Latency [cycles] Gap [cycles] Add 4.01 0.58 Div 14.03 4.01 Div (min) 13.03 4.01 Foo 18.04 4.01 Foo (min) 17.04 4.01 a) As we can see from the table above, the latency and gap of floating point addition and multiplication match the specifications provided by Intel. However, the gap of floating point addition deviates slightly more from its nominal value than the other operations, although not significantly. The reason for that is likely due to the simplicity of floating point addition and the overhead caused by the for and while loop involved in my measurement for add . Moreover, we can observe that the latency of floating point division decreases by a full cycle when we use trivial divisions such as \\(\\frac{1}{1}\\) or \\(\\frac{0}{1}\\) . b) The latency and gap of \\(f(x)\\) matches what we would expect. In order to compute \\(f(x)\\) we first have to invoke a fma operation and then a div operation. fma has a latency of 4 cycles and a gap of 0.5 cycles. Hence, the total latency is \\(4+14=18\\) cycles and the gap is equal to \\(max(0.5,4) = 4\\) cycles. Furthermore, \\(f(0) = \\frac{0}{1}\\) is a trivial division and therefore we get a minimum latency of 17 cycles. c) If fma is disabled, the latency will change, whereas the gap stays the same. In particular, the fma will change to an add and a mul . Note that the addition relies on the result of the multiplication, thus, add and mul cannot be executed in parallel. Both, floating point addition and multiplication, have a latency of 4 and a gap of 0.5 on Skylake. Hence, the total latency will be \\(8+14(13)=22(21)\\) . The gap stays the same as the gap of addition and multiplication is smaller than the gap of division.","title":"Homework 2"},{"location":"Sem6/ASL/homeworks/hw2/hw2_sol/#homework-2","text":"Krispin Wandel, 15-941-388","title":"Homework 2"},{"location":"Sem6/ASL/homeworks/hw2/hw2_sol/#1-optimization-blockers","text":"a) Results of optimizations: Algorithm Runtime [cycles] Speedup slow_performance1 53300 - slow_performance2 6740 7.91 maxperformance 2767 19.26 Code of slow_performance1 as reference: c++ {.line-numbers} void slow_performance1(float* x, float *y, float *z, int n) { for (int i = 0; i < n - 2; i++) { x[i] = x[i] / M_SQRT2 + y[i] * C1; x[i+1] += z[(i % 4) * 10] * C2; x[i+2] += sin ((2 * M_PI * i) / 3) * y[i+2]; } } slow_performance2 : First, I split the loop inside slow_performance1 into three seperate loops where in each loop I optimized lines 3-5 accordingly. For each loop I did the following optimization: 1) [Line 3] Instead of dividing through M_SQRT2 in each iteration we can simply pre-compute 1 / M_SQRT2 and then perform a much cheaper multiplication in each iteration. 2) [Line 4] z[(i % 4) * 10] * C2 can be pre-computed as well as it takes on only four values. We can then create a for-loop where in each iteration we assign those four values to the next four entries. 3) [Line 5] Similar to the previous optimization, we can pre-compute sin ((2 * M_PI * i) / 3) as it evaluates either to zero or to +/- \\(\\sin(2 \\pi / 3)\\) . Again,we assign those three values to the next three entries in each iteration of the for-loop. maxperformance : It turns out that by merging those three for loops one can perform further simplifications. As the loop variable in loop (2) of slow_performance2 is increased by four and in loop (3) increased by three, I merged those loops by iterating over the next 12 (the least common multiple of 3 and 4) entries in each step. One can then simplify all computations to only 2 floating point multiplications and additions per entry in \\(x\\) . b) As seen from the table above, the maximum speedup I got was 19.26. c) The cost is roughly: \\[ C = 2n \\cdot C_\\text{add} + 2n \\cdot C_\\text{mult} \\] \\(n=1022\\) in all tests. Hence, maxperformance has a performance of $$ \\frac{4088\\ \\text{flops}}{2767\\ \\text{cycles}} = 1.48 \\frac{\\text{flops}}{\\text{cycles}} $$","title":"1. Optimization Blockers"},{"location":"Sem6/ASL/homeworks/hw2/hw2_sol/#2-microbenchmarks","text":"The following table summarizes the results from my micro-benchmarks: Operation Latency [cycles] Gap [cycles] Add 4.01 0.58 Div 14.03 4.01 Div (min) 13.03 4.01 Foo 18.04 4.01 Foo (min) 17.04 4.01 a) As we can see from the table above, the latency and gap of floating point addition and multiplication match the specifications provided by Intel. However, the gap of floating point addition deviates slightly more from its nominal value than the other operations, although not significantly. The reason for that is likely due to the simplicity of floating point addition and the overhead caused by the for and while loop involved in my measurement for add . Moreover, we can observe that the latency of floating point division decreases by a full cycle when we use trivial divisions such as \\(\\frac{1}{1}\\) or \\(\\frac{0}{1}\\) . b) The latency and gap of \\(f(x)\\) matches what we would expect. In order to compute \\(f(x)\\) we first have to invoke a fma operation and then a div operation. fma has a latency of 4 cycles and a gap of 0.5 cycles. Hence, the total latency is \\(4+14=18\\) cycles and the gap is equal to \\(max(0.5,4) = 4\\) cycles. Furthermore, \\(f(0) = \\frac{0}{1}\\) is a trivial division and therefore we get a minimum latency of 17 cycles. c) If fma is disabled, the latency will change, whereas the gap stays the same. In particular, the fma will change to an add and a mul . Note that the addition relies on the result of the multiplication, thus, add and mul cannot be executed in parallel. Both, floating point addition and multiplication, have a latency of 4 and a gap of 0.5 on Skylake. Hence, the total latency will be \\(8+14(13)=22(21)\\) . The gap stays the same as the gap of addition and multiplication is smaller than the gap of division.","title":"2. Microbenchmarks"},{"location":"Sem6/ASL/homeworks/hw4/hw4/","text":"Homework 4 Krispin Wandel, 15-941-388 1. Associativity a) We have \\(W = 2*10=20\\) floating point operations. The byte transfer is equal to \\[ Q = \\text{\\#misses} \\cdot b, \\] where \\(b = 16\\ \\text{bytes}\\) is the block size of the cache. Hence, we can directly derive the operational intensity \\(I = W / Q\\) from the miss/hit pattern. The miss/hit pattern can be optained by first computing the set size \\(s\\) from the cache capacity \\(c = s \\cdot b \\cdot e = 128\\ \\text{bytes}\\) , where \\(e\\) is the associativity of the cache. Once we have the set size \\(s\\) , we just have to follow the LRU replacement strategy to obtain the corresponding miss/hit pattern. The table below summarizes the results: Associativity miss/hit pattern operational intensity 2 ( \\(s = 4\\) ) x: MMMHHHHMMH y: MMMMHMHHMH z: MMHHHHHHHH 13 misses \\(\\frac{20}{13 \\cdot 16} \\approx 0.096\\) 4 ( \\(s = 2\\) ) x: MMMMHHMMHH y: MMMMHMHHHM z: MMHHHHHHHH 14 misses \\(\\frac{20}{14 \\cdot 16} \\approx 0.089\\) b) 1. Access to x cannot have spatial locality because all accesses to x are 4 doubles apart from each other (and a block can only store two doubles). However, x[0], x[4], x[8] are accessed more than once and, in fact, we see from the miss/hit pattern that we could exploit this temporal locality . 2. The order y is accessed is as follows: 1, 4, 7, 2, 5, 0, 3, 6, 1, 4. As we can see, all elements from 0 to 7 are accessed and indices 1 and 4 are accessed twice. Moreover, z[0] and z[1] (or z[4], z[5]) are never accessed. Hence, x and y can both share the first cache set as we have 2-way associativity. Therefore, accesses to y benefit from both spatial and temporal locality . 2. Cache Mechanics From the cache specifications we can compute the set size \\(s = 384\\) . Furthermore, sizeof(struct_t) = 64 for PADDING_SIZE 1 and sizeof(struct_t) = 96 for PADDING_SIZE 5 . Moreover, for all \\(n\\) we get the same miss/ hit pattern for accesses to \\(A\\) as \\(A_{ij}\\) is only accessed once. Hence, we can only benefit from spatial locality as follows: c++ {.line-numbers} t = A[i*n + j].v; // miss, but will also load A[i*n + j].d for (int k = 0; k < 3; k++) { t += A[i*n + j].d[k]; // hit } for (int k = 0; k < 3; k++) { A[i*n + j].u[k] = 0; // k = 0 => miss, k = 1,2 => hit } // => 2 misses However, \\(B_{j0}, j=1 \\dots n,\\) is accessed \\(n\\) times and we can benefit from temporal locality. As we will see below, the miss rate depends on \\(n\\) . Finally, the total number of reads and writes is \\(9n^2\\) and we perform \\(4n^2\\) FLOPS. a) \\(n = 8\\) : \\(n^2 \\cdot 64\\ \\text{bytes} = 4096\\ \\text{bytes}\\) still fits into the cache. The miss/ hit pattern for \\(B\\) looks as follows: At \\(i = 0\\) we get \\(n\\) compulsory cache misses. For the next \\(n - 1\\) iterations, however, we get only one cache conflict miss as A[i*n+0] overwrites B[i*n] . In total, we have \\(2n^2 + n + n-1 = 143\\) cache misses and hence the miss rate is \\(\\frac{143}{9 \\cdot 64} \\approx 0.25\\) . The operational intensity is \\(I = \\frac{4 \\cdot 8^2\\ \\text{flops}}{143 \\cdot 32\\ \\text{byte}} \\approx 0.056\\ \\frac{\\text{flops}}{\\text{byte}}\\) . b) \\(n = 16\\) : For \\(n = 16\\) , in order to fit A (or B) into the cache we would need \\(16^2 \\cdot 64 / 32 = 512\\) cache blocks which is a third more than the cache set size. Hence, when we consecutively access \\(B_{j0},\\ j = 0 \\dots 15\\) the first four entries of B that we loaded into the cache, \\(B_{j0},\\ j = 0 \\dots 3\\) , are overwritten. For \\(i = 0\\) we get again \\(n\\) compulsory cache misses for B, but for \\(i = 1 \\dots 3\\) we now get \\(2 \\cdot 4 = 8\\) conflict misses instead of only one and for \\(i = 4 \\dots 15\\) we get one additional conflict miss because of the access to A[i*n] . In total, we have \\(2 \\cdot 16^2 + 16 + 3 * 8 + 12 * 9 = 660\\) cache misses and hence the miss rate is \\(\\frac{660}{9 \\cdot 256} \\approx 0.29\\) . The operational intensity is \\(I = \\frac{4 \\cdot 16^2\\ \\text{flops}}{660 \\cdot 32\\ \\text{byte}} \\approx 0.048\\ \\frac{\\text{flops}}{\\text{byte}}\\) . c) \\(n = 16\\) with PADDING_SIZE 5 : In this setting A (or B) is exactly twice as large as the cache capacity. Hence, we can no longer benefit from temporal locality for accesses to B. Therefore, the total number of misses is \\(2n^2 + n^2 = 3n^2\\) and the miss rate is \\(\\frac{3n^2}{9n^2} = \\frac{1}{3} \\approx 0.33\\) . The operational intensity is \\(I = \\frac{4 \\cdot 16^2\\ \\text{flops}}{768 \\cdot 32\\ \\text{byte}} \\approx 0.042\\ \\frac{\\text{flops}}{\\text{byte}}\\) . 3. Rooflines a) We have the following relationships between work \\(W\\) , byte transfer \\(Q\\) , operational intensity \\(I\\) , performance \\(P\\) and bandwidth \\(\\beta\\) . \\[ \\begin{aligned} I(n) &= \\frac{W(n)}{Q(n)} \\\\ P(n) &= \\frac{W(n)}{T(n)} \\\\ \\beta &\\geq \\frac{Q}{T} = \\frac{W}{T} \\div \\frac{W}{Q} = \\frac{P}{I} \\\\ \\log{P} &\\leq \\log{\\beta} + \\log{I} \\leq \\log{\\pi}, \\end{aligned} \\] where \\(\\pi\\) is the peak performance which is attained at \\(I = \\frac{\\pi}{\\beta}\\) . We can compute \\(\\beta\\) from the given specifications: $$ \\beta = 50 \\frac{\\text{GB}}{\\text{s}} = 50 \\frac{\\text{GB}}{2 \\cdot 10^9 \\text{cycle}} = 25 \\frac{\\text{byte}}{\\text{cycle}} $$ As the processor can issue 2 FMAs per cycle we get a peak performance of 4 FLOPs per cycle without vector instructions. With vector instructions we can do 8 FMAs per cycle and hence we get a peak performance of 16 FLOPs per cycle . b) I denote \\(I_u\\) the hard upper bound to the ooperational intensity \\(I\\) . The table below summarizes the results: function W(n) Q(n) \\(I_u(n)\\) P* P* with SIMD comp1 comp2 \\(3n\\) \\((2n + 32) \\cdot 8\\) \\(\\frac{3n}{(2n+32) \\cdot 8} \\leq \\frac{3n}{16n} = \\frac{3}{16}\\) \\(\\min(\\beta \\cdot I_u, \\pi) = \\min(4.6875, 4) = 4\\) \\(\\min(\\beta \\cdot I_u, \\pi_\\text{vec}) = \\min(4.6875, 16) = 4.6875\\) comp3 \\(2rn\\) \\((rn + 2n) \\cdot 8\\) \\(\\frac{2rn}{(rn + 2n) \\cdot 8} = \\frac{6n}{40n} = \\frac{6}{40}\\) 3.75 3.75 @import \"roofline_b.svg\" The graph above visualizes the rooflines with points corresponding to \\((I_u, P^*)\\) and \\((I_u, P_\\text{vec}^*)\\) . Note that the plot has only three visible dots because some of the points in the table are identical. c) comp1 can be computed with one FMA and one ADD. comp2 needs 3 ADDs and comp3 only one FMA. Hence, we get the following results: function \\(T(n)\\) \\(P(n)\\) \\(P_{vec}(n)\\) comp1 \\(2 \\cdot \\frac{n}{2} = n\\) \\(\\min (3, 4) = 3\\) \\(\\min (12, 4.6875) = 4.6875\\) comp2 \\(3 \\cdot \\frac{n}{2}\\) \\(\\min (2, 4) = 2\\) \\(\\min (8, 4.6875) = 4.6875\\) comp3 \\(\\frac{rn}{2}\\) \\(\\min (4, 3.75) = 3.75\\) \\(\\min (16, 3.75) = 3.75\\) @import \"roofline_c.svg\" Note that the plot has only four visible dots because some of the points in the table are identical. d) As we can see from our derivation of \\(I_u(n)\\) for comp3 , the operational intensity will increase as we increment \\(r\\) since \\(rn\\) will dominate over the term \\(2n\\) . In particular, the operational intensity converges to \\(I^* = \\frac{1}{4}\\) when we neglect cache capacity misses. The performance for \\(r=3\\) is inherently limited by the bandwith (memory bounded). Hence, we can try to increase the operational intensity to be less limited by the bandwidth. Using \\(I^*\\) we get \\(P(n) = \\min (\\beta \\cdot 0.25, \\pi) =\\min (6.25, 4) = 4\\) and \\(P_{\\text{vec}}(n) = \\min (\\beta \\cdot 0.25, \\pi_{\\text{vec}}) =\\min (6.25, 16) = 6.25\\) . 4. Cache Miss Analysis a) Similar to what we have seen in lecture, we get $$ \\begin{aligned} \\text{#misses} &\\approx \\sum_{i = 0}^{n-1} n \\cdot \\left(\\frac{n - i}{8} + n - i \\right) \\ &= \\frac{9}{8} \\left(n^3 - n \\cdot \\frac{n(n-1)}{2} \\right) \\ &= \\frac{9}{8} \\frac{n^3 + n^2}{2} \\ &\\approx \\frac{9}{16}n^3 \\end{aligned} $$ b) All three blocks of A, B and C should fit into the cache. Hence, we get \\[ \\begin{aligned} 3b^2 \\cdot 8\\ \\text{byte} \\leq \\gamma = 8 \\text{KiB} \\\\ b \\leq \\sqrt{\\frac{8192}{3 \\cdot 8}} \\approx 18.48 \\end{aligned} \\] As \\(b\\) should be divisible by 8 we get \\(b = 16\\) . c) $$ \\begin{aligned} \\text{#misses} &\\approx \\sum_{i = 0}^{\\frac{n-b}{b}} \\frac{n}{b} \\cdot \\left(\\frac{(n - ib)b}{8} + \\frac{(n - ib)b}{8} \\right) \\ &= \\sum_{i = 0}^{\\frac{n-b}{b}} \\frac{n}{b} \\cdot \\frac{(n - ib)b}{4} \\ &\\approx \\frac{n^3}{8b} \\end{aligned} $$","title":"Homework 4"},{"location":"Sem6/ASL/homeworks/hw4/hw4/#homework-4","text":"Krispin Wandel, 15-941-388","title":"Homework 4"},{"location":"Sem6/ASL/homeworks/hw4/hw4/#1-associativity","text":"a) We have \\(W = 2*10=20\\) floating point operations. The byte transfer is equal to \\[ Q = \\text{\\#misses} \\cdot b, \\] where \\(b = 16\\ \\text{bytes}\\) is the block size of the cache. Hence, we can directly derive the operational intensity \\(I = W / Q\\) from the miss/hit pattern. The miss/hit pattern can be optained by first computing the set size \\(s\\) from the cache capacity \\(c = s \\cdot b \\cdot e = 128\\ \\text{bytes}\\) , where \\(e\\) is the associativity of the cache. Once we have the set size \\(s\\) , we just have to follow the LRU replacement strategy to obtain the corresponding miss/hit pattern. The table below summarizes the results: Associativity miss/hit pattern operational intensity 2 ( \\(s = 4\\) ) x: MMMHHHHMMH y: MMMMHMHHMH z: MMHHHHHHHH 13 misses \\(\\frac{20}{13 \\cdot 16} \\approx 0.096\\) 4 ( \\(s = 2\\) ) x: MMMMHHMMHH y: MMMMHMHHHM z: MMHHHHHHHH 14 misses \\(\\frac{20}{14 \\cdot 16} \\approx 0.089\\) b) 1. Access to x cannot have spatial locality because all accesses to x are 4 doubles apart from each other (and a block can only store two doubles). However, x[0], x[4], x[8] are accessed more than once and, in fact, we see from the miss/hit pattern that we could exploit this temporal locality . 2. The order y is accessed is as follows: 1, 4, 7, 2, 5, 0, 3, 6, 1, 4. As we can see, all elements from 0 to 7 are accessed and indices 1 and 4 are accessed twice. Moreover, z[0] and z[1] (or z[4], z[5]) are never accessed. Hence, x and y can both share the first cache set as we have 2-way associativity. Therefore, accesses to y benefit from both spatial and temporal locality .","title":"1. Associativity"},{"location":"Sem6/ASL/homeworks/hw4/hw4/#2-cache-mechanics","text":"From the cache specifications we can compute the set size \\(s = 384\\) . Furthermore, sizeof(struct_t) = 64 for PADDING_SIZE 1 and sizeof(struct_t) = 96 for PADDING_SIZE 5 . Moreover, for all \\(n\\) we get the same miss/ hit pattern for accesses to \\(A\\) as \\(A_{ij}\\) is only accessed once. Hence, we can only benefit from spatial locality as follows: c++ {.line-numbers} t = A[i*n + j].v; // miss, but will also load A[i*n + j].d for (int k = 0; k < 3; k++) { t += A[i*n + j].d[k]; // hit } for (int k = 0; k < 3; k++) { A[i*n + j].u[k] = 0; // k = 0 => miss, k = 1,2 => hit } // => 2 misses However, \\(B_{j0}, j=1 \\dots n,\\) is accessed \\(n\\) times and we can benefit from temporal locality. As we will see below, the miss rate depends on \\(n\\) . Finally, the total number of reads and writes is \\(9n^2\\) and we perform \\(4n^2\\) FLOPS. a) \\(n = 8\\) : \\(n^2 \\cdot 64\\ \\text{bytes} = 4096\\ \\text{bytes}\\) still fits into the cache. The miss/ hit pattern for \\(B\\) looks as follows: At \\(i = 0\\) we get \\(n\\) compulsory cache misses. For the next \\(n - 1\\) iterations, however, we get only one cache conflict miss as A[i*n+0] overwrites B[i*n] . In total, we have \\(2n^2 + n + n-1 = 143\\) cache misses and hence the miss rate is \\(\\frac{143}{9 \\cdot 64} \\approx 0.25\\) . The operational intensity is \\(I = \\frac{4 \\cdot 8^2\\ \\text{flops}}{143 \\cdot 32\\ \\text{byte}} \\approx 0.056\\ \\frac{\\text{flops}}{\\text{byte}}\\) . b) \\(n = 16\\) : For \\(n = 16\\) , in order to fit A (or B) into the cache we would need \\(16^2 \\cdot 64 / 32 = 512\\) cache blocks which is a third more than the cache set size. Hence, when we consecutively access \\(B_{j0},\\ j = 0 \\dots 15\\) the first four entries of B that we loaded into the cache, \\(B_{j0},\\ j = 0 \\dots 3\\) , are overwritten. For \\(i = 0\\) we get again \\(n\\) compulsory cache misses for B, but for \\(i = 1 \\dots 3\\) we now get \\(2 \\cdot 4 = 8\\) conflict misses instead of only one and for \\(i = 4 \\dots 15\\) we get one additional conflict miss because of the access to A[i*n] . In total, we have \\(2 \\cdot 16^2 + 16 + 3 * 8 + 12 * 9 = 660\\) cache misses and hence the miss rate is \\(\\frac{660}{9 \\cdot 256} \\approx 0.29\\) . The operational intensity is \\(I = \\frac{4 \\cdot 16^2\\ \\text{flops}}{660 \\cdot 32\\ \\text{byte}} \\approx 0.048\\ \\frac{\\text{flops}}{\\text{byte}}\\) . c) \\(n = 16\\) with PADDING_SIZE 5 : In this setting A (or B) is exactly twice as large as the cache capacity. Hence, we can no longer benefit from temporal locality for accesses to B. Therefore, the total number of misses is \\(2n^2 + n^2 = 3n^2\\) and the miss rate is \\(\\frac{3n^2}{9n^2} = \\frac{1}{3} \\approx 0.33\\) . The operational intensity is \\(I = \\frac{4 \\cdot 16^2\\ \\text{flops}}{768 \\cdot 32\\ \\text{byte}} \\approx 0.042\\ \\frac{\\text{flops}}{\\text{byte}}\\) .","title":"2. Cache Mechanics"},{"location":"Sem6/ASL/homeworks/hw4/hw4/#3-rooflines","text":"a) We have the following relationships between work \\(W\\) , byte transfer \\(Q\\) , operational intensity \\(I\\) , performance \\(P\\) and bandwidth \\(\\beta\\) . \\[ \\begin{aligned} I(n) &= \\frac{W(n)}{Q(n)} \\\\ P(n) &= \\frac{W(n)}{T(n)} \\\\ \\beta &\\geq \\frac{Q}{T} = \\frac{W}{T} \\div \\frac{W}{Q} = \\frac{P}{I} \\\\ \\log{P} &\\leq \\log{\\beta} + \\log{I} \\leq \\log{\\pi}, \\end{aligned} \\] where \\(\\pi\\) is the peak performance which is attained at \\(I = \\frac{\\pi}{\\beta}\\) . We can compute \\(\\beta\\) from the given specifications: $$ \\beta = 50 \\frac{\\text{GB}}{\\text{s}} = 50 \\frac{\\text{GB}}{2 \\cdot 10^9 \\text{cycle}} = 25 \\frac{\\text{byte}}{\\text{cycle}} $$ As the processor can issue 2 FMAs per cycle we get a peak performance of 4 FLOPs per cycle without vector instructions. With vector instructions we can do 8 FMAs per cycle and hence we get a peak performance of 16 FLOPs per cycle . b) I denote \\(I_u\\) the hard upper bound to the ooperational intensity \\(I\\) . The table below summarizes the results: function W(n) Q(n) \\(I_u(n)\\) P* P* with SIMD comp1 comp2 \\(3n\\) \\((2n + 32) \\cdot 8\\) \\(\\frac{3n}{(2n+32) \\cdot 8} \\leq \\frac{3n}{16n} = \\frac{3}{16}\\) \\(\\min(\\beta \\cdot I_u, \\pi) = \\min(4.6875, 4) = 4\\) \\(\\min(\\beta \\cdot I_u, \\pi_\\text{vec}) = \\min(4.6875, 16) = 4.6875\\) comp3 \\(2rn\\) \\((rn + 2n) \\cdot 8\\) \\(\\frac{2rn}{(rn + 2n) \\cdot 8} = \\frac{6n}{40n} = \\frac{6}{40}\\) 3.75 3.75 @import \"roofline_b.svg\" The graph above visualizes the rooflines with points corresponding to \\((I_u, P^*)\\) and \\((I_u, P_\\text{vec}^*)\\) . Note that the plot has only three visible dots because some of the points in the table are identical. c) comp1 can be computed with one FMA and one ADD. comp2 needs 3 ADDs and comp3 only one FMA. Hence, we get the following results: function \\(T(n)\\) \\(P(n)\\) \\(P_{vec}(n)\\) comp1 \\(2 \\cdot \\frac{n}{2} = n\\) \\(\\min (3, 4) = 3\\) \\(\\min (12, 4.6875) = 4.6875\\) comp2 \\(3 \\cdot \\frac{n}{2}\\) \\(\\min (2, 4) = 2\\) \\(\\min (8, 4.6875) = 4.6875\\) comp3 \\(\\frac{rn}{2}\\) \\(\\min (4, 3.75) = 3.75\\) \\(\\min (16, 3.75) = 3.75\\) @import \"roofline_c.svg\" Note that the plot has only four visible dots because some of the points in the table are identical. d) As we can see from our derivation of \\(I_u(n)\\) for comp3 , the operational intensity will increase as we increment \\(r\\) since \\(rn\\) will dominate over the term \\(2n\\) . In particular, the operational intensity converges to \\(I^* = \\frac{1}{4}\\) when we neglect cache capacity misses. The performance for \\(r=3\\) is inherently limited by the bandwith (memory bounded). Hence, we can try to increase the operational intensity to be less limited by the bandwidth. Using \\(I^*\\) we get \\(P(n) = \\min (\\beta \\cdot 0.25, \\pi) =\\min (6.25, 4) = 4\\) and \\(P_{\\text{vec}}(n) = \\min (\\beta \\cdot 0.25, \\pi_{\\text{vec}}) =\\min (6.25, 16) = 6.25\\) .","title":"3. Rooflines"},{"location":"Sem6/ASL/homeworks/hw4/hw4/#4-cache-miss-analysis","text":"a) Similar to what we have seen in lecture, we get $$ \\begin{aligned} \\text{#misses} &\\approx \\sum_{i = 0}^{n-1} n \\cdot \\left(\\frac{n - i}{8} + n - i \\right) \\ &= \\frac{9}{8} \\left(n^3 - n \\cdot \\frac{n(n-1)}{2} \\right) \\ &= \\frac{9}{8} \\frac{n^3 + n^2}{2} \\ &\\approx \\frac{9}{16}n^3 \\end{aligned} $$ b) All three blocks of A, B and C should fit into the cache. Hence, we get \\[ \\begin{aligned} 3b^2 \\cdot 8\\ \\text{byte} \\leq \\gamma = 8 \\text{KiB} \\\\ b \\leq \\sqrt{\\frac{8192}{3 \\cdot 8}} \\approx 18.48 \\end{aligned} \\] As \\(b\\) should be divisible by 8 we get \\(b = 16\\) . c) $$ \\begin{aligned} \\text{#misses} &\\approx \\sum_{i = 0}^{\\frac{n-b}{b}} \\frac{n}{b} \\cdot \\left(\\frac{(n - ib)b}{8} + \\frac{(n - ib)b}{8} \\right) \\ &= \\sum_{i = 0}^{\\frac{n-b}{b}} \\frac{n}{b} \\cdot \\frac{(n - ib)b}{4} \\ &\\approx \\frac{n^3}{8b} \\end{aligned} $$","title":"4. Cache Miss Analysis"},{"location":"Sem6/CMM/cmm/","text":"Coordinate Transforms Consider a world frame \\(w\\) and a frame \\(1\\) that share the same origin. To transform world coordinates \\(p_w\\) to frame \\(1\\) coordinates \\(p_1\\) we need to multiply \\(p_w\\) with the following rotation matrix: $$ \\begin{aligned} {} 1R_w &= \\left( \\begin{matrix} {}_w e ^\\top \\ {} w e ^\\top \\end{matrix} \\right) = \\left( \\begin{matrix} c_\\theta & s_\\theta \\ -s_\\theta & c_\\theta \\end{matrix} \\right) \\ p_1 &= {}_1R_w\\ p_w \\end{aligned} $$ Note that a rotation is equivalent to \\({}_w R_1\\) . If frame \\(w\\) and \\(1\\) and shifted by \\({}_w t_{w,1}\\) , then we first need to subtract \\({}_w t_{w,1}\\) from \\(p_w\\) before applying \\({}_1R_w\\) : $$ \\begin{aligned} p_1 &= {} 1R_w \\ {}_w T \\ \\left(\\begin{matrix}p_w \\ 1\\end{matrix}\\right) \\ {} w T &= \\left( \\begin{matrix} I & -{} w t \\ 0 & 1 \\end{matrix} \\right) \\end{aligned} $$","title":"Cmm"},{"location":"Sem6/CMM/cmm/#coordinate-transforms","text":"Consider a world frame \\(w\\) and a frame \\(1\\) that share the same origin. To transform world coordinates \\(p_w\\) to frame \\(1\\) coordinates \\(p_1\\) we need to multiply \\(p_w\\) with the following rotation matrix: $$ \\begin{aligned} {} 1R_w &= \\left( \\begin{matrix} {}_w e ^\\top \\ {} w e ^\\top \\end{matrix} \\right) = \\left( \\begin{matrix} c_\\theta & s_\\theta \\ -s_\\theta & c_\\theta \\end{matrix} \\right) \\ p_1 &= {}_1R_w\\ p_w \\end{aligned} $$ Note that a rotation is equivalent to \\({}_w R_1\\) . If frame \\(w\\) and \\(1\\) and shifted by \\({}_w t_{w,1}\\) , then we first need to subtract \\({}_w t_{w,1}\\) from \\(p_w\\) before applying \\({}_1R_w\\) : $$ \\begin{aligned} p_1 &= {} 1R_w \\ {}_w T \\ \\left(\\begin{matrix}p_w \\ 1\\end{matrix}\\right) \\ {} w T &= \\left( \\begin{matrix} I & -{} w t \\ 0 & 1 \\end{matrix} \\right) \\end{aligned} $$","title":"Coordinate Transforms"},{"location":"Sem6/CMM/ex4proof/","text":"First Name:Krispin Last Name: Wandel Solution to Question 4: \\[ \\begin{align} [F^T F]_{ij} &= \\sum_{k=1}^n [F^T]_{ik} F_{kj} = \\sum_{k=1}^n F_{ki} F_{kj} \\\\ [F^T F]_{ii} &= \\sum_{k=1}^n F_{ki}^2 \\\\ \\text{tr} (F^T F - I) &= \\sum_{i=1}^m -1 + \\sum_{k=1}^n F_{ki}^2 = ||F||_F^2 - m = ||F||_F^2 - 2 \\end{align} \\] Solution to Question 10: First, I want to note that in the horizontal case the solution looks as expected. Furthermore, our objective \\(O\\) only depends on the two feature points and makes no further assumptions on the mesh that results from the static solution. Hence, our optimization method just takes the shortest path to the global minimum (objective is convex) in control space and, thus, the solution depends highly on the initial conditions. This behavior can result in unexpected results. Solution to Question 11: First, I tried to minimize the shear forces in the static solution but this somehow did not work. I ended up to just regularize the orientation of the left and right handles in the follwing way: Let \\(v_{l,t}\\) , \\(v_{l,b}\\) be the left top and bottom corner points and \\(v_{r,t}\\) , \\(v_{r,b}\\) the right corner points of the mesh. Let further \\(p_1\\) and \\(p_2\\) be the two feature points controlled by the user. Now, my regularization term \\(r\\) just penalizes the fact that we expect the vectors \\(v_l = v_{l,t} - v_{l,b}\\) and \\(v_r = v_{r,t} - v_{r,b}\\) to be orthogonal to \\(d = p_1 - p_2\\) : $$ \\begin{aligned} \\hat v_l &= \\frac{v_l}{||v_l||} \\ \\hat v_r &= \\frac{v_r}{||v_r||} \\ \\hat d &= \\frac{d}{||d||} \\ r &= \\frac{1}{2} \\cdot \\left((v_l^Td)^2 + (v_r^Td)^2\\right) \\end{aligned} $$ Note, we normalize the vectors to make the objective independent of the dimensions and we further square everything to make the the regularizer smooth. Finally, it is important to mention that our regularizer does not make much sense when we squeeze the bar too much because the static solution of a squeezed bar may have much more energy than a bended bar (depeding on the material paramters). Hence, if the initial bar mesh is not perfectly straight the optimization steps might take a very long time to process because the static solution results in a bended bar whereas our regularizer wants to find a straight bar. Here is a link to the video that demonstrates everything: https://youtu.be/cMOYAsW7lq4 Assignment writeup: http://crl.ethz.ch/teaching/computational-motion-21/slides/tutorial-a4.pdf Could use ./build.sh on Linux/MacOS","title":"Ex4proof"},{"location":"Sem6/CMM/ex4proof/#solution-to-question-4","text":"\\[ \\begin{align} [F^T F]_{ij} &= \\sum_{k=1}^n [F^T]_{ik} F_{kj} = \\sum_{k=1}^n F_{ki} F_{kj} \\\\ [F^T F]_{ii} &= \\sum_{k=1}^n F_{ki}^2 \\\\ \\text{tr} (F^T F - I) &= \\sum_{i=1}^m -1 + \\sum_{k=1}^n F_{ki}^2 = ||F||_F^2 - m = ||F||_F^2 - 2 \\end{align} \\]","title":"Solution to Question 4:"},{"location":"Sem6/CMM/ex4proof/#solution-to-question-10","text":"First, I want to note that in the horizontal case the solution looks as expected. Furthermore, our objective \\(O\\) only depends on the two feature points and makes no further assumptions on the mesh that results from the static solution. Hence, our optimization method just takes the shortest path to the global minimum (objective is convex) in control space and, thus, the solution depends highly on the initial conditions. This behavior can result in unexpected results.","title":"Solution to Question 10:"},{"location":"Sem6/CMM/ex4proof/#solution-to-question-11","text":"First, I tried to minimize the shear forces in the static solution but this somehow did not work. I ended up to just regularize the orientation of the left and right handles in the follwing way: Let \\(v_{l,t}\\) , \\(v_{l,b}\\) be the left top and bottom corner points and \\(v_{r,t}\\) , \\(v_{r,b}\\) the right corner points of the mesh. Let further \\(p_1\\) and \\(p_2\\) be the two feature points controlled by the user. Now, my regularization term \\(r\\) just penalizes the fact that we expect the vectors \\(v_l = v_{l,t} - v_{l,b}\\) and \\(v_r = v_{r,t} - v_{r,b}\\) to be orthogonal to \\(d = p_1 - p_2\\) : $$ \\begin{aligned} \\hat v_l &= \\frac{v_l}{||v_l||} \\ \\hat v_r &= \\frac{v_r}{||v_r||} \\ \\hat d &= \\frac{d}{||d||} \\ r &= \\frac{1}{2} \\cdot \\left((v_l^Td)^2 + (v_r^Td)^2\\right) \\end{aligned} $$ Note, we normalize the vectors to make the objective independent of the dimensions and we further square everything to make the the regularizer smooth. Finally, it is important to mention that our regularizer does not make much sense when we squeeze the bar too much because the static solution of a squeezed bar may have much more energy than a bended bar (depeding on the material paramters). Hence, if the initial bar mesh is not perfectly straight the optimization steps might take a very long time to process because the static solution results in a bended bar whereas our regularizer wants to find a straight bar. Here is a link to the video that demonstrates everything: https://youtu.be/cMOYAsW7lq4 Assignment writeup: http://crl.ethz.ch/teaching/computational-motion-21/slides/tutorial-a4.pdf Could use ./build.sh on Linux/MacOS","title":"Solution to Question 11:"},{"location":"Sem6/CMM/rigid_bodies/","text":"Rigid Bodies Describe rigid body with position of center of mass in world coordiantes and a rotation matrix that transform local vectors to world coordinates: \\[ x_w = p_w + {}_wR_b\\ x_b \\] Columns of \ud835\udc11(\ud835\udc61) encode global coordinates of body space x, y and z vectors at time \ud835\udc61. $$ x_w' = p_w' + {}_wR_b'\\ x_b $$ where the derivative is with respect to time. let \\(w\\) encode the angular velocity \\(|w| = \\theta'\\) . Let \\(c = a^\\parallel + b^\\perp\\) where \\(a \\parallel w\\) and \\(b \\perp w\\) . Then, \\(|b'| = |b||w|\\) . By assumption, \\(b'\\) is orthogonal to \\(w\\) and, thus, we can identify \\(b = w \\times b\\) . Hence, we get: \\( \\(c' = w \\times a + w \\times b = w \\times b = w \\times c\\) \\) Now we can make sense of the derivative of the rotation matrix: \\(R_{:,1}' = w \\times R_{:,1} \\rightarrow R_b' = [w]_\\times R_b\\) Rigid body dynamics \\[ \\begin{aligned} x_w' &= p_w' + [w(t)]_\\times R_b\\ x_b \\\\ &= v + w(t) \\times (R_b \\ x_b + p_w - p_w) \\\\ &= v + w(t) \\times (x_w - p_w) \\\\ &= \\underbrace{v}_{\\text{linear component}} + \\underbrace{w(t) \\times \\vec{r}_w}_{\\text{angular component}} \\end{aligned} \\] Kinetic energy \\[ K = \\frac{1}{2} \\sum_i{\\dot{x}_i^{T}m_i\\dot{x}_i} = \\underbrace{\\frac{1}{2} v^T M v}_{\\text{First order of mass: where is the mass concentrated}} + \\underbrace{\\frac{1}{2} w^T I w}_{\\text{Second order of mass: how is the mass distributed in space}} \\] Moment of intertia: \\(I = RI_b R^T\\) forces and torques forces: \\(F(t) = \\sum_i f_i(t)\\) torques: \\(\\tau(t) = \\sum_i r_i \\times f_i(t)\\) net torque enforces by gravity is zero as \\(r_i\\) is with respect to center of mass Linear and angular momenta linear momentum: \\(p = Mv\\) , \\(F = p'\\) angular momentum: \\(L = Iw\\) , \\(\\tau = L'\\) \\(L' = I'w + Iw'\\) \\(I' = [w]I + I[w] \\rightarrow I'w = w \\times Iw\\) \\(Iw' = \\tau - w \\times Iw\\) F = ma $$ \\begin{bmatrix} F \\ \\tau - w \\times Iw \\end{bmatrix} = \\begin{bmatrix} M \\mathbb{I} & 0 \\ 0 & I \\end{bmatrix} \\begin{bmatrix} v' \\ w' \\end{bmatrix} $$ The equations are decoupled so we can solve for \\(v'\\) and \\(w'\\) separatly. Symplectic Euler 1) Compute net forces and torques 2) solve for \\(v'\\) and \\(w'\\) 3) update \\(v\\) and \\(w\\) 4) update \\(p\\) and \\(R\\) - note that updating \\(R\\) is not trivial because \\(R\\) has to stay a rotation matrix. - Quaternions can help","title":"Rigid Bodies"},{"location":"Sem6/CMM/rigid_bodies/#rigid-bodies","text":"Describe rigid body with position of center of mass in world coordiantes and a rotation matrix that transform local vectors to world coordinates: \\[ x_w = p_w + {}_wR_b\\ x_b \\] Columns of \ud835\udc11(\ud835\udc61) encode global coordinates of body space x, y and z vectors at time \ud835\udc61. $$ x_w' = p_w' + {}_wR_b'\\ x_b $$ where the derivative is with respect to time. let \\(w\\) encode the angular velocity \\(|w| = \\theta'\\) . Let \\(c = a^\\parallel + b^\\perp\\) where \\(a \\parallel w\\) and \\(b \\perp w\\) . Then, \\(|b'| = |b||w|\\) . By assumption, \\(b'\\) is orthogonal to \\(w\\) and, thus, we can identify \\(b = w \\times b\\) . Hence, we get: \\( \\(c' = w \\times a + w \\times b = w \\times b = w \\times c\\) \\) Now we can make sense of the derivative of the rotation matrix: \\(R_{:,1}' = w \\times R_{:,1} \\rightarrow R_b' = [w]_\\times R_b\\)","title":"Rigid Bodies"},{"location":"Sem6/CMM/rigid_bodies/#rigid-body-dynamics","text":"\\[ \\begin{aligned} x_w' &= p_w' + [w(t)]_\\times R_b\\ x_b \\\\ &= v + w(t) \\times (R_b \\ x_b + p_w - p_w) \\\\ &= v + w(t) \\times (x_w - p_w) \\\\ &= \\underbrace{v}_{\\text{linear component}} + \\underbrace{w(t) \\times \\vec{r}_w}_{\\text{angular component}} \\end{aligned} \\]","title":"Rigid body dynamics"},{"location":"Sem6/CMM/rigid_bodies/#kinetic-energy","text":"\\[ K = \\frac{1}{2} \\sum_i{\\dot{x}_i^{T}m_i\\dot{x}_i} = \\underbrace{\\frac{1}{2} v^T M v}_{\\text{First order of mass: where is the mass concentrated}} + \\underbrace{\\frac{1}{2} w^T I w}_{\\text{Second order of mass: how is the mass distributed in space}} \\] Moment of intertia: \\(I = RI_b R^T\\)","title":"Kinetic energy"},{"location":"Sem6/CMM/rigid_bodies/#forces-and-torques","text":"forces: \\(F(t) = \\sum_i f_i(t)\\) torques: \\(\\tau(t) = \\sum_i r_i \\times f_i(t)\\) net torque enforces by gravity is zero as \\(r_i\\) is with respect to center of mass","title":"forces and torques"},{"location":"Sem6/CMM/rigid_bodies/#linear-and-angular-momenta","text":"linear momentum: \\(p = Mv\\) , \\(F = p'\\) angular momentum: \\(L = Iw\\) , \\(\\tau = L'\\) \\(L' = I'w + Iw'\\) \\(I' = [w]I + I[w] \\rightarrow I'w = w \\times Iw\\) \\(Iw' = \\tau - w \\times Iw\\)","title":"Linear and angular momenta"},{"location":"Sem6/CMM/rigid_bodies/#f-ma","text":"$$ \\begin{bmatrix} F \\ \\tau - w \\times Iw \\end{bmatrix} = \\begin{bmatrix} M \\mathbb{I} & 0 \\ 0 & I \\end{bmatrix} \\begin{bmatrix} v' \\ w' \\end{bmatrix} $$ The equations are decoupled so we can solve for \\(v'\\) and \\(w'\\) separatly.","title":"F = ma"},{"location":"Sem6/CMM/rigid_bodies/#symplectic-euler","text":"1) Compute net forces and torques 2) solve for \\(v'\\) and \\(w'\\) 3) update \\(v\\) and \\(w\\) 4) update \\(p\\) and \\(R\\) - note that updating \\(R\\) is not trivial because \\(R\\) has to stay a rotation matrix. - Quaternions can help","title":"Symplectic Euler"},{"location":"Sem6/ODS/ex1/","text":"Exercise Set 1 Exercise 2 Prove Jensen's inequality (Lemma 1.12)! Jensen's inequality: Let \\(f\\) be convex and \\(\\sum{\\lambda_i} = 1\\) , then: \\[ f \\left(\\sum \\lambda_i x_i \\right ) \\leq \\sum \\lambda_i f(x_i) \\] Proof by induction: By definition of convexity, \\[f(\\lambda x + (1 - \\lambda)y) \\leq \\lambda f(x) + (1 - \\lambda) f(y),\\] Jensen's inequality holds for \\(m=2\\) . Let \\(\\lambda = \\lambda_1\\) . Since \\(\\sum_{i=2}^{m+1} \\frac{\\lambda_i}{1-\\lambda_1} = 1\\) , we get: \\[ \\begin{aligned} f \\left(\\sum_{i=1}^{m+1}\\lambda_i x_i \\right) &= f \\left(\\lambda x_1 + (1-\\lambda)\\sum_{i=2}^{m+1} \\frac{\\lambda_i x_i}{1-\\lambda} \\right) && \\text{by definition of } \\lambda \\\\ &\\leq \\lambda_1 f(x_1) + (1-\\lambda_1) f\\left(\\sum_{i=2}^{m+1} \\frac{\\lambda_i x_i}{1-\\lambda_1}\\right) && \\text{by convexity} \\\\ &\\leq \\lambda_1 f(x_1) + (1-\\lambda_1) \\sum_{i=2}^{m+1} \\frac{\\lambda_i}{1-\\lambda_1} f(x_i) && \\text{by induction} \\\\ &= \\sum \\lambda_i f(x_i) \\end{aligned} \\] Exercise 3 Prove that a convex function (with dom(f) open) is continuous (Lemma 1.13)! Consider a cube \\(C\\) of size \\(2\\epsilon\\) centered around \\(x \\in \\mathbb{R}^d\\) : \\([x_1 - \\epsilon, x_1 + \\epsilon] \\times [x_2 - \\epsilon, x_2 + \\epsilon] \\times \\dots [x_d - \\epsilon, x_d + \\epsilon]\\) . W.l.o.g. we fix \\(x_{i, i > 1}\\) and show that a convex function \\(f(x_1 | x_{i, i > 1})\\) attains its maximum at \\(x_1 - \\epsilon\\) or \\(x_1 + \\epsilon\\) . Since \\(f\\) is convex, we get for \\(x_1 - \\epsilon \\leq z \\leq x_1 + \\epsilon\\) : \\[ f(z) \\leq \\max_\\lambda{\\lambda f(x_1-\\epsilon) + (1-\\lambda)f(x_1+\\epsilon)} = \\max\\{f(x_1-\\epsilon), f(x_1+\\epsilon)\\} \\] As we have fixed \\(x_{i, i > 1}\\) arbitrarly, \\(f\\) attains its maximum over \\(C\\) at one of the cube domain's corners. Now, consider two points \\(w, y\\) that are within radius \\(\\epsilon\\) around \\(x\\) , \\(|| w - x || \\leq \\epsilon\\) and \\(|| y - x || \\leq \\epsilon\\) , and such that there is a \\(\\delta\\) for which \\(y = (1 - \\delta)x + \\delta w\\) . Let us further define \\(M := \\max_{x \\in C} f(x)\\) . \\[ \\begin{aligned} |f(y) - f(x)| &= |f((1 - \\delta)x + \\delta w) - f(x)| \\\\ &\\leq |(1 - \\delta)f(x) + \\delta f(w) - f(x)| && \\text{by convexity of } f\\\\ &\\leq \\delta |M - f(x)| && \\text{since } w \\in C \\end{aligned} \\] The RHS vanishes for \\(\\delta \\rightarrow 0\\) since \\(|M - f(x)|\\) is constant. As \\(w\\) was chosen arbitrarly, it follows that \\(f\\) is continuous. Exercise 4 Prove that the function \\(d_y : \\mathbb{R}^d \\rightarrow \\mathbb{R}, x \\rightarrow ||x - y||^2\\) is strictly convex for any \\(y \\in \\mathbb{R}^d\\) . (Use Lemma 1.24.) Lemma 1.24 states that functions that have a positive definite Hessian are strictly convex. The gradient of \\(||x - y||^2\\) is \\(2 (x - y)\\) . The hessian is \\(2 \\text{Id}(d)\\) and hence positive definite. Exercise 5 Prove Lemma 1.18! Can (ii) be generalized to show that for two convex functions \\(f, g\\) , the function \\(f \\circ g\\) is convex as well? i) Let \\(r \\in [0, 1]\\) and \\(f_i\\) and \\(\\lambda_i\\) as in Lemma 1.18. Then, we get: \\[ \\begin{aligned} \\sum \\lambda_i f_i(r x + (1 - r) y) &\\leq \\sum \\lambda_i (r f_i(x) + (1 - r) f_i(y)) && \\text{convexity of } f_i\\\\ &= r \\sum \\lambda_i f_i(x) + (1 - r) \\sum \\lambda_i f_i(y) \\end{aligned} \\] ii) The proof follows immediately from observing that \\(A(rx + (1-r)y) + b = r(Ax + b) + (1- r)(Ay+b)\\) since \\(rb + (1-r)b = b\\) . \\[ f(A(rx + (1-r)y) + b) \\leq r f(Ax+b) + (1 - r) f(Ay+b) \\] However, \\(g = Ax+b\\) does not generalize to general convex functions. For example, \\(f = e^{-x}\\) and \\(g = x^2\\) are both convex but \\(f \\circ g\\) is not. Intuitively, if \\(f\\) is a decreasing function, the contradiction can also be seen from \\[ f(g(rx + (1-r)y)) \\geq f(rg(x) + (1-r)g(y)), \\] If instead \\(f\\) was increasing, the claim would hold. Exercise 7 Consider the function \\(l\\) defined in (1.15). Prove that \\(f\\) is convex! If we can prove that \\(\\ln \\left( \\sum e^x \\right)\\) is convex, then the proof follows immediately from Lemma 1.18 (see previous exercise). Proof of convexity of \\(\\ln \\left( \\sum e^x \\right)\\) : StackExchange - uses H\u00f6lder's inequality H\u00f6lder's inequality : Let \\(p, q \\in [1, \\infty]\\) s.t. \\(\\frac{1}{p} + \\frac{1}{q} = 1\\) , then: \\[ \\langle f, g \\rangle \\leq ||f||_p ||g||_q \\] Let \\(u = e^x\\) and \\(v = e^y\\) : \\[ \\ln \\left( \\sum e^{rx + (1-r)y} \\right) = \\ln \\left( \\sum u^r v^{1-r} \\right) \\] Using H\u00f6lder's inequality with \\(p = \\frac{1}{r}\\) and \\(q = \\frac{1}{1 - r}\\) and by observing that \\(u, v > 0\\) , we get: \\[ \\begin{aligned} \\ln \\left( \\sum u^r v^{1-r} \\right) &\\leq \\ln \\left( \\left( \\sum u^{r \\frac{1}{r}} \\right)^r \\left( \\sum v^{1-r \\frac{1}{1 - r}} \\right)^{1-r} \\right) \\\\ &= r \\ln \\left( \\sum e^x \\right) + (1-r) \\ln \\left( \\sum e^y \\right) \\end{aligned} \\]","title":"Exercise Set 1"},{"location":"Sem6/ODS/ex1/#exercise-set-1","text":"","title":"Exercise Set 1"},{"location":"Sem6/ODS/ex1/#exercise-2-prove-jensens-inequality-lemma-112","text":"Jensen's inequality: Let \\(f\\) be convex and \\(\\sum{\\lambda_i} = 1\\) , then: \\[ f \\left(\\sum \\lambda_i x_i \\right ) \\leq \\sum \\lambda_i f(x_i) \\] Proof by induction: By definition of convexity, \\[f(\\lambda x + (1 - \\lambda)y) \\leq \\lambda f(x) + (1 - \\lambda) f(y),\\] Jensen's inequality holds for \\(m=2\\) . Let \\(\\lambda = \\lambda_1\\) . Since \\(\\sum_{i=2}^{m+1} \\frac{\\lambda_i}{1-\\lambda_1} = 1\\) , we get: \\[ \\begin{aligned} f \\left(\\sum_{i=1}^{m+1}\\lambda_i x_i \\right) &= f \\left(\\lambda x_1 + (1-\\lambda)\\sum_{i=2}^{m+1} \\frac{\\lambda_i x_i}{1-\\lambda} \\right) && \\text{by definition of } \\lambda \\\\ &\\leq \\lambda_1 f(x_1) + (1-\\lambda_1) f\\left(\\sum_{i=2}^{m+1} \\frac{\\lambda_i x_i}{1-\\lambda_1}\\right) && \\text{by convexity} \\\\ &\\leq \\lambda_1 f(x_1) + (1-\\lambda_1) \\sum_{i=2}^{m+1} \\frac{\\lambda_i}{1-\\lambda_1} f(x_i) && \\text{by induction} \\\\ &= \\sum \\lambda_i f(x_i) \\end{aligned} \\]","title":"Exercise 2 Prove Jensen's inequality (Lemma 1.12)!"},{"location":"Sem6/ODS/ex1/#exercise-3-prove-that-a-convex-function-with-domf-open-is-continuous-lemma-113","text":"Consider a cube \\(C\\) of size \\(2\\epsilon\\) centered around \\(x \\in \\mathbb{R}^d\\) : \\([x_1 - \\epsilon, x_1 + \\epsilon] \\times [x_2 - \\epsilon, x_2 + \\epsilon] \\times \\dots [x_d - \\epsilon, x_d + \\epsilon]\\) . W.l.o.g. we fix \\(x_{i, i > 1}\\) and show that a convex function \\(f(x_1 | x_{i, i > 1})\\) attains its maximum at \\(x_1 - \\epsilon\\) or \\(x_1 + \\epsilon\\) . Since \\(f\\) is convex, we get for \\(x_1 - \\epsilon \\leq z \\leq x_1 + \\epsilon\\) : \\[ f(z) \\leq \\max_\\lambda{\\lambda f(x_1-\\epsilon) + (1-\\lambda)f(x_1+\\epsilon)} = \\max\\{f(x_1-\\epsilon), f(x_1+\\epsilon)\\} \\] As we have fixed \\(x_{i, i > 1}\\) arbitrarly, \\(f\\) attains its maximum over \\(C\\) at one of the cube domain's corners. Now, consider two points \\(w, y\\) that are within radius \\(\\epsilon\\) around \\(x\\) , \\(|| w - x || \\leq \\epsilon\\) and \\(|| y - x || \\leq \\epsilon\\) , and such that there is a \\(\\delta\\) for which \\(y = (1 - \\delta)x + \\delta w\\) . Let us further define \\(M := \\max_{x \\in C} f(x)\\) . \\[ \\begin{aligned} |f(y) - f(x)| &= |f((1 - \\delta)x + \\delta w) - f(x)| \\\\ &\\leq |(1 - \\delta)f(x) + \\delta f(w) - f(x)| && \\text{by convexity of } f\\\\ &\\leq \\delta |M - f(x)| && \\text{since } w \\in C \\end{aligned} \\] The RHS vanishes for \\(\\delta \\rightarrow 0\\) since \\(|M - f(x)|\\) is constant. As \\(w\\) was chosen arbitrarly, it follows that \\(f\\) is continuous.","title":"Exercise 3 Prove that a convex function (with dom(f) open) is continuous (Lemma 1.13)!"},{"location":"Sem6/ODS/ex1/#exercise-4-prove-that-the-function-d_y-mathbbrd-rightarrow-mathbbr-x-rightarrow-x-y2-is-strictly-convex-for-any-y-in-mathbbrd-use-lemma-124","text":"Lemma 1.24 states that functions that have a positive definite Hessian are strictly convex. The gradient of \\(||x - y||^2\\) is \\(2 (x - y)\\) . The hessian is \\(2 \\text{Id}(d)\\) and hence positive definite.","title":"Exercise 4 Prove that the function \\(d_y : \\mathbb{R}^d \\rightarrow \\mathbb{R}, x \\rightarrow ||x - y||^2\\) is strictly convex for any \\(y \\in \\mathbb{R}^d\\). (Use Lemma 1.24.)"},{"location":"Sem6/ODS/ex1/#exercise-5-prove-lemma-118-can-ii-be-generalized-to-show-that-for-two-convex-functions-f-g-the-function-f-circ-g-is-convex-as-well","text":"i) Let \\(r \\in [0, 1]\\) and \\(f_i\\) and \\(\\lambda_i\\) as in Lemma 1.18. Then, we get: \\[ \\begin{aligned} \\sum \\lambda_i f_i(r x + (1 - r) y) &\\leq \\sum \\lambda_i (r f_i(x) + (1 - r) f_i(y)) && \\text{convexity of } f_i\\\\ &= r \\sum \\lambda_i f_i(x) + (1 - r) \\sum \\lambda_i f_i(y) \\end{aligned} \\] ii) The proof follows immediately from observing that \\(A(rx + (1-r)y) + b = r(Ax + b) + (1- r)(Ay+b)\\) since \\(rb + (1-r)b = b\\) . \\[ f(A(rx + (1-r)y) + b) \\leq r f(Ax+b) + (1 - r) f(Ay+b) \\] However, \\(g = Ax+b\\) does not generalize to general convex functions. For example, \\(f = e^{-x}\\) and \\(g = x^2\\) are both convex but \\(f \\circ g\\) is not. Intuitively, if \\(f\\) is a decreasing function, the contradiction can also be seen from \\[ f(g(rx + (1-r)y)) \\geq f(rg(x) + (1-r)g(y)), \\] If instead \\(f\\) was increasing, the claim would hold.","title":"Exercise 5 Prove Lemma 1.18! Can (ii) be generalized to show that for two convex functions \\(f, g\\), the function \\(f \\circ g\\) is convex as well?"},{"location":"Sem6/ODS/ex1/#exercise-7-consider-the-function-l-defined-in-115-prove-that-f-is-convex","text":"If we can prove that \\(\\ln \\left( \\sum e^x \\right)\\) is convex, then the proof follows immediately from Lemma 1.18 (see previous exercise). Proof of convexity of \\(\\ln \\left( \\sum e^x \\right)\\) : StackExchange - uses H\u00f6lder's inequality H\u00f6lder's inequality : Let \\(p, q \\in [1, \\infty]\\) s.t. \\(\\frac{1}{p} + \\frac{1}{q} = 1\\) , then: \\[ \\langle f, g \\rangle \\leq ||f||_p ||g||_q \\] Let \\(u = e^x\\) and \\(v = e^y\\) : \\[ \\ln \\left( \\sum e^{rx + (1-r)y} \\right) = \\ln \\left( \\sum u^r v^{1-r} \\right) \\] Using H\u00f6lder's inequality with \\(p = \\frac{1}{r}\\) and \\(q = \\frac{1}{1 - r}\\) and by observing that \\(u, v > 0\\) , we get: \\[ \\begin{aligned} \\ln \\left( \\sum u^r v^{1-r} \\right) &\\leq \\ln \\left( \\left( \\sum u^{r \\frac{1}{r}} \\right)^r \\left( \\sum v^{1-r \\frac{1}{1 - r}} \\right)^{1-r} \\right) \\\\ &= r \\ln \\left( \\sum e^x \\right) + (1-r) \\ln \\left( \\sum e^y \\right) \\end{aligned} \\]","title":"Exercise 7 Consider the function \\(l\\) defined in (1.15). Prove that \\(f\\) is convex!"},{"location":"Sem6/ODS/ex2/","text":"Exercise Set 2 Exercise 13 By Cauchy-Schwarz : \\[ |c^T x| \\leq ||c||\\, ||x|| \\] Hence, the spectral norm of \\(c^T\\) is bounded by \\(||c||\\) . This bound is reached at \\(x = c\\) and hence equal to the Euclidean norm. Exercsie 14 We proof that the gradients of \\(f\\) are Lipschitz continuous which implies smoothness of \\(f\\) ( Lemma 2.4 from the lecture notes): \\[ \\nabla f(x) = (Q + Q^T) x + b = 2Qx + b \\] \\[ \\begin{aligned} ||2Q(x-y)|| = ||2Q\\frac{x-y}{||x-y||} ||x-y|||| \\leq 2||Q|| \\cdot ||x-y|| \\end{aligned} \\] Exercise 16 The idea is to adapt the step size \\(\\gamma\\) so that we do not make updates on \\(x\\) that are too large. One way to constrain the step size is by normalizing the gradients. Therefore, we guess: \\[ \\gamma_t = \\frac{R}{||g_t|| \\sqrt{T}} \\] Then, we can bound the updates on \\(x\\) by: \\[ \\begin{aligned} x_{t+1} &= x_t - \\frac{R}{||g_t|| \\sqrt{T}} g_t \\\\ || x_{t+1} - x_t ||^2 &\\leq \\frac{R^2}{T} \\end{aligned} \\] From the Vanilla Analysis (equation 2.3, Chapter 2 in the lecture notes), we get: \\[ \\begin{aligned} g_t^T(x_t-x^*) &= \\frac{\\gamma_t}{2} ||g_t||^2 + \\frac{1}{2 \\gamma_t} (||x_t - x^*||^2 - ||x_{t+1} - x^*||^2) \\\\ &= \\frac{1}{2} \\frac{R ||g_t||}{\\sqrt{T}} + \\frac{1}{2} \\frac{||g_t|| \\sqrt{T}}{R} (||x_t - x^*||^2 - ||x_{t+1} - x^*||^2) \\\\ &\\leq \\frac{1}{2} \\frac{R ||g_t||}{\\sqrt{T}} + \\frac{1}{2} \\frac{||g_t|| \\sqrt{T}}{R} ||x_t - x_{t+1}||^2 \\\\ &\\leq \\frac{1}{2} \\frac{R ||g_t||}{\\sqrt{T}} + \\frac{1}{2} \\frac{R ||g_t||}{\\sqrt{T}} = \\frac{R ||g_t||}{\\sqrt{T}} \\end{aligned} \\] Finally, by following the same steps as in the Vanilla Analysis, we get: \\[ \\sum_{t=0}^{T-1}{(f(x_t) - f(x^*))} \\leq \\sum_{t=0}^{T-1}{\\frac{R ||g_t||}{\\sqrt{T}}} \\leq RB \\sqrt{T} \\] Hence, for \\(T = \\frac{\\epsilon^2}{R^2B^2}\\) we get our desired result. Exercise 17 i) From \\(\\nabla f = \\sum \\lambda_i \\nabla f_i(x)\\) , we get: \\[ \\begin{aligned} || \\nabla f(x) - \\nabla f(y) || &= || \\sum \\lambda_i (\\nabla f_i(x) - \\nabla f_i(y)) || \\\\ &\\leq \\sum \\lambda_i || \\nabla f_i(x) - \\nabla f_i(y)) || && \\text{Cauchy-Schwarz} \\\\ &\\leq \\sum \\lambda_i L_i || x - y || \\end{aligned} \\] ii) Let \\(y = Ax+b\\) . Then we get \\(\\frac{\\partial y_j}{\\partial x_i} = A_{ji} = A^T_{ij}\\) and hence \\(\\frac{df(y)}{dx_i} = \\sum \\frac{\\partial f(y)}{\\partial y_j} \\frac{\\partial y_j}{\\partial x_i} = A^T_{i,:} \\nabla f(y)\\) . Let \\(u, v \\in \\text{dom}(f)\\) and we define \\(z := \\nabla f(Au + b) - \\nabla f(Av + b)\\) . Then: \\[ \\begin{aligned} || \\nabla f(u) - \\nabla f(v) || &= || A^T z|| \\\\ &= || A^T \\frac{z}{||z||} \\cdot ||z|| \\, || \\\\ &\\leq || A^T || \\cdot ||z|| && \\text{definition of spectral norm}\\\\ &\\leq || A^T || \\cdot L ||A (u - v)|| && \\text{by smoothness of } f \\\\ &\\leq || A^T || \\cdot L ||A|| \\cdot ||u - v|| \\end{aligned} \\] Since \\(|| A^T || = || A ||\\) , we get the desired result. Exercise 18 Idea: Choose \\(\\gamma\\) such that we still have sufficient decrease in each update step... Exercise 20 If we can show the existence of a global minimum \\(x^*\\) then from the definition of strongly convex functions we get \\[ f(y) \\geq f(x^*) + \\frac{\\mu}{2} || x^* - y||^2, \\] which makes \\(x^*\\) unique for \\(\\mu > 0\\) . Let us pick a random \\(x \\in \\text{dom}(f)\\) . Since \\[ g(y) = f(x) + \\nabla f(x)^T (y - x) + \\frac{\\mu}{2} || x - y||^2 \\] is a strong convex function, there must be a \\(y^*\\) that is the global unique minimum of \\(g\\) . Hence, \\(f\\) is bounded from below by \\(g(y^*)\\) which implies the existence of a global minimum in \\(f\\) .","title":"Exercise Set 2"},{"location":"Sem6/ODS/ex2/#exercise-set-2","text":"","title":"Exercise Set 2"},{"location":"Sem6/ODS/ex2/#exercise-13","text":"By Cauchy-Schwarz : \\[ |c^T x| \\leq ||c||\\, ||x|| \\] Hence, the spectral norm of \\(c^T\\) is bounded by \\(||c||\\) . This bound is reached at \\(x = c\\) and hence equal to the Euclidean norm.","title":"Exercise 13"},{"location":"Sem6/ODS/ex2/#exercsie-14","text":"We proof that the gradients of \\(f\\) are Lipschitz continuous which implies smoothness of \\(f\\) ( Lemma 2.4 from the lecture notes): \\[ \\nabla f(x) = (Q + Q^T) x + b = 2Qx + b \\] \\[ \\begin{aligned} ||2Q(x-y)|| = ||2Q\\frac{x-y}{||x-y||} ||x-y|||| \\leq 2||Q|| \\cdot ||x-y|| \\end{aligned} \\]","title":"Exercsie 14"},{"location":"Sem6/ODS/ex2/#exercise-16","text":"The idea is to adapt the step size \\(\\gamma\\) so that we do not make updates on \\(x\\) that are too large. One way to constrain the step size is by normalizing the gradients. Therefore, we guess: \\[ \\gamma_t = \\frac{R}{||g_t|| \\sqrt{T}} \\] Then, we can bound the updates on \\(x\\) by: \\[ \\begin{aligned} x_{t+1} &= x_t - \\frac{R}{||g_t|| \\sqrt{T}} g_t \\\\ || x_{t+1} - x_t ||^2 &\\leq \\frac{R^2}{T} \\end{aligned} \\] From the Vanilla Analysis (equation 2.3, Chapter 2 in the lecture notes), we get: \\[ \\begin{aligned} g_t^T(x_t-x^*) &= \\frac{\\gamma_t}{2} ||g_t||^2 + \\frac{1}{2 \\gamma_t} (||x_t - x^*||^2 - ||x_{t+1} - x^*||^2) \\\\ &= \\frac{1}{2} \\frac{R ||g_t||}{\\sqrt{T}} + \\frac{1}{2} \\frac{||g_t|| \\sqrt{T}}{R} (||x_t - x^*||^2 - ||x_{t+1} - x^*||^2) \\\\ &\\leq \\frac{1}{2} \\frac{R ||g_t||}{\\sqrt{T}} + \\frac{1}{2} \\frac{||g_t|| \\sqrt{T}}{R} ||x_t - x_{t+1}||^2 \\\\ &\\leq \\frac{1}{2} \\frac{R ||g_t||}{\\sqrt{T}} + \\frac{1}{2} \\frac{R ||g_t||}{\\sqrt{T}} = \\frac{R ||g_t||}{\\sqrt{T}} \\end{aligned} \\] Finally, by following the same steps as in the Vanilla Analysis, we get: \\[ \\sum_{t=0}^{T-1}{(f(x_t) - f(x^*))} \\leq \\sum_{t=0}^{T-1}{\\frac{R ||g_t||}{\\sqrt{T}}} \\leq RB \\sqrt{T} \\] Hence, for \\(T = \\frac{\\epsilon^2}{R^2B^2}\\) we get our desired result.","title":"Exercise 16"},{"location":"Sem6/ODS/ex2/#exercise-17","text":"i) From \\(\\nabla f = \\sum \\lambda_i \\nabla f_i(x)\\) , we get: \\[ \\begin{aligned} || \\nabla f(x) - \\nabla f(y) || &= || \\sum \\lambda_i (\\nabla f_i(x) - \\nabla f_i(y)) || \\\\ &\\leq \\sum \\lambda_i || \\nabla f_i(x) - \\nabla f_i(y)) || && \\text{Cauchy-Schwarz} \\\\ &\\leq \\sum \\lambda_i L_i || x - y || \\end{aligned} \\] ii) Let \\(y = Ax+b\\) . Then we get \\(\\frac{\\partial y_j}{\\partial x_i} = A_{ji} = A^T_{ij}\\) and hence \\(\\frac{df(y)}{dx_i} = \\sum \\frac{\\partial f(y)}{\\partial y_j} \\frac{\\partial y_j}{\\partial x_i} = A^T_{i,:} \\nabla f(y)\\) . Let \\(u, v \\in \\text{dom}(f)\\) and we define \\(z := \\nabla f(Au + b) - \\nabla f(Av + b)\\) . Then: \\[ \\begin{aligned} || \\nabla f(u) - \\nabla f(v) || &= || A^T z|| \\\\ &= || A^T \\frac{z}{||z||} \\cdot ||z|| \\, || \\\\ &\\leq || A^T || \\cdot ||z|| && \\text{definition of spectral norm}\\\\ &\\leq || A^T || \\cdot L ||A (u - v)|| && \\text{by smoothness of } f \\\\ &\\leq || A^T || \\cdot L ||A|| \\cdot ||u - v|| \\end{aligned} \\] Since \\(|| A^T || = || A ||\\) , we get the desired result.","title":"Exercise 17"},{"location":"Sem6/ODS/ex2/#exercise-18","text":"Idea: Choose \\(\\gamma\\) such that we still have sufficient decrease in each update step...","title":"Exercise 18"},{"location":"Sem6/ODS/ex2/#exercise-20","text":"If we can show the existence of a global minimum \\(x^*\\) then from the definition of strongly convex functions we get \\[ f(y) \\geq f(x^*) + \\frac{\\mu}{2} || x^* - y||^2, \\] which makes \\(x^*\\) unique for \\(\\mu > 0\\) . Let us pick a random \\(x \\in \\text{dom}(f)\\) . Since \\[ g(y) = f(x) + \\nabla f(x)^T (y - x) + \\frac{\\mu}{2} || x - y||^2 \\] is a strong convex function, there must be a \\(y^*\\) that is the global unique minimum of \\(g\\) . Hence, \\(f\\) is bounded from below by \\(g(y^*)\\) which implies the existence of a global minimum in \\(f\\) .","title":"Exercise 20"},{"location":"Sem6/ODS/ex3/","text":"Exercise Set 3 A. Subgradients Exercise 3.1 If \\(f\\) is differentiable, then by definition: $$ f(y) = f(x) + \\nabla f(x)^T (y - x) + r(y - x), $$ where \\(r\\) is a function that satisfies: $$ \\lim_{v \\rightarrow 0} \\frac{||r(v)||}{||v||} = 0 $$ Let us assume that there exists a subgradient \\(g\\) at \\(x\\) for \\(f\\) : $$ f(y) = f(x) + g^T (y - x) + r'(y-x) \\quad \\forall y, $$ where \\(r'\\) maps to \\(\\mathbb{R}_0^+\\) . Hence, for all \\(y \\in dom(f)\\) the following holds: $$ \\begin{aligned} f(x) + g^T (y - x) &\\leq f(x) + g^T (y - x) + r'(y-x) \\ &\\leq f(x) + \\nabla f(x)^T (y - x) + r(y - x) \\ &= f(y) \\end{aligned} $$ However, uniqueness of \\(\\nabla f(x)\\) yields the identity \\(g \\equiv \\nabla f(x)\\) . Moreover, by definition of convexity, \\(g\\) does only exist when \\(f\\) is convex . Hence, we get \\(\\partial f(x) \\subseteq \\{\\nabla f(x)\\}\\) . Exercise 3.2 (Lipschitz continuity and bounded subgradient) By convexity we get for all \\(g \\in \\partial f(x)\\) : $$ f(y) \\geq f(x) + g^T (y - x) $$ From this definition we can derive the following bounds: $$ \\begin{aligned} f(x) - f(y) &\\leq -g^T (y - x) \\ |f(x) - f(y)| &\\leq |-g^T (y - x)| \\ &\\leq ||g|| \\cdot ||y - x|| && \\text{Cauchy-Schwarz} \\end{aligned} $$ \\((i) \\rightarrow (ii)\\) : Follows immediately by inserting \\(||g|| \\leq B\\) into the term above. \\((ii) \\rightarrow (i)\\) : Follows immediately from \\(||g|| \\cdot ||y - x|| \\leq B \\cdot ||y - x|| \\rightarrow ||g|| \\leq B\\) . B. Subgradient Descent under Polyak's Stepsize Exercise 3.3 (Convex setting) By the basic descent lemma : $$ ||x_{t+1} - x^ ||_2^2 \\leq ||x_t - x^ || 2^2 - 2 \\gamma_t (f(x_t) - f^ ) + \\gamma_t^2 ||g_t||_2^2 $$ Now we use our assumption \\(||g_t|| < B\\) and plug in Polyak's step size \\(\\gamma_t = \\frac{f(x_t) - f^*}{||g_t||_2^2}\\) : $$ \\begin{aligned} ||x_{t+1} - x^ ||_2^2 &\\leq ||x_t - x^ ||_2^2 - 2 \\frac{f(x_t) - f^ }{||g_t||_2^2} (f(x_t) - f^ ) + \\left(\\frac{f(x_t) - f^ }{||g_t||_2^2}\\right)^2 ||g_t||_2^2 \\ &= ||x_t - x^ ||_2^2 - \\frac{(f(x_t) - f^ )^2}{||g_t||_2^2} \\ &\\leq ||x_t - x^ ||_2^2 - \\frac{(f(x_t) - f^ )^2}{B^2} \\end{aligned} $$ Taking the sum over all time steps yields: $$ \\begin{aligned} \\sum ^T \\frac{(f(x_t) - f^ )^2}{B^2} &\\leq \\sum_{t=1}^T ||x_t - x^ || 2^2 - ||x - x^ ||_2^2 \\ &\\leq ||x_1 - x^ || 2^2 \\end{aligned} $$ Finally, using that \\(f(x_t) \\geq f^*\\) we get the desired result: $$ \\begin{aligned} \\frac{T}{B^2} \\cdot (\\min f(x_t) - f^ )^2 &\\leq ||x_1 - x^ || 2^2 \\ \\min f(x_t) - f^ &\\leq \\frac{B}{\\sqrt{T}} ||x_1 - x^ ||_2 \\end{aligned} $$ Exercise 3.4 (Strongly convex setting) By definition of \\(\\mu\\) -strongly convex , non-differentiable functions: $$ \\begin{aligned} f(x^ ) &\\geq f(x_t) + g_t^T(x^ - x_t) + \\frac{\\mu}{2}||x_t - x^ ||^2 \\ g_t^T(x^t - x_ ) &\\geq f(x_t) - f(x^ ) + \\frac{\\mu}{2}||x_t - x^ ||^2 \\end{aligned} $$ Using the basic descent lemma : $$ ||x_{t+1} - x^ ||_2^2 \\leq ||x_t - x^ || 2^2 - 2 \\gamma_t \\left(f(x_t) - f(x^ ) + \\frac{\\mu}{2}||x_t - x^ ||_2^2 \\right) + \\gamma_t^2 ||g_t||_2^2 $$ Now we plug in Polyak's step-size and use our assumption \\(||g_t|| < B\\) : $$ \\begin{aligned} ||x - x^ ||_2^2 &\\leq ||x_t - x^ || 2^2 - \\frac{(f(x_t) - f^ )^2}{B^2} - \\frac{\\mu}{B^2}(f(x_t) - f^ )||x_t - x^ ||_2^2 \\ &\\leq ||x_t - x^ ||_2^2 - \\frac{\\mu}{B^2}(f(x_t) - f^ )||x_t - x^ ||_2^2 \\end{aligned} $$ Again, taking the telescoping sum yields: $$ \\begin{aligned} \\sum ^T \\frac{\\mu}{B^2}(f(x_t) - f^ )||x_t - x^ || 2^2 &\\leq \\sum ^T ||x_t - x^ || 2^2 - ||x - x^ || 2^2 \\ \\left(\\min f(x_t) - f^ \\right) \\cdot \\frac{\\mu}{B^2} \\sum_{t=1}^T ||x_t - x^ || 2^2 &\\leq ||x - x^ || 2^2 \\ \\left(\\min f(x_t) - f^ \\right) \\cdot \\frac{\\mu}{B^2} T ||x_1 - x^ || 2^2 &\\leq ||x - x^ || 2^2 \\ \\min f(x_t) - f^* &\\leq \\frac{B^2}{\\mu T} \\ &\\leq \\frac{4B^2}{\\mu T} \\end{aligned} $$ C. Programming on SVM Classification Implementation of Subgradient Descent [TODO] How to choose sub-gradient?","title":"Exercise Set 3"},{"location":"Sem6/ODS/ex3/#exercise-set-3","text":"","title":"Exercise Set 3"},{"location":"Sem6/ODS/ex3/#a-subgradients","text":"","title":"A. Subgradients"},{"location":"Sem6/ODS/ex3/#exercise-31","text":"If \\(f\\) is differentiable, then by definition: $$ f(y) = f(x) + \\nabla f(x)^T (y - x) + r(y - x), $$ where \\(r\\) is a function that satisfies: $$ \\lim_{v \\rightarrow 0} \\frac{||r(v)||}{||v||} = 0 $$ Let us assume that there exists a subgradient \\(g\\) at \\(x\\) for \\(f\\) : $$ f(y) = f(x) + g^T (y - x) + r'(y-x) \\quad \\forall y, $$ where \\(r'\\) maps to \\(\\mathbb{R}_0^+\\) . Hence, for all \\(y \\in dom(f)\\) the following holds: $$ \\begin{aligned} f(x) + g^T (y - x) &\\leq f(x) + g^T (y - x) + r'(y-x) \\ &\\leq f(x) + \\nabla f(x)^T (y - x) + r(y - x) \\ &= f(y) \\end{aligned} $$ However, uniqueness of \\(\\nabla f(x)\\) yields the identity \\(g \\equiv \\nabla f(x)\\) . Moreover, by definition of convexity, \\(g\\) does only exist when \\(f\\) is convex . Hence, we get \\(\\partial f(x) \\subseteq \\{\\nabla f(x)\\}\\) .","title":"Exercise 3.1"},{"location":"Sem6/ODS/ex3/#exercise-32-lipschitz-continuity-and-bounded-subgradient","text":"By convexity we get for all \\(g \\in \\partial f(x)\\) : $$ f(y) \\geq f(x) + g^T (y - x) $$ From this definition we can derive the following bounds: $$ \\begin{aligned} f(x) - f(y) &\\leq -g^T (y - x) \\ |f(x) - f(y)| &\\leq |-g^T (y - x)| \\ &\\leq ||g|| \\cdot ||y - x|| && \\text{Cauchy-Schwarz} \\end{aligned} $$ \\((i) \\rightarrow (ii)\\) : Follows immediately by inserting \\(||g|| \\leq B\\) into the term above. \\((ii) \\rightarrow (i)\\) : Follows immediately from \\(||g|| \\cdot ||y - x|| \\leq B \\cdot ||y - x|| \\rightarrow ||g|| \\leq B\\) .","title":"Exercise 3.2 (Lipschitz continuity and bounded subgradient)"},{"location":"Sem6/ODS/ex3/#b-subgradient-descent-under-polyaks-stepsize","text":"","title":"B. Subgradient Descent under Polyak's Stepsize"},{"location":"Sem6/ODS/ex3/#exercise-33-convex-setting","text":"By the basic descent lemma : $$ ||x_{t+1} - x^ ||_2^2 \\leq ||x_t - x^ || 2^2 - 2 \\gamma_t (f(x_t) - f^ ) + \\gamma_t^2 ||g_t||_2^2 $$ Now we use our assumption \\(||g_t|| < B\\) and plug in Polyak's step size \\(\\gamma_t = \\frac{f(x_t) - f^*}{||g_t||_2^2}\\) : $$ \\begin{aligned} ||x_{t+1} - x^ ||_2^2 &\\leq ||x_t - x^ ||_2^2 - 2 \\frac{f(x_t) - f^ }{||g_t||_2^2} (f(x_t) - f^ ) + \\left(\\frac{f(x_t) - f^ }{||g_t||_2^2}\\right)^2 ||g_t||_2^2 \\ &= ||x_t - x^ ||_2^2 - \\frac{(f(x_t) - f^ )^2}{||g_t||_2^2} \\ &\\leq ||x_t - x^ ||_2^2 - \\frac{(f(x_t) - f^ )^2}{B^2} \\end{aligned} $$ Taking the sum over all time steps yields: $$ \\begin{aligned} \\sum ^T \\frac{(f(x_t) - f^ )^2}{B^2} &\\leq \\sum_{t=1}^T ||x_t - x^ || 2^2 - ||x - x^ ||_2^2 \\ &\\leq ||x_1 - x^ || 2^2 \\end{aligned} $$ Finally, using that \\(f(x_t) \\geq f^*\\) we get the desired result: $$ \\begin{aligned} \\frac{T}{B^2} \\cdot (\\min f(x_t) - f^ )^2 &\\leq ||x_1 - x^ || 2^2 \\ \\min f(x_t) - f^ &\\leq \\frac{B}{\\sqrt{T}} ||x_1 - x^ ||_2 \\end{aligned} $$","title":"Exercise 3.3 (Convex setting)"},{"location":"Sem6/ODS/ex3/#exercise-34-strongly-convex-setting","text":"By definition of \\(\\mu\\) -strongly convex , non-differentiable functions: $$ \\begin{aligned} f(x^ ) &\\geq f(x_t) + g_t^T(x^ - x_t) + \\frac{\\mu}{2}||x_t - x^ ||^2 \\ g_t^T(x^t - x_ ) &\\geq f(x_t) - f(x^ ) + \\frac{\\mu}{2}||x_t - x^ ||^2 \\end{aligned} $$ Using the basic descent lemma : $$ ||x_{t+1} - x^ ||_2^2 \\leq ||x_t - x^ || 2^2 - 2 \\gamma_t \\left(f(x_t) - f(x^ ) + \\frac{\\mu}{2}||x_t - x^ ||_2^2 \\right) + \\gamma_t^2 ||g_t||_2^2 $$ Now we plug in Polyak's step-size and use our assumption \\(||g_t|| < B\\) : $$ \\begin{aligned} ||x - x^ ||_2^2 &\\leq ||x_t - x^ || 2^2 - \\frac{(f(x_t) - f^ )^2}{B^2} - \\frac{\\mu}{B^2}(f(x_t) - f^ )||x_t - x^ ||_2^2 \\ &\\leq ||x_t - x^ ||_2^2 - \\frac{\\mu}{B^2}(f(x_t) - f^ )||x_t - x^ ||_2^2 \\end{aligned} $$ Again, taking the telescoping sum yields: $$ \\begin{aligned} \\sum ^T \\frac{\\mu}{B^2}(f(x_t) - f^ )||x_t - x^ || 2^2 &\\leq \\sum ^T ||x_t - x^ || 2^2 - ||x - x^ || 2^2 \\ \\left(\\min f(x_t) - f^ \\right) \\cdot \\frac{\\mu}{B^2} \\sum_{t=1}^T ||x_t - x^ || 2^2 &\\leq ||x - x^ || 2^2 \\ \\left(\\min f(x_t) - f^ \\right) \\cdot \\frac{\\mu}{B^2} T ||x_1 - x^ || 2^2 &\\leq ||x - x^ || 2^2 \\ \\min f(x_t) - f^* &\\leq \\frac{B^2}{\\mu T} \\ &\\leq \\frac{4B^2}{\\mu T} \\end{aligned} $$","title":"Exercise 3.4 (Strongly convex setting)"},{"location":"Sem6/ODS/ex3/#c-programming-on-svm-classification","text":"","title":"C. Programming on SVM Classification"},{"location":"Sem6/ODS/ex3/#implementation-of-subgradient-descent","text":"[TODO] How to choose sub-gradient?","title":"Implementation of Subgradient Descent"},{"location":"Sem6/ODS/ex4/","text":"Exercise Set 4 A. Bregman Divergence Exercise 4.1 Proof: $$ V_w(x, z) = V_w(x, y) + V_w(y, z) - \\left \\langle \\nabla w(z) - \\nabla w(y), x - y \\right \\rangle $$ \\[ V_w(x, y) = w(x) - w(y) - \\nabla w(y)^T (x - y) \\] Pluggin in the definition, we get: \\[ \\begin{align*} V_w(x, z) &\\stackrel{!}{=} V_w(x, y) + V_w(y, z) - \\left \\langle \\nabla w(z) - \\nabla w(y), x - y \\right \\rangle \\\\ &= w(x) - w(y) - \\nabla w(y)^T (x - y) \\\\ &\\quad + w(y) - w(z) - \\nabla w(z)^T (y - z) \\\\ &\\quad - \\left \\langle \\nabla w(z) - \\nabla w(y), x - y \\right \\rangle \\\\ &= w(x) - w(z) - \\nabla w(z)^T (y - z) \\\\ &\\quad - \\left \\langle \\nabla w(z), x - y \\right \\rangle \\\\ &= w(x) - w(z) - \\nabla w(z)^T (x - z) \\end{align*} \\]","title":"Exercise Set 4"},{"location":"Sem6/ODS/ex4/#exercise-set-4","text":"","title":"Exercise Set 4"},{"location":"Sem6/ODS/ex4/#a-bregman-divergence","text":"","title":"A. Bregman Divergence"},{"location":"Sem6/ODS/ex4/#exercise-41","text":"Proof: $$ V_w(x, z) = V_w(x, y) + V_w(y, z) - \\left \\langle \\nabla w(z) - \\nabla w(y), x - y \\right \\rangle $$ \\[ V_w(x, y) = w(x) - w(y) - \\nabla w(y)^T (x - y) \\] Pluggin in the definition, we get: \\[ \\begin{align*} V_w(x, z) &\\stackrel{!}{=} V_w(x, y) + V_w(y, z) - \\left \\langle \\nabla w(z) - \\nabla w(y), x - y \\right \\rangle \\\\ &= w(x) - w(y) - \\nabla w(y)^T (x - y) \\\\ &\\quad + w(y) - w(z) - \\nabla w(z)^T (y - z) \\\\ &\\quad - \\left \\langle \\nabla w(z) - \\nabla w(y), x - y \\right \\rangle \\\\ &= w(x) - w(z) - \\nabla w(z)^T (y - z) \\\\ &\\quad - \\left \\langle \\nabla w(z), x - y \\right \\rangle \\\\ &= w(x) - w(z) - \\nabla w(z)^T (x - z) \\end{align*} \\]","title":"Exercise 4.1"},{"location":"Sem6/ODS/ods/","text":"Optimization for Data Science - Lectures W1 Lecture 1 \\(f: dom(f) \\rightarrow R\\) is convex , iff \\(dom(f)\\) is convex and for all \\(x, y \\in dom(f)\\) , \\(0 \\leq \\lambda \\leq 1\\) : \\[f(\\lambda x + (1 - \\lambda)y) \\leq \\lambda f(x) + (1 - \\lambda) f(y)\\] If \\(dom(f) \\subseteq R^d\\) is finite and open \\(\\rightarrow\\) \\(f\\) is continuous . W1 Lecture 2 Example: Convex function that is discontinuous . \\(V\\) = set of univariate polynomials (countable infinite vector space). Let \\(dom(f) = V\\) and define \\(f\\) as follows: \\[f(p) = p'(0)\\] Proof : \\(f\\) is discontinuous at \\(0\\) (by means of the superior norm defined on \\(V\\) ). Idea : Find sequence of polynomials that converge to \\(0\\) but have a non-zero derivative at \\(0\\) . For example, polynomials that approximate the sinus curve. Differentiable Function A function \\(f\\) that can be locally approximated ( error term is sub-linear ) by an affine function \\(l\\) : \\[l(y) = f(x) + A(y - x)\\] Sub-Linearity of error term \\(r(v)\\) ( \\(v = y - x\\) , \\(x\\) constant): \\[ lim_{v \\rightarrow 0} \\frac{|r(v)|}{|v|} = 0\\] 1st order characterization of convexity: If \\(f\\) is convex and differentiable \\(\\leftrightarrow\\) \\[f(x) \\geq f(x) + \\nabla f(x)^T (y - x)\\] Proof : Use definition and differentiability of a convex function and convexity of \\(dom(f)\\) . 2nd order characterization of convexity \\(\\nabla^2 f(x) \\succeq 0\\) is positive semidefinite. Operation that preserve Convexity sum of convex functions composition with an affine function, \\(f(Ax+b)\\) Properties of convex functions local minima are global minima (Proof by contradiction) critical points ( \\(x\\) s.t. \\(\\nabla f(x) = 0\\) ) are global minima ( Gradient descent tries to find those points) Strictly convex functions same rules as for convex functions but without equality Constrained minimaztion \\(x^* \\in X\\) , \\(X \\in dom(f)\\) convex, is a minimizer of \\(f\\) over \\(X\\) iff \\[\\nabla f(x^*)^T (x - x^*) \\geq 0, \\forall x \\in X\\] Existence of a minimizer \\(\\alpha\\) -sublevel set of \\(f\\) \\[f^{\\leq \\alpha} := \\{x \\in R^d: f(x) \\leq \\alpha\\}\\] The Weierstrass Theorem : If there is a nonempty and bounded sublevel set \\(f^{\\leq \\alpha}\\) \\(\\rightarrow\\) \\(f\\) has a global minimum . Proof : Continuous functions attain a minimum in a compact set. Weekly coercive functions W2 Lecture 3 - Gradient Descent Idea Suppose there is a global minimum at \\(x^*\\) . Find \\(x\\) s.t. \\[ f(x) - f(x^*) \\leq \\epsilon \\] The Algorithm \\[ x_{t+1} := x_t + v_t \\] How to choose \\(v_t\\) ? \\[ \\begin{aligned} f(x_t + v_t) &\\approx f(x_t) + \\nabla f(x_t)^T v_t \\\\ &\\geq f(x_t) - \\nabla f(x_t)^T \\nabla f(x_t) && \\text{Cauchy-Schwarz} \\end{aligned} \\] Hence, gradient descent takes the following update step with constant step-size \\(\\gamma\\) : $$ x_{t+1} = x_t - \\gamma \\nabla f(x_t) $$ Vanilla Analysis How to bound \\(f(x_t) - f(x^*)\\) ? Theorem 2.1: \\[ \\gamma = \\frac{R}{B\\sqrt{T}} \\] \\[ \\frac{1}{T} \\sum_{t=0}^{T-1}{(f(x_t) - f(x^*))} \\leq \\frac{RB}{\\sqrt{T}} \\] \\[ T \\geq \\frac{R^2B^2}{\\epsilon^2} \\rightarrow \\frac{RB}{\\sqrt{T}} \\leq \\epsilon \\] dimension independent (but constants could depend on dimension) holds for average and best iterate Smooth Functions \\[ f(y) \\leq f(x) + \\nabla f(x)^T (y - x) + \\frac{L}{2} ||x-y||^2 \\] Not confused with infinitely often differentiable W2 Lecture 4 - Gradient Descent cont'd Smooth Functions cont'd Trick: \\[ y^2 = x^2 + 2x(y - x) + (x - y)^2 \\] Operations the preserve smoothness: Summation and composition with an affine function. f smooth \\(\\leftrightarrow\\) Lipschitz continuity of \\(\\nabla f\\) Sufficient decrease If \\(f\\) is smooth on the line segment connecting \\(x_{t+1}\\) and \\(x_t\\) $$ \\gamma = \\frac{1}{L} $$ $$ f(x_{t+1}) \\leq f(x_t) - \\frac{1}{2L} ||\\nabla f(x_t)||^2 $$ Proof: Use smoothness and plug-in definition of gradient-descent Theorem If \\(f\\) is smooth and convex : \\[ f(x_{T}) - f(x^*) \\leq \\frac{L}{2T} ||x_0 - x^*||^2 \\] Proof: Use sufficient decrease and result from Vanilla Analysis TODO Last iterate is the best \\[ T \\geq \\frac{R^2L}{2 \\epsilon} \\rightarrow \\frac{L}{2T}R^2 \\leq \\epsilon \\] Nesterov's accelerated gradient descent Best algorithm for smooth convex functions: \\(O \\left(\\frac{1}{\\sqrt{\\epsilon}} \\right)\\) steps Proof: Based on potential functions. 3 ingredients: Sufficient decrease Vanilla Analysis Convexity (graph above the tangent hyperplane) Strongly Convex Functions Motivation: Supermodel \\(f(x) = x^2\\) has much better (exponential) convergence than we proved for general smooth functions. Definition: $$ f(x) \\geq f(x) + \\nabla f(x)^T (y - x) + \\frac{\\mu}{2} ||x - y||^2 $$ Theorem 2.12 - Smooth and strongly convex functions: \\(O(\\log{\\frac{1}{\\epsilon}})\\) steps i) \\[ ||x_{t+1} - x^*|| \\leq \\left(1 - \\frac{\\mu}{L} \\right) ||x_t - x^*||^2 \\] ii) \\[ f(x_T) - f(x^*) \\leq \\frac{L}{2} \\left(1 - \\frac{\\mu}{L} \\right)^T ||x_0 - x^*||^2 \\] Proof : Use result from Vanilla Analysis Use stronger lower bound from strong convexity \\[ T \\geq \\frac{L}{\\mu} \\log {\\frac{R^2L}{2 \\epsilon}} \\rightarrow \\frac{L}{2} \\left(1 - \\frac{\\mu}{L} \\right)^T R^2 \\leq \\epsilon \\] W3 Lecture 5 - Nonsmooth Optimization Operations that make the function non-smooth (non-differentiable) Examples: Lasso Soft Margin SVM => hinge loss non-smooth Subgradients \\(g\\) is a subgradient (non-unique) if \\[ f(y) \\geq f(x) + g^T (y - x) \\] Hyperplane seperation theorem Convex sets that do not intersect are seperable by a hyperplane Convex and Lipschitz <=> bounded subgradients W3 Lecture 6 - Nonsmooth Optimization cont'd Descent Directions TODO Subgradient descent $$ x_{t+1} = \\Pi_X(x_t - \\gamma_t g_t), $$ where \\(g_t \\in \\partial f\\) Choices for step size constant Scaled (divide through subgradient norm) Non-summable but diminishing stepsize Square summable stepsize \\(\\gamma = 1 / t\\) Polyak's stepsize \\(\\gamma_t = \\frac{f(x_t) - f(x^*)}{||g_t||_2^2}\\) Basic \"Descent\" Lemma \\[ ||x_{t+1} - x^*||_2^2 \\leq ||x_{t} - x^*||_2^2 - 2 \\gamma_t (f(x_t) - f(x^*)) + \\gamma_t^2 ||g_t||_2^2 \\] Main Theorem on Convergence If \\(f\\) is convex: $$ \\min_{1 \\leq t \\leq T} f(x_t) - f^ \\leq \\frac{||x_1 - x^ || 2^2 + \\sum ^T {\\gamma_t^2 ||g_t|| 2^2}}{2 \\sum ^T \\gamma_t} $$ and $$ f(\\hat{x} t) - f^ \\leq \\frac{||x_1 - x^ ||_2^2 + \\sum ^T {\\gamma_t^2 ||g_t|| 2^2}}{2 \\sum ^T \\gamma_t}, $$ where \\(\\hat{x}_t = \\frac{\\sum_{t=1}^T \\gamma_t x_t}{\\sum_{t=1}^T \\gamma_t}\\) . Convergence Rate fro Convex Lipschitz Problem Convergence for Strongly Convex Lipschitz case Lower bound W4 Lecture 7 & 8 - Nonsmooth and Composite Optimization Motivation: Try to exploit: - non-Euclidean geometry -> Mirror descent - structure of \\(f\\) -> Proximal algorithms Norms Bregmann Divergence mirror function Mirror descent Convergence of mirror descent $ \\gamma_t(f(x_t) - f^ ) \\leq V_w^t - V_w^{t+1} + \\frac{\\gamma_t^2}{2} ||g_t||_ ^2, $ where \\(||.||_*\\) is the dual norm. Proof TODO Convex Composite Optimization \\[ \\min_{x \\in R^d} f(x) + g(x) \\] Proximal operator Proximal Gradient Method Interpretations Interpretation 1 Lecture 5 - Stochastic Optimization \\[ \\min_{x \\in R^d} F(x) := E_{\\xi}[f(x, \\xi)] \\] Assumptions: - \\(f\\) convex in \\(x\\) and differentiable => \\(F(x)\\) is convex Similar to big- \\(n\\) problem (empirical risk). Stochastic Gradient Descent unbiased estimate Convergence Analysis Convex case Strongly convex case Smooth and strongly convex case Variance Reduction Techniques Adaptive methods Lecture 6 - Nonconvex optimization Bounded Hessians => smooth smooth => bounded hessians (over any open convex set) Say something about convergence of \\(||\\nabla f(x_t)||^2 \\rightarrow 0\\) . Gradient descent on smooth functions No overshooting with \\(\\gamma = \\frac{1}{L}\\) Trajectory analysis Balanced iterates Bounded Hessians along the trajectory Lecture 7 - Newton's Method and Quasi-Newton methods Newton-Raphson method Find zeros (Newton is referred to in optimization with 2nd derivatives, Newton-Raphson wants to find zeros - only involves first derivative) does not always converge The Babylonian method Find zero of \\(f(x) = x^2 - R\\) Newton's method \\[x_{t+1} = x_t - \\nabla^2 f(x_t)^{-1} \\nabla f(x_t)\\] = minimize second order taylor expansion at each step Once you're close you're there (when close to optimum, super-exponentially fast). Intuition, Hessian nearly constant close to optimum. Quasi Newton Methods Motivation by secant methods (replace gradient with finite difference) How to choose \\(H_t\\) : $$ \\nabla f(x_t) - \\nabla f(x_{t-1}) = H_t (x_t - x_{t-1}), \\quad H_t = H_t^T $$ Greenstadt TODO recap derivation from lecture notes (involves Lagrange multipliers) Goldfarb => BFGS method BFGS method M = L-BFGS Normal \\(m = 10\\) No theoretical runtime guarantees","title":"Lectures"},{"location":"Sem6/ODS/ods/#optimization-for-data-science-lectures","text":"","title":"Optimization for Data Science - Lectures"},{"location":"Sem6/ODS/ods/#w1-lecture-1","text":"\\(f: dom(f) \\rightarrow R\\) is convex , iff \\(dom(f)\\) is convex and for all \\(x, y \\in dom(f)\\) , \\(0 \\leq \\lambda \\leq 1\\) : \\[f(\\lambda x + (1 - \\lambda)y) \\leq \\lambda f(x) + (1 - \\lambda) f(y)\\] If \\(dom(f) \\subseteq R^d\\) is finite and open \\(\\rightarrow\\) \\(f\\) is continuous .","title":"W1 Lecture 1"},{"location":"Sem6/ODS/ods/#w1-lecture-2","text":"","title":"W1 Lecture 2"},{"location":"Sem6/ODS/ods/#example-convex-function-that-is-discontinuous","text":"\\(V\\) = set of univariate polynomials (countable infinite vector space). Let \\(dom(f) = V\\) and define \\(f\\) as follows: \\[f(p) = p'(0)\\] Proof : \\(f\\) is discontinuous at \\(0\\) (by means of the superior norm defined on \\(V\\) ). Idea : Find sequence of polynomials that converge to \\(0\\) but have a non-zero derivative at \\(0\\) . For example, polynomials that approximate the sinus curve.","title":"Example: Convex function that is discontinuous."},{"location":"Sem6/ODS/ods/#differentiable-function","text":"A function \\(f\\) that can be locally approximated ( error term is sub-linear ) by an affine function \\(l\\) : \\[l(y) = f(x) + A(y - x)\\] Sub-Linearity of error term \\(r(v)\\) ( \\(v = y - x\\) , \\(x\\) constant): \\[ lim_{v \\rightarrow 0} \\frac{|r(v)|}{|v|} = 0\\]","title":"Differentiable Function"},{"location":"Sem6/ODS/ods/#1st-order-characterization-of-convexity","text":"If \\(f\\) is convex and differentiable \\(\\leftrightarrow\\) \\[f(x) \\geq f(x) + \\nabla f(x)^T (y - x)\\] Proof : Use definition and differentiability of a convex function and convexity of \\(dom(f)\\) .","title":"1st order characterization of convexity:"},{"location":"Sem6/ODS/ods/#2nd-order-characterization-of-convexity","text":"\\(\\nabla^2 f(x) \\succeq 0\\) is positive semidefinite.","title":"2nd order characterization of convexity"},{"location":"Sem6/ODS/ods/#operation-that-preserve-convexity","text":"sum of convex functions composition with an affine function, \\(f(Ax+b)\\)","title":"Operation that preserve Convexity"},{"location":"Sem6/ODS/ods/#properties-of-convex-functions","text":"local minima are global minima (Proof by contradiction) critical points ( \\(x\\) s.t. \\(\\nabla f(x) = 0\\) ) are global minima ( Gradient descent tries to find those points)","title":"Properties of convex functions"},{"location":"Sem6/ODS/ods/#strictly-convex-functions","text":"same rules as for convex functions but without equality","title":"Strictly convex functions"},{"location":"Sem6/ODS/ods/#constrained-minimaztion","text":"\\(x^* \\in X\\) , \\(X \\in dom(f)\\) convex, is a minimizer of \\(f\\) over \\(X\\) iff \\[\\nabla f(x^*)^T (x - x^*) \\geq 0, \\forall x \\in X\\]","title":"Constrained minimaztion"},{"location":"Sem6/ODS/ods/#existence-of-a-minimizer","text":"\\(\\alpha\\) -sublevel set of \\(f\\) \\[f^{\\leq \\alpha} := \\{x \\in R^d: f(x) \\leq \\alpha\\}\\] The Weierstrass Theorem : If there is a nonempty and bounded sublevel set \\(f^{\\leq \\alpha}\\) \\(\\rightarrow\\) \\(f\\) has a global minimum . Proof : Continuous functions attain a minimum in a compact set. Weekly coercive functions","title":"Existence of a minimizer"},{"location":"Sem6/ODS/ods/#w2-lecture-3-gradient-descent","text":"","title":"W2 Lecture 3 - Gradient Descent"},{"location":"Sem6/ODS/ods/#idea","text":"Suppose there is a global minimum at \\(x^*\\) . Find \\(x\\) s.t. \\[ f(x) - f(x^*) \\leq \\epsilon \\]","title":"Idea"},{"location":"Sem6/ODS/ods/#the-algorithm","text":"\\[ x_{t+1} := x_t + v_t \\] How to choose \\(v_t\\) ? \\[ \\begin{aligned} f(x_t + v_t) &\\approx f(x_t) + \\nabla f(x_t)^T v_t \\\\ &\\geq f(x_t) - \\nabla f(x_t)^T \\nabla f(x_t) && \\text{Cauchy-Schwarz} \\end{aligned} \\] Hence, gradient descent takes the following update step with constant step-size \\(\\gamma\\) : $$ x_{t+1} = x_t - \\gamma \\nabla f(x_t) $$","title":"The Algorithm"},{"location":"Sem6/ODS/ods/#vanilla-analysis","text":"How to bound \\(f(x_t) - f(x^*)\\) ? Theorem 2.1: \\[ \\gamma = \\frac{R}{B\\sqrt{T}} \\] \\[ \\frac{1}{T} \\sum_{t=0}^{T-1}{(f(x_t) - f(x^*))} \\leq \\frac{RB}{\\sqrt{T}} \\] \\[ T \\geq \\frac{R^2B^2}{\\epsilon^2} \\rightarrow \\frac{RB}{\\sqrt{T}} \\leq \\epsilon \\] dimension independent (but constants could depend on dimension) holds for average and best iterate","title":"Vanilla Analysis"},{"location":"Sem6/ODS/ods/#smooth-functions","text":"\\[ f(y) \\leq f(x) + \\nabla f(x)^T (y - x) + \\frac{L}{2} ||x-y||^2 \\] Not confused with infinitely often differentiable","title":"Smooth Functions"},{"location":"Sem6/ODS/ods/#w2-lecture-4-gradient-descent-contd","text":"","title":"W2 Lecture 4 - Gradient Descent cont'd"},{"location":"Sem6/ODS/ods/#smooth-functions-contd","text":"Trick: \\[ y^2 = x^2 + 2x(y - x) + (x - y)^2 \\] Operations the preserve smoothness: Summation and composition with an affine function. f smooth \\(\\leftrightarrow\\) Lipschitz continuity of \\(\\nabla f\\)","title":"Smooth Functions cont'd"},{"location":"Sem6/ODS/ods/#sufficient-decrease","text":"If \\(f\\) is smooth on the line segment connecting \\(x_{t+1}\\) and \\(x_t\\) $$ \\gamma = \\frac{1}{L} $$ $$ f(x_{t+1}) \\leq f(x_t) - \\frac{1}{2L} ||\\nabla f(x_t)||^2 $$ Proof: Use smoothness and plug-in definition of gradient-descent","title":"Sufficient decrease"},{"location":"Sem6/ODS/ods/#theorem","text":"If \\(f\\) is smooth and convex : \\[ f(x_{T}) - f(x^*) \\leq \\frac{L}{2T} ||x_0 - x^*||^2 \\] Proof: Use sufficient decrease and result from Vanilla Analysis TODO Last iterate is the best \\[ T \\geq \\frac{R^2L}{2 \\epsilon} \\rightarrow \\frac{L}{2T}R^2 \\leq \\epsilon \\]","title":"Theorem"},{"location":"Sem6/ODS/ods/#nesterovs-accelerated-gradient-descent","text":"Best algorithm for smooth convex functions: \\(O \\left(\\frac{1}{\\sqrt{\\epsilon}} \\right)\\) steps Proof: Based on potential functions. 3 ingredients: Sufficient decrease Vanilla Analysis Convexity (graph above the tangent hyperplane)","title":"Nesterov's accelerated gradient descent"},{"location":"Sem6/ODS/ods/#strongly-convex-functions","text":"Motivation: Supermodel \\(f(x) = x^2\\) has much better (exponential) convergence than we proved for general smooth functions. Definition: $$ f(x) \\geq f(x) + \\nabla f(x)^T (y - x) + \\frac{\\mu}{2} ||x - y||^2 $$","title":"Strongly Convex Functions"},{"location":"Sem6/ODS/ods/#theorem-212-smooth-and-strongly-convex-functions-ologfrac1epsilon-steps","text":"i) \\[ ||x_{t+1} - x^*|| \\leq \\left(1 - \\frac{\\mu}{L} \\right) ||x_t - x^*||^2 \\] ii) \\[ f(x_T) - f(x^*) \\leq \\frac{L}{2} \\left(1 - \\frac{\\mu}{L} \\right)^T ||x_0 - x^*||^2 \\] Proof : Use result from Vanilla Analysis Use stronger lower bound from strong convexity \\[ T \\geq \\frac{L}{\\mu} \\log {\\frac{R^2L}{2 \\epsilon}} \\rightarrow \\frac{L}{2} \\left(1 - \\frac{\\mu}{L} \\right)^T R^2 \\leq \\epsilon \\]","title":"Theorem 2.12 - Smooth and strongly convex functions: \\(O(\\log{\\frac{1}{\\epsilon}})\\) steps"},{"location":"Sem6/ODS/ods/#w3-lecture-5-nonsmooth-optimization","text":"Operations that make the function non-smooth (non-differentiable) Examples: Lasso Soft Margin SVM => hinge loss non-smooth","title":"W3 Lecture 5 - Nonsmooth Optimization"},{"location":"Sem6/ODS/ods/#subgradients","text":"\\(g\\) is a subgradient (non-unique) if \\[ f(y) \\geq f(x) + g^T (y - x) \\]","title":"Subgradients"},{"location":"Sem6/ODS/ods/#hyperplane-seperation-theorem","text":"Convex sets that do not intersect are seperable by a hyperplane Convex and Lipschitz <=> bounded subgradients","title":"Hyperplane seperation theorem"},{"location":"Sem6/ODS/ods/#w3-lecture-6-nonsmooth-optimization-contd","text":"","title":"W3 Lecture 6 - Nonsmooth Optimization cont'd"},{"location":"Sem6/ODS/ods/#descent-directions","text":"TODO","title":"Descent Directions"},{"location":"Sem6/ODS/ods/#subgradient-descent","text":"$$ x_{t+1} = \\Pi_X(x_t - \\gamma_t g_t), $$ where \\(g_t \\in \\partial f\\)","title":"Subgradient descent"},{"location":"Sem6/ODS/ods/#choices-for-step-size","text":"constant Scaled (divide through subgradient norm) Non-summable but diminishing stepsize Square summable stepsize \\(\\gamma = 1 / t\\) Polyak's stepsize \\(\\gamma_t = \\frac{f(x_t) - f(x^*)}{||g_t||_2^2}\\)","title":"Choices for step size"},{"location":"Sem6/ODS/ods/#basic-descent-lemma","text":"\\[ ||x_{t+1} - x^*||_2^2 \\leq ||x_{t} - x^*||_2^2 - 2 \\gamma_t (f(x_t) - f(x^*)) + \\gamma_t^2 ||g_t||_2^2 \\]","title":"Basic \"Descent\" Lemma"},{"location":"Sem6/ODS/ods/#main-theorem-on-convergence","text":"If \\(f\\) is convex: $$ \\min_{1 \\leq t \\leq T} f(x_t) - f^ \\leq \\frac{||x_1 - x^ || 2^2 + \\sum ^T {\\gamma_t^2 ||g_t|| 2^2}}{2 \\sum ^T \\gamma_t} $$ and $$ f(\\hat{x} t) - f^ \\leq \\frac{||x_1 - x^ ||_2^2 + \\sum ^T {\\gamma_t^2 ||g_t|| 2^2}}{2 \\sum ^T \\gamma_t}, $$ where \\(\\hat{x}_t = \\frac{\\sum_{t=1}^T \\gamma_t x_t}{\\sum_{t=1}^T \\gamma_t}\\) .","title":"Main Theorem on Convergence"},{"location":"Sem6/ODS/ods/#convergence-rate-fro-convex-lipschitz-problem","text":"","title":"Convergence Rate fro Convex Lipschitz Problem"},{"location":"Sem6/ODS/ods/#convergence-for-strongly-convex-lipschitz-case","text":"","title":"Convergence for Strongly Convex Lipschitz case"},{"location":"Sem6/ODS/ods/#lower-bound","text":"","title":"Lower bound"},{"location":"Sem6/ODS/ods/#w4-lecture-7-8-nonsmooth-and-composite-optimization","text":"Motivation: Try to exploit: - non-Euclidean geometry -> Mirror descent - structure of \\(f\\) -> Proximal algorithms","title":"W4 Lecture 7 &amp; 8 - Nonsmooth and Composite Optimization"},{"location":"Sem6/ODS/ods/#norms","text":"","title":"Norms"},{"location":"Sem6/ODS/ods/#bregmann-divergence","text":"mirror function","title":"Bregmann Divergence"},{"location":"Sem6/ODS/ods/#mirror-descent","text":"","title":"Mirror descent"},{"location":"Sem6/ODS/ods/#convergence-of-mirror-descent","text":"$ \\gamma_t(f(x_t) - f^ ) \\leq V_w^t - V_w^{t+1} + \\frac{\\gamma_t^2}{2} ||g_t||_ ^2, $ where \\(||.||_*\\) is the dual norm.","title":"Convergence of mirror descent"},{"location":"Sem6/ODS/ods/#proof","text":"TODO","title":"Proof"},{"location":"Sem6/ODS/ods/#convex-composite-optimization","text":"\\[ \\min_{x \\in R^d} f(x) + g(x) \\]","title":"Convex Composite Optimization"},{"location":"Sem6/ODS/ods/#proximal-operator","text":"","title":"Proximal operator"},{"location":"Sem6/ODS/ods/#proximal-gradient-method","text":"","title":"Proximal Gradient Method"},{"location":"Sem6/ODS/ods/#interpretations","text":"","title":"Interpretations"},{"location":"Sem6/ODS/ods/#interpretation-1","text":"","title":"Interpretation 1"},{"location":"Sem6/ODS/ods/#lecture-5-stochastic-optimization","text":"\\[ \\min_{x \\in R^d} F(x) := E_{\\xi}[f(x, \\xi)] \\] Assumptions: - \\(f\\) convex in \\(x\\) and differentiable => \\(F(x)\\) is convex Similar to big- \\(n\\) problem (empirical risk).","title":"Lecture 5 - Stochastic Optimization"},{"location":"Sem6/ODS/ods/#stochastic-gradient-descent","text":"unbiased estimate","title":"Stochastic Gradient Descent"},{"location":"Sem6/ODS/ods/#convergence-analysis","text":"","title":"Convergence Analysis"},{"location":"Sem6/ODS/ods/#convex-case","text":"","title":"Convex case"},{"location":"Sem6/ODS/ods/#strongly-convex-case","text":"","title":"Strongly convex case"},{"location":"Sem6/ODS/ods/#smooth-and-strongly-convex-case","text":"","title":"Smooth and strongly convex case"},{"location":"Sem6/ODS/ods/#variance-reduction-techniques","text":"","title":"Variance Reduction Techniques"},{"location":"Sem6/ODS/ods/#adaptive-methods","text":"","title":"Adaptive methods"},{"location":"Sem6/ODS/ods/#lecture-6-nonconvex-optimization","text":"Bounded Hessians => smooth smooth => bounded hessians (over any open convex set) Say something about convergence of \\(||\\nabla f(x_t)||^2 \\rightarrow 0\\) .","title":"Lecture 6 - Nonconvex optimization"},{"location":"Sem6/ODS/ods/#gradient-descent-on-smooth-functions","text":"","title":"Gradient descent on smooth functions"},{"location":"Sem6/ODS/ods/#no-overshooting-with-gamma-frac1l","text":"","title":"No overshooting with \\(\\gamma = \\frac{1}{L}\\)"},{"location":"Sem6/ODS/ods/#trajectory-analysis","text":"","title":"Trajectory analysis"},{"location":"Sem6/ODS/ods/#balanced-iterates","text":"","title":"Balanced iterates"},{"location":"Sem6/ODS/ods/#bounded-hessians-along-the-trajectory","text":"","title":"Bounded Hessians along the trajectory"},{"location":"Sem6/ODS/ods/#lecture-7-newtons-method-and-quasi-newton-methods","text":"","title":"Lecture 7 - Newton's Method and Quasi-Newton methods"},{"location":"Sem6/ODS/ods/#newton-raphson-method","text":"Find zeros (Newton is referred to in optimization with 2nd derivatives, Newton-Raphson wants to find zeros - only involves first derivative) does not always converge","title":"Newton-Raphson method"},{"location":"Sem6/ODS/ods/#the-babylonian-method","text":"Find zero of \\(f(x) = x^2 - R\\)","title":"The Babylonian method"},{"location":"Sem6/ODS/ods/#newtons-method","text":"\\[x_{t+1} = x_t - \\nabla^2 f(x_t)^{-1} \\nabla f(x_t)\\] = minimize second order taylor expansion at each step Once you're close you're there (when close to optimum, super-exponentially fast). Intuition, Hessian nearly constant close to optimum.","title":"Newton's method"},{"location":"Sem6/ODS/ods/#quasi-newton-methods","text":"Motivation by secant methods (replace gradient with finite difference) How to choose \\(H_t\\) : $$ \\nabla f(x_t) - \\nabla f(x_{t-1}) = H_t (x_t - x_{t-1}), \\quad H_t = H_t^T $$","title":"Quasi Newton Methods"},{"location":"Sem6/ODS/ods/#greenstadt","text":"TODO recap derivation from lecture notes (involves Lagrange multipliers)","title":"Greenstadt"},{"location":"Sem6/ODS/ods/#goldfarb","text":"=> BFGS method","title":"Goldfarb"},{"location":"Sem6/ODS/ods/#bfgs-method","text":"M =","title":"BFGS method"},{"location":"Sem6/ODS/ods/#l-bfgs","text":"Normal \\(m = 10\\) No theoretical runtime guarantees","title":"L-BFGS"},{"location":"Sem6/SBRC/","text":"Speed Walker Challenge Our goal is to immitate the frog jumping mechanism using penumatic actuators. We were inspired by this video from National Geographic which shows frogs jumping in slow motion. @import \"leg concept.jpg\" Modeling We don't have any simulation results yet due to great difficulties with SOFA. Here are the issues we faced with SOFA: Compilation was not successful even after putting in hours of effort Collission detection seems not to work with the binary distributed via the Soft Robotics Plugin Homepage . Documentation for most of the components do only exist in the form of examples. Therefore, we have to reverse engineer or have to \"guess\" the options and dependencies for each component. Video tutorials only cover the pure basics and components that are well documented. Nevertheless, we plan to have a working simulation model in the near future. Moreover, we also thought about simplifying the whole simulation by modeling the frog leg as a chain of rigid bodies with interconnecting springs instead of modeling a soft material reacting to air pressure. Finally, instead of using SOFA we could also use Nvidia Flex that can model rigid/ soft/ fluid systems through particle simulations. Nvidia Flex is also available as a Unity plugin.","title":"Speed Walker Challenge"},{"location":"Sem6/SBRC/#speed-walker-challenge","text":"Our goal is to immitate the frog jumping mechanism using penumatic actuators. We were inspired by this video from National Geographic which shows frogs jumping in slow motion. @import \"leg concept.jpg\"","title":"Speed Walker Challenge"},{"location":"Sem6/SBRC/#modeling","text":"We don't have any simulation results yet due to great difficulties with SOFA. Here are the issues we faced with SOFA: Compilation was not successful even after putting in hours of effort Collission detection seems not to work with the binary distributed via the Soft Robotics Plugin Homepage . Documentation for most of the components do only exist in the form of examples. Therefore, we have to reverse engineer or have to \"guess\" the options and dependencies for each component. Video tutorials only cover the pure basics and components that are well documented. Nevertheless, we plan to have a working simulation model in the near future. Moreover, we also thought about simplifying the whole simulation by modeling the frog leg as a chain of rigid bodies with interconnecting springs instead of modeling a soft material reacting to air pressure. Finally, instead of using SOFA we could also use Nvidia Flex that can model rigid/ soft/ fluid systems through particle simulations. Nvidia Flex is also available as a Unity plugin.","title":"Modeling"},{"location":"Sem6/SBRC/hasel_paper/","text":"An Easy-to-Implement Toolkit to Create Versatile and High-Performance HASEL Actuators for Untethered Soft Robots","title":"Hasel paper"},{"location":"Sem6/SBRC/hasel_paper/#an-easy-to-implement-toolkit-to-create-versatile-and-high-performance-hasel-actuators-for-untethered-soft-robots","text":"","title":"An Easy-to-Implement Toolkit to Create Versatile and High-Performance HASEL Actuators for Untethered Soft Robots"},{"location":"Sem6/SBRC/sbrc/","text":"Lecture 3 Young's modulus \\(E\\) Shore Hardness Scales: OO (very soft) A (soft) D (hard) Poisson's ratio \\(\\nu\\) Auxetic materials: Negative Poisson ratio Lecture is structured according to material modalities Fluid elastomer actuators Pneumatic Hydraulic Sylicone Fabrication: Condensation based (moisture) Platinum based (hydrosilylation) Peroxide EcoFlex, Dragon Skin Lecture 4 Thermal Actuators Fishing Line Problems Slow Magnetic Actuators Types of magnetism: Diamagnetic Paramegnetic Ferromagnetic Magnetic Hysteris Loop Magnetic Flux with respect to applied magnetic field Coercitivity: Measure of a ferromagnetic material to withstand an external magnetic field without becoming demagnetized Lecture 5 Lecture 6 Bio-Actuators Lecture 7 - Fabrication & Design of Soft Robots","title":"Lectures"},{"location":"Sem6/SBRC/sbrc/#lecture-3","text":"Young's modulus \\(E\\) Shore Hardness Scales: OO (very soft) A (soft) D (hard) Poisson's ratio \\(\\nu\\) Auxetic materials: Negative Poisson ratio Lecture is structured according to material modalities","title":"Lecture 3"},{"location":"Sem6/SBRC/sbrc/#fluid-elastomer-actuators","text":"Pneumatic Hydraulic Sylicone Fabrication: Condensation based (moisture) Platinum based (hydrosilylation) Peroxide EcoFlex, Dragon Skin","title":"Fluid elastomer actuators"},{"location":"Sem6/SBRC/sbrc/#lecture-4","text":"","title":"Lecture 4"},{"location":"Sem6/SBRC/sbrc/#thermal-actuators","text":"Fishing Line Problems Slow","title":"Thermal Actuators"},{"location":"Sem6/SBRC/sbrc/#magnetic-actuators","text":"Types of magnetism: Diamagnetic Paramegnetic Ferromagnetic Magnetic Hysteris Loop Magnetic Flux with respect to applied magnetic field Coercitivity: Measure of a ferromagnetic material to withstand an external magnetic field without becoming demagnetized","title":"Magnetic Actuators"},{"location":"Sem6/SBRC/sbrc/#lecture-5","text":"","title":"Lecture 5"},{"location":"Sem6/SBRC/sbrc/#lecture-6","text":"","title":"Lecture 6"},{"location":"Sem6/SBRC/sbrc/#bio-actuators","text":"","title":"Bio-Actuators"},{"location":"Sem6/SBRC/sbrc/#lecture-7-fabrication-design-of-soft-robots","text":"","title":"Lecture 7 - Fabrication &amp; Design of Soft Robots"},{"location":"notes/flutter/02_setup/","text":"Setup Topic/Title: Keywords/Questions: Notes: Summary:","title":"Setup"},{"location":"notes/flutter/02_setup/#setup","text":"","title":"Setup"},{"location":"notes/flutter/02_setup/#topictitle","text":"","title":"Topic/Title:"},{"location":"notes/flutter/02_setup/#keywordsquestions","text":"","title":"Keywords/Questions:"},{"location":"notes/flutter/02_setup/#notes","text":"","title":"Notes:"},{"location":"notes/flutter/02_setup/#summary","text":"","title":"Summary:"},{"location":"notes/flutter/03_app_from_scratch/","text":"Lectures Topic/Title Creating a new Flutter Project from scratch Keywords/Questions MaterialApp, WidgetTree, Center, Reformat, main method, App from scratch Notes - Set a comma after each rounded bracket of a widget to help the reformatter to restructure the file. - Use a MaterialApp to start coding an app with material design \u2192 comes with all material widgets. - The app's child widget attribute is called home . - Centering is also done through a widget. - Hot reload does not work here (Needs stateless or stateful widget with build method) Summary Creating a hello world app using a MaterialApp Topic/Title Scaffolding a Material App Keywords/Questions Scaffold, AppBar, Image, NetworkImage, draw.io Notes center widget with context actions by hitting alt+Enter Summary re-creating the I Am Rich App Topic/Title Working with Assets in Flutter & the Puspec file Keywords/Questions assets, AssetImage, pubspec.yaml Notes To add images => 1) add images folder to project, tell flutter where to find the assets by updating the pubspec.yaml file, Press Pub get to install the packages (and update the asset folder index) Summary Exchanging the NetworkImage with an AssetImage (diamond) Topic/Title How to Add App Icons to the iOS and Android Projects Keywords/Questions App Icon, appicon.co Notes - Upload image to appicon.co and generated files for app icon - For Android: Go to app > src > main > res and then show in explorer . Replace mipmap- files with the generated ones. For circular app icons: Right click res folder and choose New > Image Asset from the context menu. Next, change the path to the start image . Finally, resize the app icon such that it fits the boundaries. Summary Add AppIcon to app","title":"I am rich"},{"location":"notes/flutter/03_app_from_scratch/#lectures","text":"Topic/Title Creating a new Flutter Project from scratch Keywords/Questions MaterialApp, WidgetTree, Center, Reformat, main method, App from scratch Notes - Set a comma after each rounded bracket of a widget to help the reformatter to restructure the file. - Use a MaterialApp to start coding an app with material design \u2192 comes with all material widgets. - The app's child widget attribute is called home . - Centering is also done through a widget. - Hot reload does not work here (Needs stateless or stateful widget with build method) Summary Creating a hello world app using a MaterialApp Topic/Title Scaffolding a Material App Keywords/Questions Scaffold, AppBar, Image, NetworkImage, draw.io Notes center widget with context actions by hitting alt+Enter Summary re-creating the I Am Rich App Topic/Title Working with Assets in Flutter & the Puspec file Keywords/Questions assets, AssetImage, pubspec.yaml Notes To add images => 1) add images folder to project, tell flutter where to find the assets by updating the pubspec.yaml file, Press Pub get to install the packages (and update the asset folder index) Summary Exchanging the NetworkImage with an AssetImage (diamond) Topic/Title How to Add App Icons to the iOS and Android Projects Keywords/Questions App Icon, appicon.co Notes - Upload image to appicon.co and generated files for app icon - For Android: Go to app > src > main > res and then show in explorer . Replace mipmap- files with the generated ones. For circular app icons: Right click res folder and choose New > Image Asset from the context menu. Next, change the path to the start image . Finally, resize the app icon such that it fits the boundaries. Summary Add AppIcon to app","title":"Lectures"},{"location":"notes/flutter/06_MiCard/","text":"Topic/Title Hot Reload & Hot Restart - Flutter Power Tools Keywords/Questions build function, hot reload/restart Notes Hot reload searches for the nearest build function. Type stless to create stateless widget with build function. Summary Topic/Title How to Use Container Widgets Keywords/Questions Container, SafeArea, EdgeInsets, margin, padding Notes Containers without children try to be as big as possible. Containers with children take the size of its children. Use SafeArea to place children in a safe area (e.g. do not overlap with the notch of an iPhone). Container is a Single-Child widget. Summary Creating a Container with a Text child wrapped in a SafeArea . Topic/Title How to Use Column and Row Widgets for Layout Keywords/Questions Column, Row, Invisible Container, double.infinity, Alignment, SizedBox Notes Use invisible Container with width: double.infinity to fill screen width / height. One can also use crossAxisAlignment.stretch . Use mainAxisAlignment to determine behavior of column along main axis (e.g. MainAxisAlignment.spaceBetween ). One can use SizedBox for spacing between elements. Finally, one can also change the size of the column with mainAxisSize attribute (e.g. MainAxisSize.min ), Summary Playing around with Row and Column Widgets. Topic/Title Typping into Widget Properties Keywords/Questions CircleAvatar, TextStyle Notes ctrl+q for quick docs. Summary Adding CircleAvatar and Text in a column Topic/Title Incorporating Custom Fonts into Your Flutter App Keywords/Questions Fonts Notes Download fonts from fonts.google.com (don't have to worry about copyright). Add to fonts/your_font.ttf , update pubspec.yaml (see documentation). Summary Use of Pacifico and Source Sans Pro fonts. Topic/Title Adding Material Icons with the Icon Widget Keywords/Questions Icons Notes materialpalette.com Summary Add phone and email fields to card Topic/Title Adding Material Icons with the Icon Widget Keywords/Questions Icons Notes materialpalette.com, use Icon widget and set Icon for example to Icons.phone Summary Add phone and email fields to card Topic/Title Flutter Card & ListTile Widget Keywords/Questions Card, ListTile, Divider Notes Use Divider to add 1px horizontal line. Summary Use ListTile as child of Card to get nice looking fields Topic/Title | --- | --- Keywords/Questions | Notes | Summary |","title":"MiCard"},{"location":"notes/flutter/07_dicee/","text":"Topic/Title Using the Expanded Widget for Flexible Layouts Keywords/Questions Expanded, flex, mage.asset Notes Use Expanded to expand widget to its parent's borders. Use flex property of Expanded to set ratio between multiple Expanded widgets. Image.asset(file name) is shorter than Image(image: AssetImage(filename)) Summary Creating a row with dice images wrapped in a expanded widget. Topic/Title How to Use Intention Actions Keywords/Questions Intention Actions Notes option+Enter to show context (intention) actions. Also available in flutter outline (might need to restart dart code analysis). Summary add padding around dice images Topic/Title Detecting User Interaction with Flutter Buttons Keywords/Questions Button, FlatButton, required, onPressed Notes FlatButton requires a onPressed property set to a VoidCallback Summary Wrap images with FlatButton Topic/Title Dart Functions Part 1 Keywords/Questions Anonymous functions Notes Anonymous function: (){ /*code goes here*/ } Summary -- Topic/Title Making the Dice Image Change Reactively Keywords/Questions Variable, String Interpolation Notes declare variables with var . Var should be declared in the build function to work with hot reload. Substitute variables in strings by using the dollar sign. Summary Set asset file through variable Topic/Title Dart Variables Keywords/Questions Notes Summary Topic/Title Dart Data Types Keywords/Questions var, dynamic, String, int Notes Dart is statically typed . However, Dart has also dynamic data types. var without initializing with a value produces a dynamic variable. Summary Topic/Title Stateful vs Stateless Widgets Keywords/Questions StatefulWidget, State, createState, setState Notes StatefulWidget instances are immutable and store their mutable state either in separate State objects that are created by the createState method, or in objects to which that State subscribes . The State object manages the logic (within the build function) and the internal state of the stateful widget. It is necessary to notify the State object about changes using the setState method. Summary Change dice number by clicking on the images. Topic/Title | --- | --- Keywords/Questions | Notes | Summary | Topic/Title | --- | --- Keywords/Questions | Notes | Summary | Topic/Title | --- | --- Keywords/Questions | Notes | Summary |","title":"Dicee - Building Apps with State"},{"location":"notes/flutter/09_xylophone/","text":"Topic/Title What are Flutter and Dart Packages? Keywords/Questions Notes Use of package: Add entry to dependencies in pubspec.yaml: <package_name>: ^x.y.z, ^ tells flutter to update the package as long as the major version stays the same. Summary Example for using a flutter package. Topic/Title How to Play Audio Across Platforms Keywords/Questions audioplayers Notes Use audioplayers package. final player = AudioCache(); player.play(); Summary Incorporating the audioplayers package Topic/Title How to play multiple songs Keywords/Questions Function Notes Summary Topic/Title Refactor and Clean up code Keywords/Questions Named paramters Notes Named paramters have to go in curly braces: foo({Color color, int number}){} Summary Build widget within function Topic/Title | --- | --- Keywords/Questions | Notes | Summary | Topic/Title | --- | --- Keywords/Questions | Notes | Summary | Topic/Title | --- | --- Keywords/Questions | Notes | Summary |","title":"Xylophone - Using Flutter and Dart Packages"},{"location":"notes/flutter/10_quizzler/","text":"Topic/Title Building a Score Keeper Keywords/Questions Icon, List types Notes Icon(Icons.check / Icons.close, color: Colors.green / Colors.red) Summary Building a row with check and close Icons Topic/Title Displaying the Questions Keywords/Questions List Notes Summary Creating a list for questions and introducing a question number Topic/Title Checking the User Answer Keywords/Questions Conditionals Notes Summary Creating an answer list and check whether questions are answered correctly Topic/Title Creating a Question Class Keywords/Questions Class Notes Summary Creating a question class Topic/Title Abstraction in Action Keywords/Questions OOP, Abstraction Notes OOP (Object Oriented Programming) has 4 pillars: Abstraction, Encapsulation, Inheritance, Polymorphism. Store questions in questionBank property of a new class QuizBrain. Benefit of using a class QuizBrain is that, for example, if we wanted to make a Sports Quiz, we could just change the class QuizBrain to SportsBrain and don't make any other changes to our app. Summary New file quiz_brain Topic/Title Encapsualtion in Action Keywords/Questions Encapsulation, private, getters Notes Do not make fields of Question public. For making variables private add underscore to start of property name. Use getters for accessing private properties. Summary Improving code by putting more logic into QuizBrain class Topic/Title Inheritance in Action Keywords/Questions extends Notes Summary Topic/Title Polymorphism in Action Keywords/Questions @override, super Notes Overriding functionality. Call parent function with super.<function_name>. Factory uses polymorphism where the factory produces consumables and the consumer does not have to worry which sort of product it is. Summary Topic/Title | --- | --- Keywords/Questions | Notes | Summary | Topic/Title | --- | --- Keywords/Questions | Notes | Summary | Topic/Title | --- | --- Keywords/Questions | Notes | Summary |","title":"Quizzler - Modularising & Organizing Flutter Code"},{"location":"notes/flutter/12_bmi/","text":"Topic/Title BMI Calculator - A Beautiful Health App Keywords/Questions dribbble.com Notes Get inspired by dribbble.com Summary Topic/Title How to Use Flutter Themes Keywords/Questions ThemeData, colorzilla.com, copyWith Notes 0xFF = opaque, We can wrap every widget with a theme widget and change its data property Summary Creating a theme for the app and adding a new file for our custom InputPage widget Topic/Title How to Refactor Flutter Widgets Keywords/Questions BoxDecoration, Key, @required, Immutable, final Notes color has to go into BoxDecoration if decoration property is set, new is deprecated. Repetitive widgets can be extracted by right clicking on that widget inside the flutter outline and then click extract widget (If flutter outline says nothing to show restart Dart analysis). Add @required to constructor arguments to make them required. Add final color property to extracted widget. Summary Creating tiles for the app where a tile is our custom widget with a color property Topic/Title Dart final vs const Keywords/Questions final, const Notes A final variable can be set only once; a const variable is a compile-time constant. (Const variables are implicitly final.) https://dart.dev/guides/language/language-tour#final-and-const Summary Adding a Container at the bottom of the App with const height and making colors const. Topic/Title Creating Custom Flutter Widgets Keywords/Questions font_awesome_flutter Notes Create new files for custom widgets Summary Add child property to our custom tiles/cards widget. Make IconContent widget for child. Topic/Title The GestureDetector Widget Keywords/Questions GestureDetector Notes FlatButton effects styling of widget. Use GestureDetector instead and set onTap property. Summary Make Fe-/Male card clickable with GestureDetector Topic/Title Dart Enums Keywords/Questions Enums Notes Enums = The action of establishing the number of something . enum <name> {type1, type2}. Enums must be outside class. Summary Creating an Enum for genders Topic/Title Dart Tenary Operators Keywords/Questions Notes a = condition ? var_if_true : var_if_false; (CODE COMPLETE 2nd edition) Summary Add selectedGender variables and determine color with tenary operator Topic/Title Dart Functions as First Order Objects Keywords/Questions Function type Notes Summary GestureDetector moved to Reusable card and pass onPress Function to constructor Topic/Title The Flutter Slider Widget Keywords/Questions Slider Notes Dedicated constant file (why not put constants into theme?) Summary Adding Slider to App Topic/Title Customizing Widgets using Themes Keywords/Questions SliderThemeData, .of Notes Wrap Slider with SliderTheme for fine-grained control. .of e.g. SliderTheme.of(context).copyWith(...), Widgets are immutable, that is, changing a color would create a new object, for example Summary Customizing the Slider Topic/Title Composition vs Inheritance - Building Flutter Widgets from Scratch Keywords/Questions Notes How to customize even further, not just using ThemeData? First option: Inherit from a class and alter its properties/ define new features. Second option: Assume every class is composed of modules. Then we could try to change a widget's composition to fine tune a widget to our needs. Summary Topic/Title | --- | --- Keywords/Questions | Notes | Summary |","title":"BMI Calculator - Building Flutter UIs for Intermediates"},{"location":"notes/flutter/13_clima/","text":"Topic/Title Getting Location Data From Across Platforms Keywords/Questions Geolocator, Permissions, Async, Await Notes Use Geolocator plugin to get high/ low precision geo location. It is necessary to add entry to android manifesto/ IOS info to gain permission. Summary Get location on press button Topic/Title Dart Futures, Async & Await Keywords/Questions Async, Await, Future Notes Async methods must return a Future<type>. void foo() async { String blubb = await fun();} Summary Adding scratch file to project Topic/Title Stateful Widget Lifecycle Methods Keywords/Questions initState, build, deactivate, @override Notes super.initState Summary Load location at loading the screen Topic/Title Dart Exception Handling & Null Aware Operators Keywords/Questions try catch, ??, throw Notes ?? check if variable if is null (myvar ?? defaultValue). try { } catch (e) {print(e);}. throw <message>; Summary Try catch getLocation Topic/Title Networking in Flutter Apps with the HTTP Package Keywords/Questions http, Response status, JSON Notes Status: 1) Hango on. 2) You're good to go. 3) Go away. 4) You're screwed. 5) I'm screwed. http.Response resp = http.get(url), returns JSON Summary add getData funtion Topic/Title JSON Parsing and Dynamic Types Keywords/Questions JSON extension for Chrome, jsonDecode Notes import 'dart:convert'; Summary Create networking.dart file for getting data Topic/Title Showing a Spinner While the User Waits Keywords/Questions spinkit Notes Summary Loading animation while fetching weather data. Then link to location screen Topic/Title Passing Data to a State Object Keywords/Questions Notes Passing data from stateless widget to its state. State points to its parent StateFul widget. State has a widget property. Summary Adding temperature etc to state variables in location screen, function updateUI called from initState Topic/Title Updating the Weather with the WeatherModel Keywords/Questions Notes Summary Using the WeatherModel class to get weather icon and weather message Topic/Title Refactoring the Location Methods Keywords/Questions Notes Changing location requires to open google maps Summary add getLocationWeather to the weather model class. Add funtionality to update location on press button. Topic/Title Creating and Styling a TextField Widget for Text Entry in city screen Keywords/Questions TextField Notes Summary creating TextField and decorating it Topic/Title Passing Data Backwards Through the Navigation Stack Keywords/Questions pop, push Notes pass back by addin result to .pop(context, result) method. push() method return a Future with the result. Summary getCityWeather to weather model. return cityName property Topic/Title | --- | --- Keywords/Questions | Notes | Summary | Topic/Title | --- | --- Keywords/Questions | Notes | Summary |","title":"Clima - Powering Your Flutter App with Live Weather Web Data"},{"location":"notes/flutter/14_bitcoin/","text":"Topic/Title The Material DropdownButton Widgets Keywords/Questions DropdownButton, DropdownMenuItem Notes Summary Add option to select currency from list Topic/Title Introducing Cupertino Widgets Keywords/Questions CupertinoPicker Notes Summary Replace Dropdown with CupertinoPicker Topic/Title Building Platform Specific UI (iOS & Android) Keywords/Questions dart::io show Platform Notes Summary Platform.isIOS ? CupertinoPicker(...) : DropdownButton(...) Topic/Title | --- | --- Keywords/Questions | Notes | Summary | Topic/Title | --- | --- Keywords/Questions | Notes | Summary | Topic/Title | --- | --- Keywords/Questions | Notes | Summary | Topic/Title | --- | --- Keywords/Questions | Notes | Summary | Topic/Title | --- | --- Keywords/Questions | Notes | Summary | Topic/Title | --- | --- Keywords/Questions | Notes | Summary | Topic/Title | --- | --- Keywords/Questions | Notes | Summary |","title":"Bitcoin Ticker"},{"location":"notes/flutter/15_chat/","text":"Topic/Title Named Routes Keywords/Questions static, router, initialRoute Notes Instead of using strings in routes map associate an static id with each screen => less risk of typos. Forgot how to use named router => F1 shows documentation Summary Adding named routes to main.dart and static id to screens. Topic/Title Refactor Routes with the Static Const Keywords/Questions Notes Summary All routes as static const id + added Navigator.pushNamed(context, id) Topic/Title Flutter Hero Animations Keywords/Questions Hero Notes Hero requires a tag Summary Logo to float from one to another screen. Topic/Title Custom Flutter Animations with the Animation Controller Keywords/Questions SingleTickerProviderStateMixin, AnimationController, Animation, with , mixin , dispose, ColorTween Notes Mixin => with SingleTickerProviderStateMixin, controller.value from 0 -> 1. Change animation curve by defining an animation = CurvedAnimation(parent: controller, curve: Curves.easeIn). animation.addStatusListener, controller.addListener. Dispose controller when app is disposed to save ressources. Animation listens on controller, controller controls the tick event. controller.forward(), controller.reverse() Summary Play around with animations Topic/Title Code refactoring challenge Keywords/Questions Notes Remember constants can be further tuned with .copyWith(property) Summary extract widgets (rounded_button.dart) and create constant for TextDecoration Topic/Title Registering Users with Firebase using FirebaseAuth Keywords/Questions Notes keyboardType: TextInputType.emailAddress, obscureText: true Summary Tuning input text fields Topic/Title Listening for Data from Firebase using Streams Keywords/Questions stream Notes .collection(collectionName).snapshots() Summary Subscribe to document changes in the cloud with streams Topic/Title Turning Streams into Widgets Using the StreamBuilder Keywords/Questions StreamBuilder Notes Use Streambuilder to subscribe to streams and handle update Summary Column of messages Topic/Title The Flutter ListView Keywords/Questions Notes Summary Styling the text messages Topic/Title A Different UI for Different Senders Keywords/Questions Notes Summary Topic/Title Cloud Firestore Security Rules Keywords/Questions Notes Summary Topic/Title | --- | --- Keywords/Questions | Notes | Summary | Topic/Title | --- | --- Keywords/Questions | Notes | Summary | Topic/Title | --- | --- Keywords/Questions | Notes | Summary |","title":"Chat App w. Firebase"},{"location":"notes/flutter/16_todoey/","text":"Topic/Title Designing the To-Do List App Keywords/Questions Notes Summary Styling the Todoey list, adding a tasks_screen file Topic/Title The ListView Challenge Keywords/Questions ListView, TaskTile Notes Summary Creating new files tasks_list.dart and task_tile.dart Topic/Title The BottomSheet Widget Keywords/Questions showModalBottomSheet Notes Summary add_task_screen.dart Topic/Title What is State and How do we Manage it? Keywords/Questions Notes Summary Create TaskCheckbox in task_tile.dart, convert task_tile to stateful widget Topic/Title The ListView Builder Keywords/Questions ListView.builder Notes ListView builder builds only tiles that are visible. Summary Make TaskTile stateless again. Create models/task.dart and a list of tasks. Topic/Title Lifting State Up Challenge Keywords/Questions Notes Summary Make list of tasks available to AddTaskScreen by lifting the list up to the TasksScreen. Topic/Title Flutter App Architecture Patterns Keywords/Questions Model View Control ( MVC ) Notes Model = Data & Logic, View = User interface, Control = Mediator (e.g. makes queries) Summary Topic/Title Introducing the Provider Package Keywords/Questions Prop Drilling, Provider, InheritedWidget, ChangeNotifier Notes Prop Drilling = pass data to descendants => InheritedWidget , Provider wraps InheritedWidget. In order to use the Provider package wrap the App (or a widget) with the Provider or ChangeNotifierProvider widget. Data class should inherit from ChangeNotifier => create function that calls notifyListeners() . Update data with Provider.of<Data>(context).changeString() where changeString is a custom method of Data that calls notifyListeners(). Summary Topic/Title Using a Provider and a ChangeNotifier to Manage State Keywords/Questions Consumer, get Notes Instead of multiple calls to Provider.of<Data>(context).tasks one can simply wrap the parent widget with a Consumer widget which then makes the data available to its children. Summary Topic/Title Adding New To-Do List Tasks Keywords/Questions UnmodifiableListView Notes Summary Topic/Title | --- | --- Keywords/Questions | Notes | Summary | Topic/Title | --- | --- Keywords/Questions | Notes | Summary |","title":"Todoey - State Management"},{"location":"software%20design/factory/","text":"Factory Pattern The factory pattern is used when... Source: Wikipedia First Header Second Header Third Header Ipsum has been the industry's standard dummy text ever since the 1500s, when an unknown printer took a galley of type and scrambled it to make a type specimen book. It has survived not only five centuries, but also the leap into electronic typesetting, remaining essentially unchanged. It was popularised in the 1960s with the release of Letraset sheets containing Lorem Ipsum passag Content Cell Content Cell Content Cell Content Cell Content Cell Title Lorem Ipsum is simply dummy text of the printing and typesetting industry. Lorem Ipsum has been the industry's standard dummy text ever since the 1500s, when an unknown printer took a galley of type and scrambled it to make a type specimen book. It has survived not only five centuries, but also the leap into electronic typesetting, remaining essentially unchanged. It was popularised in the 1960s with the release of Letraset sheets containing Lorem Ipsum passages, and more recently with desktop publishing software like Aldus PageMaker including versions of Lorem Ipsum. Title This is a test When $a \\ne 0$, there are two solutions to \\(ax^2 + bx + c = 0\\) and they are $$x = {-b \\pm \\sqrt{b^2-4ac} \\over 2a}.$$ Title This is a test Title This is a test Title Lorem Ipsum is simply dummy text of the printing and typesetting industry. Lorem Ipsum has been the industry's standard dummy text ever since the 1500s, when an unknown printer took a galley of type and scrambled it to make a type specimen book. It has survived not only five centuries, but also the leap into electronic typesetting, remaining essentially unchanged. It was popularised in the 1960s with the release of Letraset sheets containing Lorem Ipsum passages, and more recently with desktop publishing software like Aldus PageMaker including versions of Lorem Ipsum. Title Lorem Ipsum is simply dummy text of the printing and typesetting industry. Lorem Ipsum has been the industry's standard dummy text ever since the 1500s, when an unknown printer took a galley of type and scrambled it to make a type specimen book. It has survived not only five centuries, but also the leap into electronic typesetting, remaining essentially unchanged. It was popularised in the 1960s with the release of Letraset sheets containing Lorem Ipsum passages, and more recently with desktop publishing software like Aldus PageMaker including versions of Lorem Ipsum. Title Lorem Ipsum is simply dummy text of the printing and typesetting industry. Lorem Ipsum has been the industry's standard dummy text ever since the 1500s, when an unknown printer took a galley of type and scrambled it to make a type specimen book. It has survived not only five centuries, but also the leap into electronic typesetting, remaining essentially unchanged. It was popularised in the 1960s with the release of Letraset sheets containing Lorem Ipsum passages, and more recently with desktop publishing software like Aldus PageMaker including versions of Lorem Ipsum. Title Lorem Ipsum is simply dummy text of the printing and typesetting industry. Lorem Ipsum has been the industry's standard dummy text ever since the 1500s, when an unknown printer took a galley of type and scrambled it to make a type specimen book. It has survived not only five centuries, but also the leap into electronic typesetting, remaining essentially unchanged. It was popularised in the 1960s with the release of Letraset sheets containing Lorem Ipsum passages, and more recently with desktop publishing software like Aldus PageMaker including versions of Lorem Ipsum. hi","title":"Factory"},{"location":"software%20design/factory/#factory-pattern","text":"The factory pattern is used when... Source: Wikipedia First Header Second Header Third Header Ipsum has been the industry's standard dummy text ever since the 1500s, when an unknown printer took a galley of type and scrambled it to make a type specimen book. It has survived not only five centuries, but also the leap into electronic typesetting, remaining essentially unchanged. It was popularised in the 1960s with the release of Letraset sheets containing Lorem Ipsum passag Content Cell Content Cell Content Cell Content Cell Content Cell Title Lorem Ipsum is simply dummy text of the printing and typesetting industry. Lorem Ipsum has been the industry's standard dummy text ever since the 1500s, when an unknown printer took a galley of type and scrambled it to make a type specimen book. It has survived not only five centuries, but also the leap into electronic typesetting, remaining essentially unchanged. It was popularised in the 1960s with the release of Letraset sheets containing Lorem Ipsum passages, and more recently with desktop publishing software like Aldus PageMaker including versions of Lorem Ipsum. Title This is a test When $a \\ne 0$, there are two solutions to \\(ax^2 + bx + c = 0\\) and they are $$x = {-b \\pm \\sqrt{b^2-4ac} \\over 2a}.$$ Title This is a test Title This is a test Title Lorem Ipsum is simply dummy text of the printing and typesetting industry. Lorem Ipsum has been the industry's standard dummy text ever since the 1500s, when an unknown printer took a galley of type and scrambled it to make a type specimen book. It has survived not only five centuries, but also the leap into electronic typesetting, remaining essentially unchanged. It was popularised in the 1960s with the release of Letraset sheets containing Lorem Ipsum passages, and more recently with desktop publishing software like Aldus PageMaker including versions of Lorem Ipsum. Title Lorem Ipsum is simply dummy text of the printing and typesetting industry. Lorem Ipsum has been the industry's standard dummy text ever since the 1500s, when an unknown printer took a galley of type and scrambled it to make a type specimen book. It has survived not only five centuries, but also the leap into electronic typesetting, remaining essentially unchanged. It was popularised in the 1960s with the release of Letraset sheets containing Lorem Ipsum passages, and more recently with desktop publishing software like Aldus PageMaker including versions of Lorem Ipsum. Title Lorem Ipsum is simply dummy text of the printing and typesetting industry. Lorem Ipsum has been the industry's standard dummy text ever since the 1500s, when an unknown printer took a galley of type and scrambled it to make a type specimen book. It has survived not only five centuries, but also the leap into electronic typesetting, remaining essentially unchanged. It was popularised in the 1960s with the release of Letraset sheets containing Lorem Ipsum passages, and more recently with desktop publishing software like Aldus PageMaker including versions of Lorem Ipsum. Title Lorem Ipsum is simply dummy text of the printing and typesetting industry. Lorem Ipsum has been the industry's standard dummy text ever since the 1500s, when an unknown printer took a galley of type and scrambled it to make a type specimen book. It has survived not only five centuries, but also the leap into electronic typesetting, remaining essentially unchanged. It was popularised in the 1960s with the release of Letraset sheets containing Lorem Ipsum passages, and more recently with desktop publishing software like Aldus PageMaker including versions of Lorem Ipsum. hi","title":"Factory Pattern"},{"location":"software%20design/overview/","text":"Short overview over topics treated in the summary \\[ \\operatorname{ker} f=\\{g2\\in G:f(g)=e_{H}\\}{\\mbox{.}} \\] \\[ \\begin{equation} E = mc^2 \\label{eq:sample} \\end{equation} \\] In \\(\\eqref{eq:sample}\\) we see that Lorem ipsum 1 dolor sit amet, consectetur adipiscing elit. Das ist ein test. Lorem ipsum dolor sit amet, consectetur adipiscing elit. \u21a9","title":"Overview"}]}